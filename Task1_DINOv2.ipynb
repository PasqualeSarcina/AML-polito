{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "honcpimEq_B2",
    "ExecuteTime": {
     "end_time": "2025-12-07T11:13:57.523772Z",
     "start_time": "2025-12-07T11:13:57.504693Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, image_keys):\n",
    "        self.image_keys = image_keys\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        for key in self.image_keys:\n",
    "            image[key] /= 255.0\n",
    "            image[key] = self.normalize(image[key])\n",
    "        return image\n",
    "\n",
    "\n",
    "def read_img(path):\n",
    "    img = np.array(Image.open(path).convert('RGB'))\n",
    "\n",
    "    return torch.tensor(img.transpose(2, 0, 1).astype(np.float32))\n",
    "\n",
    "\n",
    "class SPairDataset(Dataset):\n",
    "    def __init__(self, pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype):\n",
    "\n",
    "        self.datatype = datatype\n",
    "        self.pck_alpha = pck_alpha\n",
    "        self.ann_files = open(os.path.join(layout_path, dataset_size, datatype + '.txt'), \"r\").read().split('\\n')\n",
    "        self.ann_files = self.ann_files[:len(self.ann_files) - 1]\n",
    "        self.pair_ann_path = pair_ann_path\n",
    "        self.image_path = image_path\n",
    "        self.categories = list(map(lambda x: os.path.basename(x), glob.glob('%s/*' % image_path)))\n",
    "        self.categories.sort()\n",
    "        self.transform = Normalize(['src_img', 'trg_img'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        ann_filename = self.ann_files[idx]\n",
    "        ann_file = ann_filename + '.json'\n",
    "        json_path = os.path.join(self.pair_ann_path, self.datatype, ann_file)\n",
    "\n",
    "        with open(json_path) as f:\n",
    "            annotation = json.load(f)\n",
    "\n",
    "        category = annotation['category']\n",
    "        src_img = read_img(os.path.join(self.image_path, category, annotation['src_imname']))\n",
    "        trg_img = read_img(os.path.join(self.image_path, category, annotation['trg_imname']))\n",
    "\n",
    "        trg_bbox = annotation['trg_bndbox']\n",
    "        pck_threshold = max(trg_bbox[2] - trg_bbox[0],  trg_bbox[3] - trg_bbox[1]) * self.pck_alpha\n",
    "\n",
    "        sample = {'pair_id': annotation['pair_id'],\n",
    "                  'filename': annotation['filename'],\n",
    "                  'src_imname': annotation['src_imname'],\n",
    "                  'trg_imname': annotation['trg_imname'],\n",
    "                  'src_imsize': src_img.size(),\n",
    "                  'trg_imsize': trg_img.size(),\n",
    "\n",
    "                  'src_bbox': annotation['src_bndbox'],\n",
    "                  'trg_bbox': annotation['trg_bndbox'],\n",
    "                  'category': annotation['category'],\n",
    "\n",
    "                  'src_pose': annotation['src_pose'],\n",
    "                  'trg_pose': annotation['trg_pose'],\n",
    "\n",
    "                  'src_img': src_img,\n",
    "                  'trg_img': trg_img,\n",
    "                  'src_kps': torch.tensor(annotation['src_kps']).float(),\n",
    "                  'trg_kps': torch.tensor(annotation['trg_kps']).float(),\n",
    "\n",
    "                  'mirror': annotation['mirror'],\n",
    "                  'vp_var': annotation['viewpoint_variation'],\n",
    "                  'sc_var': annotation['scale_variation'],\n",
    "                  'truncn': annotation['truncation'],\n",
    "                  'occlsn': annotation['occlusion'],\n",
    "\n",
    "                  'pck_threshold': pck_threshold}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base_dir = os.path.abspath(os.path.curdir)\n",
    "    dataset_dir = os.path.join(base_dir, 'dataset')\n",
    "    pair_ann_path = os.path.join(dataset_dir, 'PairAnnotation')\n",
    "    layout_path = os.path.join(dataset_dir, 'Layout')\n",
    "    image_path = os.path.join(dataset_dir, 'JPEGImages')\n",
    "    dataset_size = 'large'\n",
    "    pck_alpha = 0.05\n",
    "    \n",
    "    # Verifica che i percorsi esistano prima di creare il dataset\n",
    "    if os.path.exists(pair_ann_path) and os.path.exists(layout_path) and os.path.exists(image_path):\n",
    "        trn_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='trn')\n",
    "        val_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='val')\n",
    "        test_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='test')\n",
    "\n",
    "        trn_dataloader = DataLoader(trn_dataset, num_workers=0)\n",
    "        val_dataloader = DataLoader(val_dataset, num_workers=0)\n",
    "        test_dataloader = DataLoader(test_dataset, num_workers=0)\n",
    "        print(\"Dataset caricati correttamente.\")\n",
    "    else:\n",
    "        print(f\"Errore: Impossibile trovare i percorsi del dataset in '{base_dir}'.\\nVerifica l'estrazione e controlla se la struttura delle cartelle corrisponde.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset caricati correttamente.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "e99e7173",
    "outputId": "d4c98c11-58a0-4bbe-c75f-9339d6a62114",
    "ExecuteTime": {
     "end_time": "2025-12-07T11:23:34.251421Z",
     "start_time": "2025-12-07T11:14:00.636259Z"
    }
   },
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import math \n",
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n",
    "model.eval() # il modello in modalità valutazione (congela dropout, ecc)\n",
    "\n",
    "print(f\"Modello caricato su: {device}\")\n",
    "\n",
    "# Inizializza i contatori per la metrica PCK\n",
    "total_keypoints = 0\n",
    "#correct_kps_0_05 = 0\n",
    "#correct_kps_0_1 = 0\n",
    "correct_kps_0_2 = 0\n",
    "class_pck_data = {}\n",
    "\n",
    "with torch.no_grad(): # Disabilita il calcolo dei gradienti (risparmia memoria RAM/VRAM)\n",
    "    for i, data in enumerate(tqdm(test_dataloader, desc=\"Valutazione\")):\n",
    "        category = data['category'][0]\n",
    "        if category not in class_pck_data:\n",
    "            class_pck_data[category] = {\n",
    "                'total_keypoints': 0,\n",
    "                'correct_kps_0_2': 0\n",
    "            }\n",
    "\n",
    "        src_img = data['src_img'].to(device)\n",
    "        trg_img = data['trg_img'].to(device)\n",
    "\n",
    "        outputs_src = model(pixel_values=src_img)\n",
    "        outputs_trg = model(pixel_values=trg_img)\n",
    "\n",
    "        feats_src = outputs_src.last_hidden_state\n",
    "        feats_trg = outputs_trg.last_hidden_state\n",
    "        \n",
    "        _, _, H, W = data['src_img'].shape \n",
    "\n",
    "        patch_size = 14\n",
    "        w_grid = W // patch_size # Numero di patch in orizzontale\n",
    "\n",
    "        kps_list_src = data['src_kps'][0] # Keypoints dell'immagine sorgente\n",
    "        trg_kps_gt = data['trg_kps'][0] # Keypoints ground truth dell'immagine target\n",
    "\n",
    "        pck_threshold = data['pck_threshold']\n",
    "        \n",
    "        for n_keypoint, keypoint_src in enumerate(kps_list_src):\n",
    "\n",
    "            x_pixel_src = int(keypoint_src[0].item())\n",
    "            y_pixel_src = int(keypoint_src[1].item())\n",
    "\n",
    "            # CALCOLA L'INDICE DELLA PATCH nell'immagine sorgente\n",
    "            x_patch_src = x_pixel_src // patch_size\n",
    "            y_patch_src = y_pixel_src // patch_size\n",
    "\n",
    "            patch_index_src = 1 + (y_patch_src * w_grid) + x_patch_src\n",
    "\n",
    "            # Controllo di sicurezza per non uscire dai bordi\n",
    "            max_patches_src = feats_src.shape[1]\n",
    "            if patch_index_src >= max_patches_src:\n",
    "                patch_index_src = max_patches_src - 1\n",
    "\n",
    "            # ESTRAI IL VETTORE (Feature) del keypoint sorgente\n",
    "            source_vec = feats_src[0, patch_index_src, :]\n",
    "\n",
    "            # COSINE SIMILARITY con tutte le patch del target\n",
    "            similarity_map = torch.cosine_similarity(source_vec, feats_trg[0], dim=-1)\n",
    "\n",
    "            max_sim_idx_from_map = torch.argmax(similarity_map).item()\n",
    "\n",
    "            if max_sim_idx_from_map == 0: # Se il CLS token è il più simile\n",
    "                patch_idx_0based_for_grid_calc = 0\n",
    "            else:\n",
    "                patch_idx_0based_for_grid_calc = max_sim_idx_from_map - 1\n",
    "\n",
    "            # Converti l'indice 0-based della patch visiva in coordinate (colonna, riga) \n",
    "            x_col_max_patch = patch_idx_0based_for_grid_calc % w_grid\n",
    "            y_row_max_patch = patch_idx_0based_for_grid_calc // w_grid\n",
    "\n",
    "            # Converti le coordinate della griglia in coordinate pixel predette (al centro della patch)\n",
    "            x_pred_pixel = x_col_max_patch * patch_size + (patch_size // 2)\n",
    "            y_pred_pixel = y_row_max_patch * patch_size + (patch_size // 2)\n",
    "\n",
    "            gt_x = trg_kps_gt[n_keypoint, 0].item()\n",
    "            gt_y = trg_kps_gt[n_keypoint, 1].item()\n",
    "\n",
    "            # Calcola la distanza euclidea tra predetto e GT\n",
    "            distance = math.sqrt((x_pred_pixel - gt_x)**2 + (y_pred_pixel - gt_y)**2)\n",
    "\n",
    "            # Aggiorna i contatori PCK \n",
    "            class_pck_data[category]['total_keypoints'] += 1\n",
    "            if distance <= pck_threshold:\n",
    "                class_pck_data[category]['correct_kps_0_2'] += 1\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello caricato su: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valutazione:  16%|█▋        | 1993/12234 [09:32<49:03,  3.48it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 72\u001B[39m\n\u001B[32m     69\u001B[39m \u001B[38;5;66;03m# COSINE SIMILARITY con tutte le patch del target\u001B[39;00m\n\u001B[32m     70\u001B[39m similarity_map = torch.cosine_similarity(source_vec, feats_trg[\u001B[32m0\u001B[39m], dim=-\u001B[32m1\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m72\u001B[39m max_sim_idx_from_map = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43msimilarity_map\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m max_sim_idx_from_map == \u001B[32m0\u001B[39m: \u001B[38;5;66;03m# Se il CLS token è il più simile\u001B[39;00m\n\u001B[32m     75\u001B[39m     patch_idx_0based_for_grid_calc = \u001B[32m0\u001B[39m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello caricato su: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valutazione: 100%|██████████| 12234/12234 [21:32<00:00,  9.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# CALCOLO PCK PER IMAGE\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import math \n",
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n",
    "model.eval() # il modello in modalità valutazione (congela dropout, ecc)\n",
    "\n",
    "print(f\"Modello caricato su: {device}\")\n",
    "\n",
    "# Inizializza i contatori per la metrica PCK\n",
    "correct_kps_0_05 = 0\n",
    "#correct_kps_0_1 = 0\n",
    "#correct_kps_0_2 = 0\n",
    "class_pck_data = {}\n",
    "\n",
    "with torch.no_grad(): # Disabilita il calcolo dei gradienti\n",
    "    for i, data in enumerate(tqdm(test_dataloader, desc=\"Valutazione\")):\n",
    "\n",
    "        # Retrieve the category for the current item\n",
    "        category = data['category'][0]\n",
    "\n",
    "        # Initialize category entry in class_pck_data if it doesn't exist\n",
    "        if category not in class_pck_data:\n",
    "            class_pck_data[category] = {\n",
    "                'total_image': 0,\n",
    "                'image_value_0_05': 0,\n",
    "            }\n",
    "        class_pck_data[category]['total_image'] +=1\n",
    "\n",
    "        tot_num_keypoint = 0\n",
    "        correct_keypoints = 0\n",
    "\n",
    "        src_img = data['src_img'].to(device)\n",
    "        trg_img = data['trg_img'].to(device)\n",
    "\n",
    "        outputs_src = model(pixel_values=src_img)\n",
    "        outputs_trg = model(pixel_values=trg_img)\n",
    "\n",
    "        feats_src = outputs_src.last_hidden_state\n",
    "        feats_trg = outputs_trg.last_hidden_state\n",
    "        \n",
    "        _, _, H, W = data['src_img'].shape \n",
    "\n",
    "        patch_size = 14\n",
    "        w_grid = W // patch_size # Numero di patch in orizzontale\n",
    "\n",
    "        kps_list_src = data['src_kps'][0] # Keypoints dell'immagine sorgente\n",
    "        trg_kps_gt = data['trg_kps'][0] # Keypoints ground truth dell'immagine target\n",
    "\n",
    "        pck_threshold = data['pck_threshold']\n",
    "        \n",
    "        for n_keypoint, keypoint_src in enumerate(kps_list_src):\n",
    "            \n",
    "            x_pixel_src = int(keypoint_src[0].item())\n",
    "            y_pixel_src = int(keypoint_src[1].item())\n",
    "\n",
    "            # CALCOLA L'INDICE DELLA PATCH nell'immagine sorgente\n",
    "            x_patch_src = x_pixel_src // patch_size\n",
    "            y_patch_src = y_pixel_src // patch_size\n",
    "\n",
    "            patch_index_src = 1 + (y_patch_src * w_grid) + x_patch_src\n",
    "\n",
    "            # Controllo di sicurezza per non uscire dai bordi\n",
    "            max_patches_src = feats_src.shape[1]\n",
    "            if patch_index_src >= max_patches_src:\n",
    "                patch_index_src = max_patches_src - 1\n",
    "\n",
    "            # ESTRAI IL VETTORE (Feature) del keypoint sorgente\n",
    "            source_vec = feats_src[0, patch_index_src, :]\n",
    "\n",
    "            # COSINE SIMILARITY con tutte le patch del target\n",
    "            similarity_map = torch.cosine_similarity(source_vec, feats_trg[0], dim=-1)\n",
    "\n",
    "            max_sim_idx_from_map = torch.argmax(similarity_map).item()\n",
    "\n",
    "            # Converti questo indice nel 0-based index della patch visiva per il calcolo delle coordinate\n",
    "            if max_sim_idx_from_map == 0: # Se il CLS token è il più simile\n",
    "                patch_idx_0based_for_grid_calc = 0\n",
    "            else:\n",
    "                patch_idx_0based_for_grid_calc = max_sim_idx_from_map - 1\n",
    "\n",
    "            # Converti l'indice 0-based della patch visiva in coordinate (colonna, riga) della griglia\n",
    "            x_col_max_patch = patch_idx_0based_for_grid_calc % w_grid\n",
    "            y_row_max_patch = patch_idx_0based_for_grid_calc // w_grid\n",
    "\n",
    "            # Converti le coordinate della griglia in coordinate pixel predette (al centro della patch)\n",
    "            x_pred_pixel = x_col_max_patch * patch_size + (patch_size // 2)\n",
    "            y_pred_pixel = y_row_max_patch * patch_size + (patch_size // 2)\n",
    "\n",
    "            gt_x = trg_kps_gt[n_keypoint, 0].item()\n",
    "            gt_y = trg_kps_gt[n_keypoint, 1].item()\n",
    "\n",
    "            # Calcola la distanza euclidea tra predetto e GT\n",
    "            distance = math.sqrt((x_pred_pixel - gt_x)**2 + (y_pred_pixel - gt_y)**2)\n",
    "\n",
    "            # Aggiorna i contatori PCK (CLASS-SPECIFIC)\n",
    "            tot_num_keypoint += 1\n",
    "            if distance <= pck_threshold:\n",
    "                correct_keypoints += 1\n",
    "        class_pck_data[category]['image_value_0_05'] += correct_keypoints/tot_num_keypoint\n",
    "        del outputs_src, outputs_trg, feats_src, feats_trg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PCK per Class ---\n",
      "Category: aeroplane\n",
      "  PCK@0.05: 36.34% (250.7318228598027/690)\n",
      "--------------------\n",
      "Category: bicycle\n",
      "  PCK@0.05: 19.50% (126.73318903318913/650)\n",
      "--------------------\n",
      "Category: bird\n",
      "  PCK@0.05: 31.14% (218.62080142080143/702)\n",
      "--------------------\n",
      "Category: boat\n",
      "  PCK@0.05: 16.00% (112.33492063492066/702)\n",
      "--------------------\n",
      "Category: bottle\n",
      "  PCK@0.05: 7.54% (65.61230158730164/870)\n",
      "--------------------\n",
      "Category: bus\n",
      "  PCK@0.05: 23.66% (152.33914010825796/644)\n",
      "--------------------\n",
      "Category: car\n",
      "  PCK@0.05: 19.56% (110.30733571983582/564)\n",
      "--------------------\n",
      "Category: cat\n",
      "  PCK@0.05: 42.09% (252.52851315351265/600)\n",
      "--------------------\n",
      "Category: chair\n",
      "  PCK@0.05: 6.06% (39.1277417027417/646)\n",
      "--------------------\n",
      "Category: cow\n",
      "  PCK@0.05: 23.97% (153.42627019523312/640)\n",
      "--------------------\n",
      "Category: dog\n",
      "  PCK@0.05: 28.64% (171.85326062826076/600)\n",
      "--------------------\n",
      "Category: horse\n",
      "  PCK@0.05: 7.92% (47.50466477966479/600)\n",
      "--------------------\n",
      "Category: motorbike\n",
      "  PCK@0.05: 23.94% (168.07857142857154/702)\n",
      "--------------------\n",
      "Category: person\n",
      "  PCK@0.05: 20.30% (131.95775058275058/650)\n",
      "--------------------\n",
      "Category: pottedplant\n",
      "  PCK@0.05: 4.62% (39.84761904761906/862)\n",
      "--------------------\n",
      "Category: sheep\n",
      "  PCK@0.05: 23.34% (154.9831039058983/664)\n",
      "--------------------\n",
      "Category: train\n",
      "  PCK@0.05: 24.71% (186.8401626151628/756)\n",
      "--------------------\n",
      "Category: tvmonitor\n",
      "  PCK@0.05: 6.41% (44.35695970695974/692)\n",
      "--------------------\n",
      "\n",
      "--- Overall Mean PCK ---\n",
      "Overall Mean PCK@0.05: 20.32%\n"
     ]
    }
   ],
   "source": [
    "# CALCOLO PCK PER IMAGE\n",
    "print(\"--- PCK per Class ---\")\n",
    "class_pck_0_05_list = []\n",
    "#class_pck_0_1_list = []\n",
    "#class_pck_0_2_list = []\n",
    "\n",
    "for category, data in class_pck_data.items():\n",
    "    total_image = data['total_image']\n",
    "    correct_image_0_05 = data['image_value_0_05']\n",
    "    #correct_image_0_1 = data['image_value_0_1']\n",
    "    #correct_image_0_2 = data['image_value_0_2']\n",
    "\n",
    "    pck_0_05 = (correct_image_0_05 / total_image) * 100 if total_image > 0 else 0\n",
    "    #pck_0_1 = (correct_image_0_1 / total_image) * 100 if total_image > 0 else 0\n",
    "    #pck_0_2 = (correct_image_0_2 / total_image) * 100 if total_image > 0 else 0\n",
    "\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"  PCK@0.05: {pck_0_05:.2f}% ({correct_image_0_05}/{total_image})\")\n",
    "    #print(f\"  PCK@0.1: {pck_0_1:.2f}% ({correct_image_0_1}/{total_image})\")\n",
    "    #print(f\"  PCK@0.2: {pck_0_2:.2f}% ({correct_image_0_2}/{total_image})\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    if total_image> 0: # Only add to the list if there were keypoints for this class\n",
    "        class_pck_0_05_list.append(pck_0_05)\n",
    "        #class_pck_0_1_list.append(pck_0_1)\n",
    "        #class_pck_0_2_list.append(pck_0_2)\n",
    "\n",
    "# 4. Calculate and Display Overall Mean PCK\n",
    "print(\"\\n--- Overall Mean PCK ---\")\n",
    "overall_mean_pck_0_05 = sum(class_pck_0_05_list) / len(class_pck_0_05_list) if class_pck_0_05_list else 0\n",
    "#overall_mean_pck_0_1 = sum(class_pck_0_1_list) / len(class_pck_0_1_list) if class_pck_0_1_list else 0\n",
    "#overall_mean_pck_0_2 = sum(class_pck_0_2_list) / len(class_pck_0_2_list) if class_pck_0_2_list else 0\n",
    "\n",
    "print(f\"Overall Mean PCK@0.05: {overall_mean_pck_0_05:.2f}%\")\n",
    "#print(f\"Overall Mean PCK@0.1: {overall_mean_pck_0_1:.2f}%\")\n",
    "#print(f\"Overall Mean PCK@0.2: {overall_mean_pck_0_2:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0-oTron10lL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PCK per Class ---\n",
      "Category: aeroplane\n",
      "  PCK@0.2: 60.03% (3303/5502)\n",
      "--------------------\n",
      "Category: bicycle\n",
      "  PCK@0.2: 42.55% (1645/3866)\n",
      "--------------------\n",
      "Category: bird\n",
      "  PCK@0.2: 55.15% (2398/4348)\n",
      "--------------------\n",
      "Category: boat\n",
      "  PCK@0.2: 41.55% (1407/3386)\n",
      "--------------------\n",
      "Category: bottle\n",
      "  PCK@0.2: 26.77% (1719/6422)\n",
      "--------------------\n",
      "Category: bus\n",
      "  PCK@0.2: 53.15% (2380/4478)\n",
      "--------------------\n",
      "Category: car\n",
      "  PCK@0.2: 46.94% (1686/3592)\n",
      "--------------------\n",
      "Category: cat\n",
      "  PCK@0.2: 63.42% (3931/6198)\n",
      "--------------------\n",
      "Category: chair\n",
      "  PCK@0.2: 20.37% (744/3652)\n",
      "--------------------\n",
      "Category: cow\n",
      "  PCK@0.2: 51.49% (2759/5358)\n",
      "--------------------\n",
      "Category: dog\n",
      "  PCK@0.2: 60.08% (2885/4802)\n",
      "--------------------\n",
      "Category: horse\n",
      "  PCK@0.2: 27.89% (1312/4704)\n",
      "--------------------\n",
      "Category: motorbike\n",
      "  PCK@0.2: 53.64% (1825/3402)\n",
      "--------------------\n",
      "Category: person\n",
      "  PCK@0.2: 51.86% (2228/4296)\n",
      "--------------------\n",
      "Category: pottedplant\n",
      "  PCK@0.2: 21.41% (967/4516)\n",
      "--------------------\n",
      "Category: sheep\n",
      "  PCK@0.2: 56.92% (2163/3800)\n",
      "--------------------\n",
      "Category: train\n",
      "  PCK@0.2: 62.10% (5378/8660)\n",
      "--------------------\n",
      "Category: tvmonitor\n",
      "  PCK@0.2: 29.34% (2155/7346)\n",
      "--------------------\n",
      "\n",
      "--- Overall Mean PCK ---\n",
      "Overall Mean PCK@0.2: 45.82%\n"
     ]
    }
   ],
   "source": [
    "#PCK per point\n",
    "print(\"--- PCK per Class ---\")\n",
    "#class_pck_0_05_list = []\n",
    "#class_pck_0_1_list = []\n",
    "class_pck_0_2_list = []\n",
    "\n",
    "for category, data in class_pck_data.items():\n",
    "    total_kps = data['total_keypoints']\n",
    "    #correct_kps_0_05 = data['correct_kps_0_05']\n",
    "    #correct_kps_0_1 = data['correct_kps_0_1']\n",
    "    correct_kps_0_2 = data['correct_kps_0_2']\n",
    "\n",
    "    #pck_0_05 = (correct_kps_0_05 / total_kps) * 100 if total_kps > 0 else 0\n",
    "    #pck_0_1 = (correct_kps_0_1 / total_kps) * 100 if total_kps > 0 else 0\n",
    "    pck_0_2 = (correct_kps_0_2 / total_kps) * 100 if total_kps > 0 else 0\n",
    "\n",
    "    print(f\"Category: {category}\")\n",
    "    #print(f\"  PCK@0.05: {pck_0_05:.2f}% ({correct_kps_0_05}/{total_kps})\")\n",
    "    #print(f\"  PCK@0.1: {pck_0_1:.2f}% ({correct_kps_0_1}/{total_kps})\")\n",
    "    print(f\"  PCK@0.2: {pck_0_2:.2f}% ({correct_kps_0_2}/{total_kps})\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    if total_kps > 0: # Only add to the list if there were keypoints for this class\n",
    "        #class_pck_0_05_list.append(pck_0_05)\n",
    "        #class_pck_0_1_list.append(pck_0_1)\n",
    "        class_pck_0_2_list.append(pck_0_2)\n",
    "\n",
    "# 4. Calculate and Display Overall Mean PCK\n",
    "print(\"\\n--- Overall Mean PCK ---\")\n",
    "#overall_mean_pck_0_05 = sum(class_pck_0_05_list) / len(class_pck_0_05_list) if class_pck_0_05_list else 0\n",
    "#overall_mean_pck_0_1 = sum(class_pck_0_1_list) / len(class_pck_0_1_list) if class_pck_0_1_list else 0\n",
    "overall_mean_pck_0_2 = sum(class_pck_0_2_list) / len(class_pck_0_2_list) if class_pck_0_2_list else 0\n",
    "\n",
    "#print(f\"Overall Mean PCK@0.05: {overall_mean_pck_0_05:.2f}%\")\n",
    "#print(f\"Overall Mean PCK@0.1: {overall_mean_pck_0_1:.2f}%\")\n",
    "print(f\"Overall Mean PCK@0.2: {overall_mean_pck_0_2:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM94XQGmSqU+CbzhlwN85hS",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
