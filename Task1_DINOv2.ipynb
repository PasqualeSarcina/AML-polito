{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8AKrNt5lxaQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "zip_file_path = r'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k.zip' \n",
    "extract_dir = r'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted'\n",
    "\n",
    "# Crea la directory di estrazione se non esiste\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Estrai il file ZIP solo se esiste\n",
    "if os.path.exists(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"File '{zip_file_path}' estratto con successo nella directory '{extract_dir}'\")\n",
    "    print(f\"Contenuti della directory '{extract_dir}':\\n{os.listdir(extract_dir)}\")\n",
    "else:\n",
    "    print(f\"File zip '{zip_file_path}' non trovato. Assicurati che il dataset sia estratto in '{extract_dir}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "id": "honcpimEq_B2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset caricati correttamente.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import json\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, image_keys):\n",
    "        self.image_keys = image_keys\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        for key in self.image_keys:\n",
    "            image[key] /= 255.0\n",
    "            image[key] = self.normalize(image[key])\n",
    "        return image\n",
    "\n",
    "\n",
    "def read_img(path):\n",
    "    img = np.array(Image.open(path).convert('RGB'))\n",
    "\n",
    "    return torch.tensor(img.transpose(2, 0, 1).astype(np.float32))\n",
    "\n",
    "\n",
    "class SPairDataset(Dataset):\n",
    "    def __init__(self, pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype):\n",
    "\n",
    "        self.datatype = datatype\n",
    "        self.pck_alpha = pck_alpha\n",
    "        self.ann_files = open(os.path.join(layout_path, dataset_size, datatype + '.txt'), \"r\").read().split('\\n')\n",
    "        self.ann_files = self.ann_files[:len(self.ann_files) - 1]\n",
    "        self.pair_ann_path = pair_ann_path\n",
    "        self.image_path = image_path\n",
    "        self.categories = list(map(lambda x: os.path.basename(x), glob.glob('%s/*' % image_path)))\n",
    "        self.categories.sort()\n",
    "        self.transform = Normalize(['src_img', 'trg_img'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Recupera la riga dal file di layout\n",
    "        # Esempio: \"000001...:aeroplane\"\n",
    "        raw_line = self.ann_files[idx]\n",
    "\n",
    "        # 2. LA FIX: Sostituisci i due punti ':' con l'underscore '_'\n",
    "        # Da \"000001...:aeroplane\" diventa \"000001..._aeroplane\"\n",
    "        ann_filename = raw_line.replace(':', '_')\n",
    "\n",
    "        # 3. Aggiungi l'estensione .json\n",
    "        ann_file = ann_filename + '.json'\n",
    "\n",
    "        # 4. Costruisci il percorso completo usando self.datatype (trn/val/test)\n",
    "        # Il percorso finale sarà: .../PairAnnotation/trn/000001..._aeroplane.json\n",
    "        json_path = os.path.join(self.pair_ann_path, self.datatype, ann_file)\n",
    "\n",
    "        with open(json_path) as f:\n",
    "            annotation = json.load(f)\n",
    "\n",
    "        category = annotation['category']\n",
    "        src_img = read_img(os.path.join(self.image_path, category, annotation['src_imname']))\n",
    "        trg_img = read_img(os.path.join(self.image_path, category, annotation['trg_imname']))\n",
    "\n",
    "        trg_bbox = annotation['trg_bndbox']\n",
    "        pck_threshold = max(trg_bbox[2] - trg_bbox[0],  trg_bbox[3] - trg_bbox[1]) * self.pck_alpha\n",
    "\n",
    "        sample = {'pair_id': annotation['pair_id'],\n",
    "                  'filename': annotation['filename'],\n",
    "                  'src_imname': annotation['src_imname'],\n",
    "                  'trg_imname': annotation['trg_imname'],\n",
    "                  'src_imsize': src_img.size(),\n",
    "                  'trg_imsize': trg_img.size(),\n",
    "\n",
    "                  'src_bbox': annotation['src_bndbox'],\n",
    "                  'trg_bbox': annotation['trg_bndbox'],\n",
    "                  'category': annotation['category'],\n",
    "\n",
    "                  'src_pose': annotation['src_pose'],\n",
    "                  'trg_pose': annotation['trg_pose'],\n",
    "\n",
    "                  'src_img': src_img,\n",
    "                  'trg_img': trg_img,\n",
    "                  'src_kps': torch.tensor(annotation['src_kps']).float(),\n",
    "                  'trg_kps': torch.tensor(annotation['trg_kps']).float(),\n",
    "\n",
    "                  'mirror': annotation['mirror'],\n",
    "                  'vp_var': annotation['viewpoint_variation'],\n",
    "                  'sc_var': annotation['scale_variation'],\n",
    "                  'truncn': annotation['truncation'],\n",
    "                  'occlsn': annotation['occlusion'],\n",
    "\n",
    "                  'pck_threshold': pck_threshold}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base_dir = r\"C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted\\SPair-71k\\SPair-71k\"    \n",
    "    pair_ann_path = os.path.join(base_dir, 'PairAnnotation')\n",
    "    layout_path = os.path.join(base_dir, 'Layout')\n",
    "    image_path = os.path.join(base_dir, 'JPEGImages')\n",
    "    dataset_size = 'large'\n",
    "    pck_alpha = 0.2\n",
    "    \n",
    "    # Verifica che i percorsi esistano prima di creare il dataset\n",
    "    if os.path.exists(pair_ann_path) and os.path.exists(layout_path) and os.path.exists(image_path):\n",
    "        trn_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='trn')\n",
    "        val_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='val')\n",
    "        test_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='test')\n",
    "\n",
    "        trn_dataloader = DataLoader(trn_dataset, num_workers=0)\n",
    "        val_dataloader = DataLoader(val_dataset, num_workers=0)\n",
    "        test_dataloader = DataLoader(test_dataset, num_workers=0)\n",
    "        print(\"Dataset caricati correttamente.\")\n",
    "    else:\n",
    "        print(f\"Errore: Impossibile trovare i percorsi del dataset in '{base_dir}'.\\nVerifica l'estrazione e controlla se la struttura delle cartelle corrisponde.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "e99e7173",
    "outputId": "d4c98c11-58a0-4bbe-c75f-9339d6a62114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello caricato su: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valutazione: 100%|██████████| 12234/12234 [23:36<00:00,  8.64it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "import math \n",
    "from transformers import AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-base').to(device)\n",
    "model.eval() # il modello in modalità valutazione (congela dropout, ecc)\n",
    "\n",
    "print(f\"Modello caricato su: {device}\")\n",
    "\n",
    "# Inizializza i contatori per la metrica PCK\n",
    "total_keypoints = 0\n",
    "#correct_kps_0_05 = 0\n",
    "#correct_kps_0_1 = 0\n",
    "correct_kps_0_2 = 0\n",
    "class_pck_data = {}\n",
    "\n",
    "with torch.no_grad(): # Disabilita il calcolo dei gradienti (risparmia memoria RAM/VRAM)\n",
    "    for i, data in enumerate(tqdm(test_dataloader, desc=\"Valutazione\")):\n",
    "\n",
    "        # Retrieve the category for the current item\n",
    "        category = data['category'][0]\n",
    "\n",
    "        # Initialize category entry in class_pck_data if it doesn't exist\n",
    "        if category not in class_pck_data:\n",
    "            class_pck_data[category] = {\n",
    "                'total_keypoints': 0,\n",
    "                'correct_kps_0_2': 0\n",
    "            }\n",
    "\n",
    "        # Estraiamo le immagini sorgente e target dal dizionario\n",
    "        src_img = data['src_img'].to(device)\n",
    "        trg_img = data['trg_img'].to(device)\n",
    "\n",
    "        outputs_src = model(pixel_values=src_img)\n",
    "        outputs_trg = model(pixel_values=trg_img)\n",
    "\n",
    "        # Estrazione delle feature\n",
    "        feats_src = outputs_src.last_hidden_state\n",
    "        feats_trg = outputs_trg.last_hidden_state\n",
    "        \n",
    "        _, _, H, W = data['src_img'].shape # Dimensioni dell'immagine sorgente\n",
    "\n",
    "        patch_size = 14\n",
    "        w_grid = W // patch_size # Numero di patch in orizzontale\n",
    "\n",
    "        kps_list_src = data['src_kps'][0] # Keypoints dell'immagine sorgente\n",
    "        trg_kps_gt = data['trg_kps'][0] # Keypoints ground truth dell'immagine target\n",
    "\n",
    "        pck_threshold = data['pck_threshold']\n",
    "        \n",
    "        # Loop sui singoli keypoint\n",
    "        for n_keypoint, keypoint_src in enumerate(kps_list_src):\n",
    "\n",
    "            # A. PRENDI LE COORDINATE (Pixel) del keypoint sorgente\n",
    "            x_pixel_src = int(keypoint_src[0].item())\n",
    "            y_pixel_src = int(keypoint_src[1].item())\n",
    "\n",
    "            # B. CALCOLA L'INDICE DELLA PATCH (Matematica della griglia) nell'immagine sorgente\n",
    "            x_patch_src = x_pixel_src // patch_size\n",
    "            y_patch_src = y_pixel_src // patch_size\n",
    "\n",
    "            patch_index_src = 1 + (y_patch_src * w_grid) + x_patch_src\n",
    "\n",
    "            # Controllo di sicurezza per non uscire dai bordi\n",
    "            max_patches_src = feats_src.shape[1]\n",
    "            if patch_index_src >= max_patches_src:\n",
    "                patch_index_src = max_patches_src - 1\n",
    "\n",
    "            # C. ESTRAI IL VETTORE (Feature) del keypoint sorgente\n",
    "            source_vec = feats_src[0, patch_index_src, :]\n",
    "\n",
    "            # D. COSINE SIMILARITY con tutte le patch del target\n",
    "            similarity_map = torch.cosine_similarity(source_vec, feats_trg[0], dim=-1)\n",
    "\n",
    "            # Trova l'indice del massimo valore di somiglianza\n",
    "            max_sim_idx_from_map = torch.argmax(similarity_map).item()\n",
    "\n",
    "            # Converti questo indice nel 0-based index della patch visiva per il calcolo delle coordinate\n",
    "            if max_sim_idx_from_map == 0: # Se il CLS token è il più simile\n",
    "                patch_idx_0based_for_grid_calc = 0\n",
    "            else:\n",
    "                patch_idx_0based_for_grid_calc = max_sim_idx_from_map - 1\n",
    "\n",
    "            # Converti l'indice 0-based della patch visiva in coordinate (colonna, riga) della griglia\n",
    "            x_col_max_patch = patch_idx_0based_for_grid_calc % w_grid\n",
    "            y_row_max_patch = patch_idx_0based_for_grid_calc // w_grid\n",
    "\n",
    "            # Converti le coordinate della griglia in coordinate pixel predette (al centro della patch)\n",
    "            x_pred_pixel = x_col_max_patch * patch_size + (patch_size // 2)\n",
    "            y_pred_pixel = y_row_max_patch * patch_size + (patch_size // 2)\n",
    "\n",
    "            # E. Confronto con il Ground Truth e calcolo PCK@T\n",
    "            gt_x = trg_kps_gt[n_keypoint, 0].item()\n",
    "            gt_y = trg_kps_gt[n_keypoint, 1].item()\n",
    "\n",
    "            # Calcola la distanza euclidea tra predetto e GT\n",
    "            distance = math.sqrt((x_pred_pixel - gt_x)**2 + (y_pred_pixel - gt_y)**2)\n",
    "\n",
    "            # Aggiorna i contatori PCK (CLASS-SPECIFIC)\n",
    "            class_pck_data[category]['total_keypoints'] += 1\n",
    "            if distance <= pck_threshold:\n",
    "                class_pck_data[category]['correct_kps_0_2'] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S0-oTron10lL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PCK per Class ---\n",
      "Category: aeroplane\n",
      "  PCK@0.05: 38.22% (2103/5502)\n",
      "--------------------\n",
      "Category: bicycle\n",
      "  PCK@0.05: 22.74% (879/3866)\n",
      "--------------------\n",
      "Category: bird\n",
      "  PCK@0.05: 30.61% (1331/4348)\n",
      "--------------------\n",
      "Category: boat\n",
      "  PCK@0.05: 14.94% (506/3386)\n",
      "--------------------\n",
      "Category: bottle\n",
      "  PCK@0.05: 7.35% (472/6422)\n",
      "--------------------\n",
      "Category: bus\n",
      "  PCK@0.05: 29.32% (1313/4478)\n",
      "--------------------\n",
      "Category: car\n",
      "  PCK@0.05: 24.39% (876/3592)\n",
      "--------------------\n",
      "Category: cat\n",
      "  PCK@0.05: 42.63% (2642/6198)\n",
      "--------------------\n",
      "Category: chair\n",
      "  PCK@0.05: 6.35% (232/3652)\n",
      "--------------------\n",
      "Category: cow\n",
      "  PCK@0.05: 23.67% (1268/5358)\n",
      "--------------------\n",
      "Category: dog\n",
      "  PCK@0.05: 30.61% (1470/4802)\n",
      "--------------------\n",
      "Category: horse\n",
      "  PCK@0.05: 8.35% (393/4704)\n",
      "--------------------\n",
      "Category: motorbike\n",
      "  PCK@0.05: 25.84% (879/3402)\n",
      "--------------------\n",
      "Category: person\n",
      "  PCK@0.05: 23.23% (998/4296)\n",
      "--------------------\n",
      "Category: pottedplant\n",
      "  PCK@0.05: 4.89% (221/4516)\n",
      "--------------------\n",
      "Category: sheep\n",
      "  PCK@0.05: 24.08% (915/3800)\n",
      "--------------------\n",
      "Category: train\n",
      "  PCK@0.05: 26.07% (2258/8660)\n",
      "--------------------\n",
      "Category: tvmonitor\n",
      "  PCK@0.05: 7.00% (514/7346)\n",
      "--------------------\n",
      "\n",
      "--- Overall Mean PCK ---\n",
      "Overall Mean PCK@0.05: 21.68%\n"
     ]
    }
   ],
   "source": [
    "# 3. Calculate and Display PCK for key point per Class\n",
    "print(\"--- PCK per Class ---\")\n",
    "#class_pck_0_05_list = []\n",
    "#class_pck_0_1_list = []\n",
    "class_pck_0_2_list = []\n",
    "\n",
    "for category, data in class_pck_data.items():\n",
    "    total_kps = data['total_keypoints']\n",
    "    #correct_kps_0_05 = data['correct_kps_0_05']\n",
    "    #correct_kps_0_1 = data['correct_kps_0_1']\n",
    "    correct_kps_0_2 = data['correct_kps_0_2']\n",
    "\n",
    "    #pck_0_05 = (correct_kps_0_05 / total_kps) * 100 if total_kps > 0 else 0\n",
    "    #pck_0_1 = (correct_kps_0_1 / total_kps) * 100 if total_kps > 0 else 0\n",
    "    pck_0_2 = (correct_kps_0_2 / total_kps) * 100 if total_kps > 0 else 0\n",
    "\n",
    "    print(f\"Category: {category}\")\n",
    "    #print(f\"  PCK@0.05: {pck_0_05:.2f}% ({correct_kps_0_05}/{total_kps})\")\n",
    "    #print(f\"  PCK@0.1: {pck_0_1:.2f}% ({correct_kps_0_1}/{total_kps})\")\n",
    "    print(f\"  PCK@0.2: {pck_0_2:.2f}% ({correct_kps_0_2}/{total_kps})\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    if total_kps > 0: # Only add to the list if there were keypoints for this class\n",
    "        #class_pck_0_05_list.append(pck_0_05)\n",
    "        #class_pck_0_1_list.append(pck_0_1)\n",
    "        class_pck_0_2_list.append(pck_0_2)\n",
    "\n",
    "# 4. Calculate and Display Overall Mean PCK\n",
    "print(\"\\n--- Overall Mean PCK ---\")\n",
    "#overall_mean_pck_0_05 = sum(class_pck_0_05_list) / len(class_pck_0_05_list) if class_pck_0_05_list else 0\n",
    "#overall_mean_pck_0_1 = sum(class_pck_0_1_list) / len(class_pck_0_1_list) if class_pck_0_1_list else 0\n",
    "overall_mean_pck_0_2 = sum(class_pck_0_2_list) / len(class_pck_0_2_list) if class_pck_0_2_list else 0\n",
    "\n",
    "#print(f\"Overall Mean PCK@0.05: {overall_mean_pck_0_05:.2f}%\")\n",
    "#print(f\"Overall Mean PCK@0.1: {overall_mean_pck_0_1:.2f}%\")\n",
    "print(f\"Overall Mean PCK@0.2: {overall_mean_pck_0_2:.2f}%\")\n",
    "\n",
    "# 5. Final Task: Summarize the results\n",
    "##print(\"\\n--- Summary ---\")\n",
    "#print(\"The analysis provides detailed PCK scores for each object category at different thresholds (0.05, 0.1, 0.2).\")\n",
    "#print(\"This class-specific breakdown highlights the model's performance on various object types, indicating categories where the model performs strongly or weakly.\")\n",
    "#print(\"For instance, a low PCK score for a specific category might suggest that the model struggles with keypoint localization for objects in that category.\")\n",
    "#print(\"The overall mean PCK scores then provide a consolidated view of the model's average performance across all categories.\")\n",
    "#print(f\"The model achieved an overall mean PCK@0.05 of {overall_mean_pck_0_05:.2f}%, PCK@0.1 of {overall_mean_pck_0_1:.2f}%, and PCK@0.2 of {overall_mean_pck_0_2:.2f}%.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM94XQGmSqU+CbzhlwN85hS",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
