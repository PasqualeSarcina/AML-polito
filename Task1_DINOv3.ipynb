{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9eUxOYLyzGG1"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Task 1 — DINOv3 (FROZEN) — SPair-71k TEST\n",
        "# Baseline protocol (DIFT-style):\n",
        "# 1) Dense features from frozen backbone\n",
        "# 2) For each source keypoint: cosine sim vs ALL target patches\n",
        "# 3) Argmax -> predicted patch; output pixel = patch center\n",
        "# 4) Evaluate PCK@{0.05, 0.10, 0.20}\n",
        "#    - norm = max(width,height) of TARGET bbox (match DINOv2 baseline)\n",
        "#\n",
        "# OUTPUT:\n",
        "# - Prints GLOBAL PCK (per-image mean + per-keypoint)\n",
        "# - Prints PER-CATEGORY PCK (per-keypoint + per-image mean)\n",
        "#\n",
        "# Notes:\n",
        "# - NO CSV saving\n",
        "# - T4-safe: chunked similarity + explicit cache clearing\n",
        "# - Runs 3 configs: LastLayer, InterLayer_10, FusionMean_last4(8,9,10,11)\n",
        "# - Uses DataLoader correctly (batch_size=1 + custom collate_fn)\n",
        "# ============================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zGOzDI5zYQ1",
        "outputId": "da732b9f-e7c7-49ef-8b94-b744792764c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "from pathlib import Path\n",
        "import os, json, math, time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "SPAIR_ROOT = Path(\"/content/drive/MyDrive/AMLDataset/SPair-71k\")\n",
        "PAIR_ANN_PATH = SPAIR_ROOT / \"PairAnnotation\"\n",
        "LAYOUT_PATH   = SPAIR_ROOT / \"Layout\"\n",
        "IMAGE_PATH    = SPAIR_ROOT / \"JPEGImages\"\n",
        "assert SPAIR_ROOT.exists(), f\"SPair-71k non trovato: {SPAIR_ROOT}\"\n",
        "assert PAIR_ANN_PATH.exists() and LAYOUT_PATH.exists() and IMAGE_PATH.exists(), \"Cartelle SPair mancanti\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zx9Ao97fza4v"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Dataset\n",
        "# ----------------------------\n",
        "def read_img(image_path: str) -> torch.Tensor:\n",
        "    \"\"\"Return CHW float32 in [0..255].\"\"\"\n",
        "    img = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "    return torch.from_numpy(img.transpose(2, 0, 1)).float()\n",
        "\n",
        "class SPairDataset(Dataset):\n",
        "    def __init__(self, pair_ann_path, layout_path, image_path, dataset_size=\"large\", datatype=\"test\"):\n",
        "        self.datatype = datatype\n",
        "        self.pair_ann_path = str(pair_ann_path)\n",
        "        self.layout_path   = str(layout_path)\n",
        "        self.image_path    = str(image_path)\n",
        "\n",
        "        layout_file = os.path.join(self.layout_path, dataset_size, datatype + \".txt\")\n",
        "        with open(layout_file, \"r\") as f:\n",
        "            self.ann_files = [x for x in f.read().splitlines() if len(x) > 0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        pair_id = self.ann_files[index]\n",
        "        ann_filepath = os.path.join(self.pair_ann_path, self.datatype, pair_id + \".json\")\n",
        "        with open(ann_filepath, \"r\") as f:\n",
        "            ann = json.load(f)\n",
        "\n",
        "        category = ann[\"category\"]\n",
        "        src_img_path = os.path.join(self.image_path, category, ann[\"src_imname\"])\n",
        "        trg_img_path = os.path.join(self.image_path, category, ann[\"trg_imname\"])\n",
        "\n",
        "        return {\n",
        "            \"pair_id\": pair_id,\n",
        "            \"category\": category,\n",
        "            \"src_bbox\": ann[\"src_bndbox\"],\n",
        "            \"trg_bbox\": ann[\"trg_bndbox\"],\n",
        "            \"src_img\": read_img(src_img_path),\n",
        "            \"trg_img\": read_img(trg_img_path),\n",
        "            \"src_kps\": torch.tensor(ann[\"src_kps\"]).float(),\n",
        "            \"trg_kps\": torch.tensor(ann[\"trg_kps\"]).float(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# DataLoader (batch_size=1 + custom collate)\n",
        "# ----------------------------\n",
        "def collate_single(batch):\n",
        "    # batch is list of length batch_size; we keep sample dict as-is\n",
        "    assert len(batch) == 1\n",
        "    return batch[0]\n",
        "\n",
        "test_dataset = SPairDataset(PAIR_ANN_PATH, LAYOUT_PATH, IMAGE_PATH, dataset_size=\"large\", datatype=\"test\")\n",
        "print(\"Test pairs:\", len(test_dataset))\n",
        "\n",
        "# If Colab gives worker issues, set NUM_WORKERS=0 and PERSISTENT=False.\n",
        "NUM_WORKERS = 2\n",
        "PERSISTENT = True if NUM_WORKERS > 0 else False\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_single,\n",
        "    persistent_workers=PERSISTENT,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B263tCx7EU-n",
        "outputId": "410b4e10-d18d-45d1-aee5-7777426e63bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test pairs: 12234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlSILuNSzdgt",
        "outputId": "7d7f3a31-15d7-4ff1-eb8b-548a1c1f118c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'dinov3'...\n",
            "remote: Enumerating objects: 538, done.\u001b[K\n",
            "remote: Counting objects: 100% (363/363), done.\u001b[K\n",
            "remote: Compressing objects: 100% (264/264), done.\u001b[K\n",
            "remote: Total 538 (delta 201), reused 99 (delta 99), pack-reused 175 (from 1)\u001b[K\n",
            "Receiving objects: 100% (538/538), 9.88 MiB | 11.27 MiB/s, done.\n",
            "Resolving deltas: 100% (223/223), done.\n",
            "/content/dinov3\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Device: cuda\n",
            "Downloading: \"file:///content/drive/MyDrive/AMLDataset/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\" to /root/.cache/torch/hub/checkpoints/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 327M/327M [00:24<00:00, 13.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DINOv3 blocks: 12\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# Load DINOv3\n",
        "# ----------------------------\n",
        "%cd /content\n",
        "!test -d dinov3 || git clone https://github.com/facebookresearch/dinov3.git\n",
        "%cd /content/dinov3\n",
        "!pip -q install einops timm opencv-python torchmetrics fvcore iopath\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "DINOV3_DIR = \"/content/dinov3\"\n",
        "DINOV3_WEIGHTS = \"/content/drive/MyDrive/AMLDataset/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
        "assert os.path.exists(DINOV3_WEIGHTS), f\"Pesi DINOv3 non trovati: {DINOV3_WEIGHTS}\"\n",
        "\n",
        "dinov3 = torch.hub.load(\n",
        "    DINOV3_DIR,\n",
        "    \"dinov3_vitb16\",\n",
        "    source=\"local\",\n",
        "    weights=DINOV3_WEIGHTS,\n",
        ").eval().to(device)\n",
        "\n",
        "for p in dinov3.parameters():\n",
        "    p.requires_grad_(False)\n",
        "\n",
        "assert hasattr(dinov3, \"blocks\")\n",
        "N_BLOCKS = len(dinov3.blocks)\n",
        "print(\"DINOv3 blocks:\", N_BLOCKS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Mypr3aOdzhPC"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Preprocess & geometry\n",
        "# ----------------------------\n",
        "PATCH = 16\n",
        "mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
        "std  = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def preprocess_for_model(img_chw_0_255: torch.Tensor) -> torch.Tensor:\n",
        "    x = (img_chw_0_255 / 255.0).unsqueeze(0).to(device, non_blocking=True)\n",
        "    return (x - mean) / std\n",
        "\n",
        "def pad_to_multiple(img_chw: torch.Tensor, k: int) -> torch.Tensor:\n",
        "    C, H, W = img_chw.shape\n",
        "    new_h = int(math.ceil(H / k) * k)\n",
        "    new_w = int(math.ceil(W / k) * k)\n",
        "    pad_bottom = new_h - H\n",
        "    pad_right  = new_w - W\n",
        "    if pad_bottom == 0 and pad_right == 0:\n",
        "        return img_chw\n",
        "    return F.pad(img_chw, (0, pad_right, 0, pad_bottom), value=0.0)\n",
        "\n",
        "def safe_tokens(out):\n",
        "    if isinstance(out, (tuple, list)):\n",
        "        out = out[0]\n",
        "    if not torch.is_tensor(out) or out.ndim != 3:\n",
        "        raise RuntimeError(f\"Unexpected tokens output: {type(out)} shape={getattr(out,'shape',None)}\")\n",
        "    return out\n",
        "\n",
        "def tokens_to_featuremap(tokens_bnc: torch.Tensor, h_grid: int, w_grid: int) -> torch.Tensor:\n",
        "    tok = tokens_bnc.squeeze(0)  # [Ntok,C]\n",
        "    Npatch = h_grid * w_grid\n",
        "    if tok.shape[0] < Npatch:\n",
        "        raise RuntimeError(f\"Ntok={tok.shape[0]} < Npatch={Npatch}\")\n",
        "    patch_tok = tok[-Npatch:]    # drop CLS/register\n",
        "    Ft = patch_tok.view(h_grid, w_grid, -1)\n",
        "    return F.normalize(Ft, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2UJ8eR__1j3_"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Feature extractors\n",
        "# ----------------------------\n",
        "@torch.no_grad()\n",
        "def feat_last(img_pad_chw: torch.Tensor, hg: int, wg: int) -> torch.Tensor:\n",
        "    out = dinov3.forward_features(preprocess_for_model(img_pad_chw))\n",
        "    patch = out[\"x_norm_patchtokens\"].squeeze(0)  # [N,C]\n",
        "    if patch.shape[0] != hg * wg:\n",
        "        raise RuntimeError(f\"Patch tokens N={patch.shape[0]} != hg*wg={hg*wg}\")\n",
        "    return F.normalize(patch.view(hg, wg, -1), dim=-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def feat_inter(img_pad_chw: torch.Tensor, layer_id: int, hg: int, wg: int) -> torch.Tensor:\n",
        "    captured = {}\n",
        "    def hook(m, inp, out):\n",
        "        captured[\"t\"] = safe_tokens(out).detach()\n",
        "    h = dinov3.blocks[layer_id].register_forward_hook(hook)\n",
        "    _ = dinov3.forward_features(preprocess_for_model(img_pad_chw))\n",
        "    h.remove()\n",
        "    if \"t\" not in captured:\n",
        "        raise RuntimeError(f\"Hook failed for layer {layer_id}\")\n",
        "    return tokens_to_featuremap(captured[\"t\"], hg, wg)\n",
        "\n",
        "@torch.no_grad()\n",
        "def feat_fusion_mean(img_pad_chw: torch.Tensor, layer_ids, hg: int, wg: int) -> torch.Tensor:\n",
        "    feats = {}\n",
        "    handles = []\n",
        "    def mk_hook(lid):\n",
        "        def hook(m, inp, out):\n",
        "            feats[lid] = safe_tokens(out).detach()\n",
        "        return hook\n",
        "\n",
        "    for lid in layer_ids:\n",
        "        handles.append(dinov3.blocks[lid].register_forward_hook(mk_hook(lid)))\n",
        "\n",
        "    _ = dinov3.forward_features(preprocess_for_model(img_pad_chw))\n",
        "\n",
        "    for hh in handles:\n",
        "        hh.remove()\n",
        "\n",
        "    missing = [lid for lid in layer_ids if lid not in feats]\n",
        "    if missing:\n",
        "        raise RuntimeError(f\"Missing feats for layers: {missing}\")\n",
        "\n",
        "    fmaps = [tokens_to_featuremap(feats[lid], hg, wg) for lid in layer_ids]\n",
        "    Ft = torch.stack(fmaps, dim=0).mean(dim=0)\n",
        "    return F.normalize(Ft, dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MqBTSzGtzkoh"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Matching (chunked cosine)\n",
        "# ----------------------------\n",
        "@torch.no_grad()\n",
        "def argmax_cosine(Ft_flat: torch.Tensor, f_src: torch.Tensor, chunk: int = 4096) -> int:\n",
        "    best_val = None\n",
        "    best_idx = 0\n",
        "    N = Ft_flat.shape[0]\n",
        "    for s in range(0, N, chunk):\n",
        "        part = Ft_flat[s:s+chunk]\n",
        "        sim = (part * f_src).sum(dim=-1)\n",
        "        v, i = sim.max(dim=0)\n",
        "        v = float(v.item())\n",
        "        i = int(i.item()) + s\n",
        "        if (best_val is None) or (v > best_val):\n",
        "            best_val, best_idx = v, i\n",
        "    return best_idx\n",
        "\n",
        "@torch.no_grad()\n",
        "def match_one_pair(sample, feat_fn, sim_chunk=4096):\n",
        "    src_img, trg_img = sample[\"src_img\"], sample[\"trg_img\"]\n",
        "    src_kps, trg_kps = sample[\"src_kps\"], sample[\"trg_kps\"]\n",
        "\n",
        "    # Handle [2,K] -> [K,2]\n",
        "    if src_kps.ndim == 2 and src_kps.shape[0] == 2 and src_kps.shape[1] != 2:\n",
        "        src_kps = src_kps.t()\n",
        "    if trg_kps.ndim == 2 and trg_kps.shape[0] == 2 and trg_kps.shape[1] != 2:\n",
        "        trg_kps = trg_kps.t()\n",
        "\n",
        "    _, Hs, Ws = src_img.shape\n",
        "    _, Ht, Wt = trg_img.shape\n",
        "\n",
        "    src_pad = pad_to_multiple(src_img, PATCH)\n",
        "    trg_pad = pad_to_multiple(trg_img, PATCH)\n",
        "\n",
        "    hg_s, wg_s = src_pad.shape[1] // PATCH, src_pad.shape[2] // PATCH\n",
        "    hg_t, wg_t = trg_pad.shape[1] // PATCH, trg_pad.shape[2] // PATCH\n",
        "\n",
        "    Fs = feat_fn(src_pad, hg_s, wg_s)\n",
        "    Ft = feat_fn(trg_pad, hg_t, wg_t)\n",
        "    Ft_flat = Ft.view(-1, Ft.shape[-1])\n",
        "\n",
        "    preds, gts = [], []\n",
        "    for sp, gt in zip(src_kps, trg_kps):\n",
        "        if torch.isnan(sp).any() or torch.isnan(gt).any():\n",
        "            continue\n",
        "        if (sp[0] < 0) or (sp[1] < 0) or (gt[0] < 0) or (gt[1] < 0):\n",
        "            continue\n",
        "\n",
        "        x_src, y_src = float(sp[0].item()), float(sp[1].item())\n",
        "        x_gt,  y_gt  = float(gt[0].item()), float(gt[1].item())\n",
        "\n",
        "        if not (0.0 <= x_src < Ws and 0.0 <= y_src < Hs):\n",
        "            continue\n",
        "        if not (0.0 <= x_gt  < Wt and 0.0 <= y_gt  < Ht):\n",
        "            continue\n",
        "\n",
        "        jsrc = min(int(x_src) // PATCH, wg_s - 1)\n",
        "        isrc = min(int(y_src) // PATCH, hg_s - 1)\n",
        "\n",
        "        f_src = Fs[isrc, jsrc]\n",
        "        best = argmax_cosine(Ft_flat, f_src, chunk=sim_chunk)\n",
        "\n",
        "        it = best // wg_t\n",
        "        jt = best %  wg_t\n",
        "        x_pred = jt * PATCH + (PATCH / 2.0)\n",
        "        y_pred = it * PATCH + (PATCH / 2.0)\n",
        "\n",
        "        preds.append((x_pred, y_pred))\n",
        "        gts.append((x_gt, y_gt))\n",
        "\n",
        "    # Free GPU memory aggressively\n",
        "    del Fs, Ft, Ft_flat\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    if len(preds) == 0:\n",
        "        return torch.zeros((0,2)), torch.zeros((0,2))\n",
        "    return torch.tensor(preds, dtype=torch.float32), torch.tensor(gts, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Dq7VQjqdzoW2"
      },
      "outputs": [],
      "source": [
        "# ----------------------------\n",
        "# Evaluation using DataLoader (global + per-category, per-kp and per-img)\n",
        "# ----------------------------\n",
        "def evaluate_loader(name, feat_fn, loader, max_pairs=None, sim_chunk=4096):\n",
        "    thresholds = (0.05, 0.10, 0.20)\n",
        "\n",
        "    global_correct = {T: 0.0 for T in thresholds}\n",
        "    global_total_kp = 0.0\n",
        "    all_pck_img = {T: [] for T in thresholds}\n",
        "\n",
        "    per_cat_correct = {}\n",
        "    per_cat_total_kp = {}\n",
        "    per_cat_pck_img = {}\n",
        "\n",
        "    n_seen = 0\n",
        "    for sample in loader:\n",
        "        if max_pairs is not None and n_seen >= int(max_pairs):\n",
        "            break\n",
        "\n",
        "        n_seen += 1\n",
        "        if n_seen % 100 == 0:\n",
        "            print(f\"[{name}] {n_seen}\")\n",
        "\n",
        "        cat = sample[\"category\"]\n",
        "        if cat not in per_cat_correct:\n",
        "            per_cat_correct[cat] = {T: 0.0 for T in thresholds}\n",
        "            per_cat_total_kp[cat] = 0.0\n",
        "            per_cat_pck_img[cat] = {T: [] for T in thresholds}\n",
        "\n",
        "        pred, gt = match_one_pair(sample, feat_fn, sim_chunk=sim_chunk)\n",
        "        if pred.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        x0, y0, x1, y1 = map(float, sample[\"trg_bbox\"])\n",
        "        norm = max(x1 - x0, y1 - y0)\n",
        "        if norm <= 1e-6:\n",
        "            continue\n",
        "\n",
        "        dists = torch.linalg.norm(pred - gt, dim=1)\n",
        "        N = float(dists.numel())\n",
        "        if N <= 0:\n",
        "            continue\n",
        "\n",
        "        global_total_kp += N\n",
        "        per_cat_total_kp[cat] += N\n",
        "\n",
        "        for T in thresholds:\n",
        "            thr = T * norm\n",
        "            correct = float((dists <= thr).float().sum().item())\n",
        "            pck_img = correct / N\n",
        "\n",
        "            global_correct[T] += correct\n",
        "            per_cat_correct[cat][T] += correct\n",
        "\n",
        "            all_pck_img[T].append(pck_img)\n",
        "            per_cat_pck_img[cat][T].append(pck_img)\n",
        "\n",
        "    mean_pck_img = {T: float(np.mean(all_pck_img[T])) if len(all_pck_img[T]) else 0.0 for T in thresholds}\n",
        "    global_pck_kp = {T: float(global_correct[T] / max(global_total_kp, 1.0)) for T in thresholds}\n",
        "\n",
        "    per_cat_pck_kp = {}\n",
        "    per_cat_mean_pck_img = {}\n",
        "    for cat in per_cat_correct:\n",
        "        per_cat_pck_kp[cat] = {T: float(per_cat_correct[cat][T] / max(per_cat_total_kp[cat], 1.0)) for T in thresholds}\n",
        "        per_cat_mean_pck_img[cat] = {T: float(np.mean(per_cat_pck_img[cat][T])) if len(per_cat_pck_img[cat][T]) else 0.0 for T in thresholds}\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"n_pairs_run\": n_seen,\n",
        "        \"mean_pck_per_img\": mean_pck_img,\n",
        "        \"global_pck_per_kp\": global_pck_kp,\n",
        "        \"per_cat_pck_per_kp\": per_cat_pck_kp,\n",
        "        \"per_cat_mean_pck_per_img\": per_cat_mean_pck_img,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Printing helpers\n",
        "# ----------------------------\n",
        "def print_global_report(r):\n",
        "    thresholds = (0.05, 0.10, 0.20)\n",
        "    print(\"\\n================ TASK 1 REPORT ================\")\n",
        "    print(\"Config:\", r[\"name\"])\n",
        "    print(\"Pairs run:\", r[\"n_pairs_run\"])\n",
        "\n",
        "    print(\"\\nGlobal PCK (per-image mean):\")\n",
        "    for T in thresholds:\n",
        "        print(f\"  PCK@{T:.2f}: {100.0*r['mean_pck_per_img'][T]:.2f}%\")\n",
        "\n",
        "    print(\"\\nGlobal PCK (per-keypoint):\")\n",
        "    for T in thresholds:\n",
        "        print(f\"  PCK@{T:.2f}: {100.0*r['global_pck_per_kp'][T]:.2f}%\")\n",
        "\n",
        "def print_per_category_table(r):\n",
        "    thresholds = (0.05, 0.10, 0.20)\n",
        "    cats = sorted(r[\"per_cat_pck_per_kp\"].keys())\n",
        "\n",
        "    print(\"\\n================ PER-CATEGORY RESULTS ================\")\n",
        "    print(\"Category\".ljust(15), end=\"\")\n",
        "    for T in thresholds:\n",
        "        print(f\" KP@{T:.2f}\".rjust(9), end=\"\")\n",
        "    for T in thresholds:\n",
        "        print(f\" IMG@{T:.2f}\".rjust(9), end=\"\")\n",
        "    print()\n",
        "    print(\"-\" * (15 + 9*6))\n",
        "\n",
        "    for cat in cats:\n",
        "        print(cat.ljust(15), end=\"\")\n",
        "        for T in thresholds:\n",
        "            v = 100.0 * r[\"per_cat_pck_per_kp\"][cat][T]\n",
        "            print(f\"{v:8.2f}%\".rjust(9), end=\"\")\n",
        "        for T in thresholds:\n",
        "            v = 100.0 * r[\"per_cat_mean_pck_per_img\"][cat][T]\n",
        "            print(f\"{v:8.2f}%\".rjust(9), end=\"\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "rDdrCTwBFGs1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXNYKeuzzuz6",
        "outputId": "a9b87633-7e97-4d1e-e3d5-a860ae065079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LastLayer] 100\n",
            "[LastLayer] 200\n",
            "[LastLayer] 300\n",
            "[LastLayer] 400\n",
            "[LastLayer] 500\n",
            "[LastLayer] 600\n",
            "[LastLayer] 700\n",
            "[LastLayer] 800\n",
            "[LastLayer] 900\n",
            "[LastLayer] 1000\n",
            "[LastLayer] 1100\n",
            "[LastLayer] 1200\n",
            "[LastLayer] 1300\n",
            "[LastLayer] 1400\n",
            "[LastLayer] 1500\n",
            "[LastLayer] 1600\n",
            "[LastLayer] 1700\n",
            "[LastLayer] 1800\n",
            "[LastLayer] 1900\n",
            "[LastLayer] 2000\n",
            "[LastLayer] 2100\n",
            "[LastLayer] 2200\n",
            "[LastLayer] 2300\n",
            "[LastLayer] 2400\n",
            "[LastLayer] 2500\n",
            "[LastLayer] 2600\n",
            "[LastLayer] 2700\n",
            "[LastLayer] 2800\n",
            "[LastLayer] 2900\n",
            "[LastLayer] 3000\n",
            "[LastLayer] 3100\n",
            "[LastLayer] 3200\n",
            "[LastLayer] 3300\n",
            "[LastLayer] 3400\n",
            "[LastLayer] 3500\n",
            "[LastLayer] 3600\n",
            "[LastLayer] 3700\n",
            "[LastLayer] 3800\n",
            "[LastLayer] 3900\n",
            "[LastLayer] 4000\n",
            "[LastLayer] 4100\n",
            "[LastLayer] 4200\n",
            "[LastLayer] 4300\n",
            "[LastLayer] 4400\n",
            "[LastLayer] 4500\n",
            "[LastLayer] 4600\n",
            "[LastLayer] 4700\n",
            "[LastLayer] 4800\n",
            "[LastLayer] 4900\n",
            "[LastLayer] 5000\n",
            "[LastLayer] 5100\n",
            "[LastLayer] 5200\n",
            "[LastLayer] 5300\n",
            "[LastLayer] 5400\n",
            "[LastLayer] 5500\n",
            "[LastLayer] 5600\n",
            "[LastLayer] 5700\n",
            "[LastLayer] 5800\n",
            "[LastLayer] 5900\n",
            "[LastLayer] 6000\n",
            "[LastLayer] 6100\n",
            "[LastLayer] 6200\n",
            "[LastLayer] 6300\n",
            "[LastLayer] 6400\n",
            "[LastLayer] 6500\n",
            "[LastLayer] 6600\n",
            "[LastLayer] 6700\n",
            "[LastLayer] 6800\n",
            "[LastLayer] 6900\n",
            "[LastLayer] 7000\n",
            "[LastLayer] 7100\n",
            "[LastLayer] 7200\n",
            "[LastLayer] 7300\n",
            "[LastLayer] 7400\n",
            "[LastLayer] 7500\n",
            "[LastLayer] 7600\n",
            "[LastLayer] 7700\n",
            "[LastLayer] 7800\n",
            "[LastLayer] 7900\n",
            "[LastLayer] 8000\n",
            "[LastLayer] 8100\n",
            "[LastLayer] 8200\n",
            "[LastLayer] 8300\n",
            "[LastLayer] 8400\n",
            "[LastLayer] 8500\n",
            "[LastLayer] 8600\n",
            "[LastLayer] 8700\n",
            "[LastLayer] 8800\n",
            "[LastLayer] 8900\n",
            "[LastLayer] 9000\n",
            "[LastLayer] 9100\n",
            "[LastLayer] 9200\n",
            "[LastLayer] 9300\n",
            "[LastLayer] 9400\n",
            "[LastLayer] 9500\n",
            "[LastLayer] 9600\n",
            "[LastLayer] 9700\n",
            "[LastLayer] 9800\n",
            "[LastLayer] 9900\n",
            "[LastLayer] 10000\n",
            "[LastLayer] 10100\n",
            "[LastLayer] 10200\n",
            "[LastLayer] 10300\n",
            "[LastLayer] 10400\n",
            "[LastLayer] 10500\n",
            "[LastLayer] 10600\n",
            "[LastLayer] 10700\n",
            "[LastLayer] 10800\n",
            "[LastLayer] 10900\n",
            "[LastLayer] 11000\n",
            "[LastLayer] 11100\n",
            "[LastLayer] 11200\n",
            "[LastLayer] 11300\n",
            "[LastLayer] 11400\n",
            "[LastLayer] 11500\n",
            "[LastLayer] 11600\n",
            "[LastLayer] 11700\n",
            "[LastLayer] 11800\n",
            "[LastLayer] 11900\n",
            "[LastLayer] 12000\n",
            "[LastLayer] 12100\n",
            "[LastLayer] 12200\n",
            "\n",
            "================ TASK 1 REPORT ================\n",
            "Config: LastLayer\n",
            "Pairs run: 12234\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 29.31%\n",
            "  PCK@0.10: 46.44%\n",
            "  PCK@0.20: 62.07%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 33.27%\n",
            "  PCK@0.10: 51.54%\n",
            "  PCK@0.20: 67.35%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "Category         KP@0.05  KP@0.10  KP@0.20 IMG@0.05 IMG@0.10 IMG@0.20\n",
            "---------------------------------------------------------------------\n",
            "aeroplane         38.04%   52.74%   65.87%   36.19%   50.77%   63.72%\n",
            "bicycle           28.56%   47.39%   63.35%   26.55%   43.87%   59.19%\n",
            "bird              49.08%   73.32%   85.46%   48.57%   72.10%   84.44%\n",
            "boat              13.76%   27.73%   42.56%   12.21%   24.58%   37.41%\n",
            "bottle            28.82%   46.09%   61.82%   27.38%   44.80%   60.90%\n",
            "bus               33.10%   47.92%   58.87%   25.25%   36.55%   45.96%\n",
            "car               30.90%   46.99%   59.52%   22.50%   35.16%   47.80%\n",
            "cat               56.39%   69.83%   81.22%   56.33%   69.88%   81.38%\n",
            "chair             21.58%   34.99%   49.26%   19.13%   32.63%   46.15%\n",
            "cow               44.81%   64.99%   79.79%   41.20%   61.50%   77.09%\n",
            "dog               35.05%   53.46%   69.60%   32.81%   51.50%   68.38%\n",
            "horse             31.38%   50.21%   69.07%   29.89%   48.38%   67.04%\n",
            "motorbike         25.84%   46.27%   64.93%   24.43%   44.38%   63.12%\n",
            "person            34.68%   55.82%   71.28%   32.43%   51.87%   67.55%\n",
            "pottedplant       18.49%   37.09%   58.72%   16.56%   34.13%   55.69%\n",
            "sheep             27.79%   46.71%   66.32%   25.56%   42.05%   60.48%\n",
            "train             36.25%   55.92%   72.73%   33.35%   52.55%   70.29%\n",
            "tvmonitor         25.88%   48.83%   69.10%   23.26%   43.49%   62.29%\n",
            "\n",
            "Minutes: 91.83907371759415\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# LastLayer\n",
        "# ----------------------------\n",
        "SIM_CHUNK = 4096   # if OOM: 2048\n",
        "MAX_PAIRS = None   # full test (use 200 for debug)\n",
        "\n",
        "t0 = time.time()\n",
        "r_last = evaluate_loader(\n",
        "    name=\"LastLayer\",\n",
        "    feat_fn=lambda img,hg,wg: feat_last(img,hg,wg),\n",
        "    loader=test_loader,\n",
        "    max_pairs=MAX_PAIRS,\n",
        "    sim_chunk=SIM_CHUNK,\n",
        ")\n",
        "print_global_report(r_last)\n",
        "print_per_category_table(r_last)\n",
        "print(\"\\nMinutes:\", (time.time() - t0) / 60.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUak_Zq1qrYg",
        "outputId": "9ced2c8e-597a-4b27-8c4a-4b7907ca4039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 31 17:53:11 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   78C    P0             34W /   70W |     514MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuiJiixbL1F5",
        "outputId": "23f15b32-f3b9-4360-862c-e813f3c6941a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[InterLayer_10] 100\n",
            "[InterLayer_10] 200\n",
            "[InterLayer_10] 300\n",
            "[InterLayer_10] 400\n",
            "[InterLayer_10] 500\n",
            "[InterLayer_10] 600\n",
            "[InterLayer_10] 700\n",
            "[InterLayer_10] 800\n",
            "[InterLayer_10] 900\n",
            "[InterLayer_10] 1000\n",
            "[InterLayer_10] 1100\n",
            "[InterLayer_10] 1200\n",
            "[InterLayer_10] 1300\n",
            "[InterLayer_10] 1400\n",
            "[InterLayer_10] 1500\n",
            "[InterLayer_10] 1600\n",
            "[InterLayer_10] 1700\n",
            "[InterLayer_10] 1800\n",
            "[InterLayer_10] 1900\n",
            "[InterLayer_10] 2000\n",
            "[InterLayer_10] 2100\n",
            "[InterLayer_10] 2200\n",
            "[InterLayer_10] 2300\n",
            "[InterLayer_10] 2400\n",
            "[InterLayer_10] 2500\n",
            "[InterLayer_10] 2600\n",
            "[InterLayer_10] 2700\n",
            "[InterLayer_10] 2800\n",
            "[InterLayer_10] 2900\n",
            "[InterLayer_10] 3000\n",
            "[InterLayer_10] 3100\n",
            "[InterLayer_10] 3200\n",
            "[InterLayer_10] 3300\n",
            "[InterLayer_10] 3400\n",
            "[InterLayer_10] 3500\n",
            "[InterLayer_10] 3600\n",
            "[InterLayer_10] 3700\n",
            "[InterLayer_10] 3800\n",
            "[InterLayer_10] 3900\n",
            "[InterLayer_10] 4000\n",
            "[InterLayer_10] 4100\n",
            "[InterLayer_10] 4200\n",
            "[InterLayer_10] 4300\n",
            "[InterLayer_10] 4400\n",
            "[InterLayer_10] 4500\n",
            "[InterLayer_10] 4600\n",
            "[InterLayer_10] 4700\n",
            "[InterLayer_10] 4800\n",
            "[InterLayer_10] 4900\n",
            "[InterLayer_10] 5000\n",
            "[InterLayer_10] 5100\n",
            "[InterLayer_10] 5200\n",
            "[InterLayer_10] 5300\n",
            "[InterLayer_10] 5400\n",
            "[InterLayer_10] 5500\n",
            "[InterLayer_10] 5600\n",
            "[InterLayer_10] 5700\n",
            "[InterLayer_10] 5800\n",
            "[InterLayer_10] 5900\n",
            "[InterLayer_10] 6000\n",
            "[InterLayer_10] 6100\n",
            "[InterLayer_10] 6200\n",
            "[InterLayer_10] 6300\n",
            "[InterLayer_10] 6400\n",
            "[InterLayer_10] 6500\n",
            "[InterLayer_10] 6600\n",
            "[InterLayer_10] 6700\n",
            "[InterLayer_10] 6800\n",
            "[InterLayer_10] 6900\n",
            "[InterLayer_10] 7000\n",
            "[InterLayer_10] 7100\n",
            "[InterLayer_10] 7200\n",
            "[InterLayer_10] 7300\n",
            "[InterLayer_10] 7400\n",
            "[InterLayer_10] 7500\n",
            "[InterLayer_10] 7600\n",
            "[InterLayer_10] 7700\n",
            "[InterLayer_10] 7800\n",
            "[InterLayer_10] 7900\n",
            "[InterLayer_10] 8000\n",
            "[InterLayer_10] 8100\n",
            "[InterLayer_10] 8200\n",
            "[InterLayer_10] 8300\n",
            "[InterLayer_10] 8400\n",
            "[InterLayer_10] 8500\n",
            "[InterLayer_10] 8600\n",
            "[InterLayer_10] 8700\n",
            "[InterLayer_10] 8800\n",
            "[InterLayer_10] 8900\n",
            "[InterLayer_10] 9000\n",
            "[InterLayer_10] 9100\n",
            "[InterLayer_10] 9200\n",
            "[InterLayer_10] 9300\n",
            "[InterLayer_10] 9400\n",
            "[InterLayer_10] 9500\n",
            "[InterLayer_10] 9600\n",
            "[InterLayer_10] 9700\n",
            "[InterLayer_10] 9800\n",
            "[InterLayer_10] 9900\n",
            "[InterLayer_10] 10000\n",
            "[InterLayer_10] 10100\n",
            "[InterLayer_10] 10200\n",
            "[InterLayer_10] 10300\n",
            "[InterLayer_10] 10400\n",
            "[InterLayer_10] 10500\n",
            "[InterLayer_10] 10600\n",
            "[InterLayer_10] 10700\n",
            "[InterLayer_10] 10800\n",
            "[InterLayer_10] 10900\n",
            "[InterLayer_10] 11000\n",
            "[InterLayer_10] 11100\n",
            "[InterLayer_10] 11200\n",
            "[InterLayer_10] 11300\n",
            "[InterLayer_10] 11400\n",
            "[InterLayer_10] 11500\n",
            "[InterLayer_10] 11600\n",
            "[InterLayer_10] 11700\n",
            "[InterLayer_10] 11800\n",
            "[InterLayer_10] 11900\n",
            "[InterLayer_10] 12000\n",
            "[InterLayer_10] 12100\n",
            "[InterLayer_10] 12200\n",
            "\n",
            "================ TASK 1 REPORT ================\n",
            "Config: InterLayer_10\n",
            "Pairs run: 12234\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 30.06%\n",
            "  PCK@0.10: 47.85%\n",
            "  PCK@0.20: 64.83%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 32.98%\n",
            "  PCK@0.10: 51.55%\n",
            "  PCK@0.20: 68.41%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "Category         KP@0.05  KP@0.10  KP@0.20 IMG@0.05 IMG@0.10 IMG@0.20\n",
            "---------------------------------------------------------------------\n",
            "aeroplane         44.86%   61.54%   76.26%   43.22%   59.80%   74.51%\n",
            "bicycle           31.25%   51.24%   68.44%   29.45%   48.00%   64.73%\n",
            "bird              55.31%   78.84%   90.48%   54.98%   78.50%   90.02%\n",
            "boat              15.56%   31.22%   49.56%   14.62%   30.22%   47.07%\n",
            "bottle            24.40%   43.20%   61.35%   23.08%   41.80%   60.12%\n",
            "bus               31.84%   46.05%   57.50%   26.24%   38.29%   49.37%\n",
            "car               30.99%   47.97%   61.78%   25.89%   40.63%   54.78%\n",
            "cat               57.89%   71.73%   83.16%   57.93%   71.91%   83.47%\n",
            "chair             17.94%   30.42%   46.71%   16.10%   28.67%   45.03%\n",
            "cow               43.90%   63.89%   80.25%   40.82%   61.36%   78.98%\n",
            "dog               37.21%   58.10%   75.07%   35.12%   56.19%   74.14%\n",
            "horse             32.97%   53.30%   73.41%   31.48%   51.29%   71.47%\n",
            "motorbike         28.81%   49.59%   69.55%   27.23%   47.81%   67.63%\n",
            "person            36.01%   57.80%   74.65%   33.88%   53.74%   71.81%\n",
            "pottedplant       15.52%   32.84%   51.64%   14.77%   31.01%   49.94%\n",
            "sheep             28.00%   46.82%   67.84%   27.10%   43.56%   63.59%\n",
            "train             32.68%   54.45%   74.13%   30.31%   51.19%   72.29%\n",
            "tvmonitor         18.53%   36.78%   55.99%   17.79%   35.34%   53.89%\n",
            "\n",
            "Minutes: 22.66454629500707\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# InterLayer_10\n",
        "# ----------------------------\n",
        "LID = 10\n",
        "t0 = time.time()\n",
        "r_inter = evaluate_loader(\n",
        "    name=f\"InterLayer_{LID:02d}\",\n",
        "    feat_fn=lambda img,hg,wg: feat_inter(img, LID, hg, wg),\n",
        "    loader=test_loader,\n",
        "    max_pairs=MAX_PAIRS,\n",
        "    sim_chunk=SIM_CHUNK,\n",
        ")\n",
        "print_global_report(r_inter)\n",
        "print_per_category_table(r_inter)\n",
        "print(\"\\nMinutes:\", (time.time() - t0) / 60.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSudGQk5w3CL",
        "outputId": "bee13cc8-1575-4dac-b8e2-6ec1c035d8ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 31 18:16:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0             32W /   70W |     514MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5uZ0xbkL56e",
        "outputId": "207e46e4-5ebc-4f67-9bcc-49d6e282bc0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FusionMean_last4] 100\n",
            "[FusionMean_last4] 200\n",
            "[FusionMean_last4] 300\n",
            "[FusionMean_last4] 400\n",
            "[FusionMean_last4] 500\n",
            "[FusionMean_last4] 600\n",
            "[FusionMean_last4] 700\n",
            "[FusionMean_last4] 800\n",
            "[FusionMean_last4] 900\n",
            "[FusionMean_last4] 1000\n",
            "[FusionMean_last4] 1100\n",
            "[FusionMean_last4] 1200\n",
            "[FusionMean_last4] 1300\n",
            "[FusionMean_last4] 1400\n",
            "[FusionMean_last4] 1500\n",
            "[FusionMean_last4] 1600\n",
            "[FusionMean_last4] 1700\n",
            "[FusionMean_last4] 1800\n",
            "[FusionMean_last4] 1900\n",
            "[FusionMean_last4] 2000\n",
            "[FusionMean_last4] 2100\n",
            "[FusionMean_last4] 2200\n",
            "[FusionMean_last4] 2300\n",
            "[FusionMean_last4] 2400\n",
            "[FusionMean_last4] 2500\n",
            "[FusionMean_last4] 2600\n",
            "[FusionMean_last4] 2700\n",
            "[FusionMean_last4] 2800\n",
            "[FusionMean_last4] 2900\n",
            "[FusionMean_last4] 3000\n",
            "[FusionMean_last4] 3100\n",
            "[FusionMean_last4] 3200\n",
            "[FusionMean_last4] 3300\n",
            "[FusionMean_last4] 3400\n",
            "[FusionMean_last4] 3500\n",
            "[FusionMean_last4] 3600\n",
            "[FusionMean_last4] 3700\n",
            "[FusionMean_last4] 3800\n",
            "[FusionMean_last4] 3900\n",
            "[FusionMean_last4] 4000\n",
            "[FusionMean_last4] 4100\n",
            "[FusionMean_last4] 4200\n",
            "[FusionMean_last4] 4300\n",
            "[FusionMean_last4] 4400\n",
            "[FusionMean_last4] 4500\n",
            "[FusionMean_last4] 4600\n",
            "[FusionMean_last4] 4700\n",
            "[FusionMean_last4] 4800\n",
            "[FusionMean_last4] 4900\n",
            "[FusionMean_last4] 5000\n",
            "[FusionMean_last4] 5100\n",
            "[FusionMean_last4] 5200\n",
            "[FusionMean_last4] 5300\n",
            "[FusionMean_last4] 5400\n",
            "[FusionMean_last4] 5500\n",
            "[FusionMean_last4] 5600\n",
            "[FusionMean_last4] 5700\n",
            "[FusionMean_last4] 5800\n",
            "[FusionMean_last4] 5900\n",
            "[FusionMean_last4] 6000\n",
            "[FusionMean_last4] 6100\n",
            "[FusionMean_last4] 6200\n",
            "[FusionMean_last4] 6300\n",
            "[FusionMean_last4] 6400\n",
            "[FusionMean_last4] 6500\n",
            "[FusionMean_last4] 6600\n",
            "[FusionMean_last4] 6700\n",
            "[FusionMean_last4] 6800\n",
            "[FusionMean_last4] 6900\n",
            "[FusionMean_last4] 7000\n",
            "[FusionMean_last4] 7100\n",
            "[FusionMean_last4] 7200\n",
            "[FusionMean_last4] 7300\n",
            "[FusionMean_last4] 7400\n",
            "[FusionMean_last4] 7500\n",
            "[FusionMean_last4] 7600\n",
            "[FusionMean_last4] 7700\n",
            "[FusionMean_last4] 7800\n",
            "[FusionMean_last4] 7900\n",
            "[FusionMean_last4] 8000\n",
            "[FusionMean_last4] 8100\n",
            "[FusionMean_last4] 8200\n",
            "[FusionMean_last4] 8300\n",
            "[FusionMean_last4] 8400\n",
            "[FusionMean_last4] 8500\n",
            "[FusionMean_last4] 8600\n",
            "[FusionMean_last4] 8700\n",
            "[FusionMean_last4] 8800\n",
            "[FusionMean_last4] 8900\n",
            "[FusionMean_last4] 9000\n",
            "[FusionMean_last4] 9100\n",
            "[FusionMean_last4] 9200\n",
            "[FusionMean_last4] 9300\n",
            "[FusionMean_last4] 9400\n",
            "[FusionMean_last4] 9500\n",
            "[FusionMean_last4] 9600\n",
            "[FusionMean_last4] 9700\n",
            "[FusionMean_last4] 9800\n",
            "[FusionMean_last4] 9900\n",
            "[FusionMean_last4] 10000\n",
            "[FusionMean_last4] 10100\n",
            "[FusionMean_last4] 10200\n",
            "[FusionMean_last4] 10300\n",
            "[FusionMean_last4] 10400\n",
            "[FusionMean_last4] 10500\n",
            "[FusionMean_last4] 10600\n",
            "[FusionMean_last4] 10700\n",
            "[FusionMean_last4] 10800\n",
            "[FusionMean_last4] 10900\n",
            "[FusionMean_last4] 11000\n",
            "[FusionMean_last4] 11100\n",
            "[FusionMean_last4] 11200\n",
            "[FusionMean_last4] 11300\n",
            "[FusionMean_last4] 11400\n",
            "[FusionMean_last4] 11500\n",
            "[FusionMean_last4] 11600\n",
            "[FusionMean_last4] 11700\n",
            "[FusionMean_last4] 11800\n",
            "[FusionMean_last4] 11900\n",
            "[FusionMean_last4] 12000\n",
            "[FusionMean_last4] 12100\n",
            "[FusionMean_last4] 12200\n",
            "\n",
            "================ TASK 1 REPORT ================\n",
            "Config: FusionMean_last4\n",
            "Pairs run: 12234\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 30.22%\n",
            "  PCK@0.10: 47.58%\n",
            "  PCK@0.20: 64.07%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 33.19%\n",
            "  PCK@0.10: 51.31%\n",
            "  PCK@0.20: 67.87%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "Category         KP@0.05  KP@0.10  KP@0.20 IMG@0.05 IMG@0.10 IMG@0.20\n",
            "---------------------------------------------------------------------\n",
            "aeroplane         46.13%   61.36%   75.28%   45.48%   60.93%   74.53%\n",
            "bicycle           28.32%   47.26%   63.04%   26.36%   44.36%   59.51%\n",
            "bird              54.46%   78.45%   90.82%   53.91%   77.71%   90.11%\n",
            "boat              15.36%   30.12%   48.26%   14.52%   28.61%   45.19%\n",
            "bottle            27.83%   45.58%   61.99%   26.74%   44.50%   60.85%\n",
            "bus               31.31%   44.46%   55.92%   25.57%   36.44%   46.98%\n",
            "car               29.65%   46.24%   59.80%   24.05%   38.41%   52.27%\n",
            "cat               58.68%   71.91%   82.96%   58.83%   72.08%   83.31%\n",
            "chair             19.72%   33.76%   47.59%   17.78%   31.43%   45.26%\n",
            "cow               44.05%   63.31%   79.13%   41.45%   61.42%   78.35%\n",
            "dog               36.69%   55.50%   72.45%   34.66%   53.57%   71.37%\n",
            "horse             31.19%   51.19%   70.66%   29.77%   49.49%   69.10%\n",
            "motorbike         27.10%   45.15%   63.35%   25.69%   43.55%   61.68%\n",
            "person            36.57%   58.59%   75.40%   34.59%   55.15%   72.78%\n",
            "pottedplant       16.63%   35.39%   55.14%   15.95%   33.25%   52.98%\n",
            "sheep             29.00%   47.58%   68.68%   27.64%   43.88%   63.90%\n",
            "train             32.01%   52.51%   72.59%   29.50%   49.40%   70.50%\n",
            "tvmonitor         20.08%   40.13%   60.56%   18.82%   38.17%   58.49%\n",
            "\n",
            "Minutes: 90.95998289585114\n"
          ]
        }
      ],
      "source": [
        "# ----------------------------\n",
        "# FusionMean_last4 (8,9,10,11)\n",
        "# ----------------------------\n",
        "SIM_CHUNK = 4096   # if OOM: 2048\n",
        "MAX_PAIRS = None   # full test (use 200 for debug)\n",
        "LIDS_FUS = (8, 9, 10, 11)\n",
        "t0 = time.time()\n",
        "r_fus = evaluate_loader(\n",
        "    name=\"FusionMean_last4\",\n",
        "    feat_fn=lambda img,hg,wg: feat_fusion_mean(img, LIDS_FUS, hg, wg),\n",
        "    loader=test_loader,\n",
        "    max_pairs=MAX_PAIRS,\n",
        "    sim_chunk=SIM_CHUNK,\n",
        ")\n",
        "print_global_report(r_fus)\n",
        "print_per_category_table(r_fus)\n",
        "print(\"\\nMinutes:\", (time.time() - t0) / 60.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCG_CJBK4AWx",
        "outputId": "db6c72e8-efcc-4666-e445-45af23c35423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan  2 11:02:48 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0             26W /   70W |     514MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}