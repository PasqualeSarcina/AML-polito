{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Task 2 — DINOv3 Light Fine-tuning (Last Blocks) — SPair-71k\n",
        "# - Training supervision: keypoint -> target patch index (CrossEntropy)\n",
        "# - Evaluation: PCK@{0.05,0.10,0.20} using argmax matching (Task1-style)\n",
        "# Geometry: padding bottom/right to multiple of PATCH=16\n",
        "# - Task2-complete: LR finder + overfit sanity + sweep blocks (select on VAL), test only best\n",
        "# ============================================================\n",
        "\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BDrHQW1b_p7",
        "outputId": "4da45a92-5f4b-436e-b8cd-5029dc62c418"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan  2 19:20:36 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "from pathlib import Path\n",
        "import os, json, time, copy, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "SPAIR_ROOT = Path(\"/content/drive/MyDrive/AMLDataset/SPair-71k\")\n",
        "PAIR_ANN_PATH = SPAIR_ROOT / \"PairAnnotation\"\n",
        "LAYOUT_PATH   = SPAIR_ROOT / \"Layout\"\n",
        "IMAGE_PATH    = SPAIR_ROOT / \"JPEGImages\"\n",
        "assert SPAIR_ROOT.exists(), f\"SPair-71k non trovato: {SPAIR_ROOT}\"\n",
        "assert PAIR_ANN_PATH.exists() and LAYOUT_PATH.exists() and IMAGE_PATH.exists(), \"Cartelle SPair mancanti\"\n",
        "\n",
        "# ----------------------------\n",
        "# Setup\n",
        "# ----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "PATCH = 16  # vitb16\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKYjcJbUcDbz",
        "outputId": "486ecea0-d9a1-4e03-f0ad-b6253d2c9e8c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Utilities\n",
        "# ----------------------------\n",
        "def read_img(image_path: str) -> torch.Tensor:\n",
        "    \"\"\"CHW float in [0..255]\"\"\"\n",
        "    img = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "    return torch.from_numpy(img.transpose(2, 0, 1)).float()\n",
        "\n",
        "def normalize_img_chw_0_255(img_chw_0_255: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"CHW float [0..255] -> normalized float (ImageNet)\"\"\"\n",
        "    x = img_chw_0_255 / 255.0\n",
        "    mean = torch.tensor(IMAGENET_MEAN, device=x.device).view(3,1,1)\n",
        "    std  = torch.tensor(IMAGENET_STD,  device=x.device).view(3,1,1)\n",
        "    return (x - mean) / std\n",
        "\n",
        "def pad_to_patch_multiple(x_chw: torch.Tensor, patch=16):\n",
        "    \"\"\"Pad bottom/right with zeros so H,W multiples of patch.\"\"\"\n",
        "    C, H, W = x_chw.shape\n",
        "    H_pad = ((H + patch - 1) // patch) * patch\n",
        "    W_pad = ((W + patch - 1) // patch) * patch\n",
        "    pad_bottom = H_pad - H\n",
        "    pad_right  = W_pad - W\n",
        "    x_pad = F.pad(x_chw, (0, pad_right, 0, pad_bottom), value=0.0)\n",
        "    return x_pad, (H, W), (H_pad, W_pad)\n",
        "\n",
        "def ensure_kps_k2(kps: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Coerce keypoints to [K,2] (x,y). Accepts [K,2], [2,K], [K,3], [3,K].\n",
        "    Drops visibility if present.\n",
        "    \"\"\"\n",
        "    if kps.ndim != 2:\n",
        "        raise ValueError(f\"kps must be 2D, got {kps.shape}\")\n",
        "    if kps.shape[0] in (2,3) and kps.shape[1] not in (2,3):\n",
        "        kps = kps.t()\n",
        "    if kps.shape[1] == 3:\n",
        "        kps = kps[:, :2]\n",
        "    if kps.shape[1] != 2:\n",
        "        raise ValueError(f\"Cannot convert to [K,2], got {kps.shape}\")\n",
        "    return kps\n",
        "\n",
        "def kps_to_flat_indices(kps_k2: torch.Tensor, H_pad: int, W_pad: int, patch=16):\n",
        "    \"\"\"\n",
        "    kps_k2: [K,2] pixel coords.\n",
        "    Returns:\n",
        "      flat_idx [K] long\n",
        "      valid [K] bool (inside padded image and non-negative)\n",
        "      hg,wg\n",
        "    \"\"\"\n",
        "    x = kps_k2[:,0]\n",
        "    y = kps_k2[:,1]\n",
        "    valid = (x >= 0) & (y >= 0) & (x < W_pad) & (y < H_pad)\n",
        "\n",
        "    hg = H_pad // patch\n",
        "    wg = W_pad // patch\n",
        "\n",
        "    ix = torch.clamp((x // patch).long(), 0, wg - 1)\n",
        "    iy = torch.clamp((y // patch).long(), 0, hg - 1)\n",
        "    flat = iy * wg + ix\n",
        "    return flat, valid, hg, wg\n",
        "\n",
        "def find_layout_file(layout_root: Path, dataset_size: str, split: str):\n",
        "    \"\"\"\n",
        "    Robustly find Layout/<size>/<split>.txt, allowing small naming variants.\n",
        "    \"\"\"\n",
        "    folder = layout_root / dataset_size\n",
        "    candidates = [\n",
        "        folder / f\"{split}.txt\",\n",
        "        folder / f\"{split}n.txt\",   # e.g., trnn/valn\n",
        "        folder / f\"{split}_.txt\"\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if c.exists():\n",
        "            return c\n",
        "    for f in folder.glob(\"*.txt\"):\n",
        "        if f.stem.lower() == split.lower():\n",
        "            return f\n",
        "    raise FileNotFoundError(f\"Nessun layout file trovato per split='{split}' in {folder}.\")"
      ],
      "metadata": {
        "id": "Q-nBKJP7cGJc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Dataset\n",
        "# ----------------------------\n",
        "class SPairDataset(Dataset):\n",
        "    def __init__(self, pair_ann_path, layout_path, image_path,\n",
        "                 dataset_size=\"large\", split=\"trn\", max_retries=3):\n",
        "        self.split = split\n",
        "        self.pair_ann_path = Path(pair_ann_path)\n",
        "        self.layout_path   = Path(layout_path)\n",
        "        self.image_path    = Path(image_path)\n",
        "        self.max_retries   = int(max_retries)\n",
        "\n",
        "        layout_file = find_layout_file(self.layout_path, dataset_size, split)\n",
        "        with open(layout_file, \"r\") as f:\n",
        "            self.ann_files = [x.strip() for x in f.read().splitlines() if len(x.strip()) > 0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        pair_id = self.ann_files[index]\n",
        "        ann_filepath = self.pair_ann_path / self.split / f\"{pair_id}.json\"\n",
        "\n",
        "        last_err = None\n",
        "        for t in range(self.max_retries):\n",
        "            try:\n",
        "                with open(ann_filepath, \"r\") as f:\n",
        "                    ann = json.load(f)\n",
        "                break\n",
        "            except OSError as e:\n",
        "                last_err = e\n",
        "                time.sleep(0.2 * (t + 1))\n",
        "        else:\n",
        "            raise last_err\n",
        "\n",
        "        category = ann[\"category\"]\n",
        "        src_img_path = self.image_path / category / ann[\"src_imname\"]\n",
        "        trg_img_path = self.image_path / category / ann[\"trg_imname\"]\n",
        "\n",
        "        src_img = read_img(str(src_img_path))  # CHW float [0..255]\n",
        "        trg_img = read_img(str(trg_img_path))\n",
        "\n",
        "        # keypoints -> torch float [K,2]\n",
        "        src_kps = ensure_kps_k2(torch.tensor(ann[\"src_kps\"], dtype=torch.float32))\n",
        "        trg_kps = ensure_kps_k2(torch.tensor(ann[\"trg_kps\"], dtype=torch.float32))\n",
        "\n",
        "        # bboxes -> torch float [4] (so DataLoader collate is always [B,4])\n",
        "        src_bbox = torch.tensor(ann[\"src_bndbox\"], dtype=torch.float32).view(-1)\n",
        "        trg_bbox = torch.tensor(ann[\"trg_bndbox\"], dtype=torch.float32).view(-1)\n",
        "        if src_bbox.numel() != 4 or trg_bbox.numel() != 4:\n",
        "            raise ValueError(f\"Bad bbox size for pair_id={pair_id}: \"\n",
        "                            f\"src_bbox={src_bbox.tolist()} trg_bbox={trg_bbox.tolist()}\")\n",
        "\n",
        "        return {\n",
        "            \"pair_id\": pair_id,        # string (ok with batch_size=1)\n",
        "            \"category\": category,      # string (ok with batch_size=1)\n",
        "            \"src_bbox\": src_bbox,      # tensor [4]\n",
        "            \"trg_bbox\": trg_bbox,      # tensor [4]\n",
        "            \"src_img\": src_img,        # tensor [3,H,W]\n",
        "            \"trg_img\": trg_img,        # tensor [3,H,W]\n",
        "            \"src_kps\": src_kps,        # tensor [K,2]\n",
        "            \"trg_kps\": trg_kps,        # tensor [K,2]\n",
        "        }"
      ],
      "metadata": {
        "id": "nG4siJP_cKZW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Choose dataset size here\n",
        "# ----------------------------\n",
        "DATASET_SIZE = \"small\"   # <-- set \"small\" or \"large\"\n",
        "print(\"DATASET_SIZE:\", DATASET_SIZE)\n",
        "\n",
        "train_dataset = SPairDataset(PAIR_ANN_PATH, LAYOUT_PATH, IMAGE_PATH, dataset_size=DATASET_SIZE, split=\"trn\")\n",
        "val_dataset   = SPairDataset(PAIR_ANN_PATH, LAYOUT_PATH, IMAGE_PATH, dataset_size=DATASET_SIZE, split=\"val\")\n",
        "test_dataset  = SPairDataset(PAIR_ANN_PATH, LAYOUT_PATH, IMAGE_PATH, dataset_size=DATASET_SIZE, split=\"test\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=1, shuffle=False, num_workers=0, pin_memory=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=1, shuffle=False, num_workers=0, pin_memory=False)\n",
        "\n",
        "print(\"Train pairs:\", len(train_dataset))\n",
        "print(\"Val   pairs:\", len(val_dataset))\n",
        "print(\"Test  pairs:\", len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRzZYzpYkZzp",
        "outputId": "3c37c6b4-d596-40aa-db68-b153b571443b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET_SIZE: small\n",
            "Train pairs: 10652\n",
            "Val   pairs: 1070\n",
            "Test  pairs: 2438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Load DINOv3\n",
        "# ----------------------------\n",
        "%cd /content\n",
        "!test -d dinov3 || git clone https://github.com/facebookresearch/dinov3.git\n",
        "%cd /content/dinov3\n",
        "!pip -q install einops timm opencv-python torchmetrics fvcore iopath\n",
        "\n",
        "DINOV3_DIR = \"/content/dinov3\"\n",
        "DINOV3_WEIGHTS = \"/content/drive/MyDrive/AMLDataset/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
        "assert os.path.exists(DINOV3_WEIGHTS), f\"Pesi DINOv3 non trovati: {DINOV3_WEIGHTS}\"\n",
        "\n",
        "dinov3 = torch.hub.load(\n",
        "    DINOV3_DIR,\n",
        "    \"dinov3_vitb16\",\n",
        "    source=\"local\",\n",
        "    weights=DINOV3_WEIGHTS,\n",
        ").to(device)\n",
        "\n",
        "assert hasattr(dinov3, \"blocks\"), \"Model has no attribute 'blocks'—cannot unfreeze last blocks.\"\n",
        "print(\"DINOv3 blocks:\", len(dinov3.blocks))\n",
        "\n",
        "# Save pretrained snapshot (for fair comparison across settings)\n",
        "pretrained_state = copy.deepcopy(dinov3.state_dict())\n",
        "\n",
        "def restore_pretrained():\n",
        "    dinov3.load_state_dict(pretrained_state, strict=True)\n",
        "    dinov3.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9lzy9gGcOfm",
        "outputId": "6435e3f2-defd-46b4-a80f-653d357b334f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'dinov3'...\n",
            "remote: Enumerating objects: 538, done.\u001b[K\n",
            "remote: Counting objects: 100% (363/363), done.\u001b[K\n",
            "remote: Compressing objects: 100% (264/264), done.\u001b[K\n",
            "remote: Total 538 (delta 201), reused 99 (delta 99), pack-reused 175 (from 1)\u001b[K\n",
            "Receiving objects: 100% (538/538), 9.88 MiB | 19.96 MiB/s, done.\n",
            "Resolving deltas: 100% (223/223), done.\n",
            "/content/dinov3\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading: \"file:///content/drive/MyDrive/AMLDataset/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\" to /root/.cache/torch/hub/checkpoints/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 327M/327M [00:10<00:00, 33.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DINOv3 blocks: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Trainability control (unfreeze last blocks + optional final norm)\n",
        "# ----------------------------\n",
        "def set_trainable_last_blocks(model, n_last_blocks: int, train_final_norm=True):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad_(False)\n",
        "\n",
        "    if n_last_blocks > 0:\n",
        "        for b in model.blocks[-n_last_blocks:]:\n",
        "            for p in b.parameters():\n",
        "                p.requires_grad_(True)\n",
        "\n",
        "    if train_final_norm and hasattr(model, \"norm\"):\n",
        "        for p in model.norm.parameters():\n",
        "            p.requires_grad_(True)"
      ],
      "metadata": {
        "id": "yK8db_3QcRio"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Patch tokens extraction (robust + expected_n safeguard)\n",
        "# ----------------------------\n",
        "def get_patch_tokens(model, x_bchw: torch.Tensor, expected_n: int | None = None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns patch tokens [B, N, C] (no CLS).\n",
        "    \"\"\"\n",
        "    def strip_cls_if_needed(t: torch.Tensor) -> torch.Tensor:\n",
        "        if t.ndim != 3:\n",
        "            return t\n",
        "        if expected_n is None:\n",
        "            return t[:, 1:, :] if t.shape[1] > 1 else t\n",
        "        if t.shape[1] == expected_n:\n",
        "            return t\n",
        "        if t.shape[1] == expected_n + 1:\n",
        "            return t[:, 1:, :]\n",
        "        return t\n",
        "\n",
        "    if hasattr(model, \"forward_features\"):\n",
        "        out = model.forward_features(x_bchw)\n",
        "        if isinstance(out, dict):\n",
        "            for key in [\"x_norm_patchtokens\", \"x_patchtokens\", \"patchtokens\", \"x_norm\", \"x\"]:\n",
        "                if key in out and isinstance(out[key], torch.Tensor):\n",
        "                    return strip_cls_if_needed(out[key])\n",
        "        elif torch.is_tensor(out):\n",
        "            return strip_cls_if_needed(out)\n",
        "\n",
        "    out = model(x_bchw)\n",
        "    if torch.is_tensor(out):\n",
        "        return strip_cls_if_needed(out)\n",
        "\n",
        "    raise RuntimeError(\"Could not extract patch tokens from DINOv3 output.\")"
      ],
      "metadata": {
        "id": "ZBLXkccHcWVs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Training loss (Keypoint CE)\n",
        "# ----------------------------\n",
        "def kp_ce_loss(src_tok_bnc, trg_tok_bnc, src_flat_idx, trg_flat_idx, valid_mask, temp=0.1):\n",
        "    src = F.normalize(src_tok_bnc[0], dim=-1)  # [Ns,C]\n",
        "    trg = F.normalize(trg_tok_bnc[0], dim=-1)  # [Nt,C]\n",
        "\n",
        "    if valid_mask.sum() == 0:\n",
        "        return src.new_tensor(0.0), 0\n",
        "\n",
        "    src_kp = src[src_flat_idx]              # [K,C]\n",
        "    logits = (src_kp @ trg.t()) / temp      # [K,Nt]\n",
        "\n",
        "    logits_v = logits[valid_mask]\n",
        "    gt_v     = trg_flat_idx[valid_mask]\n",
        "    loss = F.cross_entropy(logits_v, gt_v)\n",
        "    return loss, int(valid_mask.sum().item())"
      ],
      "metadata": {
        "id": "-tEndQAEcZYe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Evaluation helpers\n",
        "# ----------------------------\n",
        "@torch.no_grad()\n",
        "def tokens_to_featuremap(tok_bnc, hg, wg):\n",
        "    t = tok_bnc[0]  # [N,C]\n",
        "    if t.shape[0] != hg * wg:\n",
        "        raise RuntimeError(f\"N={t.shape[0]} != hg*wg={hg*wg}\")\n",
        "    return F.normalize(t.view(hg, wg, -1), dim=-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def argmax_cosine(Ft_flat: torch.Tensor, f_src: torch.Tensor, chunk: int = 4096) -> int:\n",
        "    best_val = None\n",
        "    best_idx = 0\n",
        "    N = Ft_flat.shape[0]\n",
        "    for s in range(0, N, chunk):\n",
        "        part = Ft_flat[s:s+chunk]\n",
        "        sim = (part * f_src).sum(dim=-1)\n",
        "        v, i = sim.max(dim=0)\n",
        "        v = float(v.item())\n",
        "        i = int(i.item()) + s\n",
        "        if (best_val is None) or (v > best_val):\n",
        "            best_val, best_idx = v, i\n",
        "    return best_idx\n",
        "\n",
        "@torch.no_grad()\n",
        "def match_one_pair(sample, sim_chunk=4096):\n",
        "    dinov3.eval()  # <<< FIX: garantisce no dropout/stochasticity\n",
        "\n",
        "    src_img = sample[\"src_img\"].to(device)\n",
        "    trg_img = sample[\"trg_img\"].to(device)\n",
        "    src_kps = sample[\"src_kps\"].to(device)\n",
        "    trg_kps = sample[\"trg_kps\"].to(device)\n",
        "\n",
        "    src_x = normalize_img_chw_0_255(src_img)\n",
        "    trg_x = normalize_img_chw_0_255(trg_img)\n",
        "\n",
        "    src_pad, (Hs, Ws), (Hs_pad, Ws_pad) = pad_to_patch_multiple(src_x, PATCH)\n",
        "    trg_pad, (Ht, Wt), (Ht_pad, Wt_pad) = pad_to_patch_multiple(trg_x, PATCH)\n",
        "\n",
        "    hg_s, wg_s = Hs_pad // PATCH, Ws_pad // PATCH\n",
        "    hg_t, wg_t = Ht_pad // PATCH, Wt_pad // PATCH\n",
        "\n",
        "    Ns = hg_s * wg_s\n",
        "    Nt = hg_t * wg_t\n",
        "\n",
        "    src_tok = get_patch_tokens(dinov3, src_pad.unsqueeze(0), expected_n=Ns)\n",
        "    trg_tok = get_patch_tokens(dinov3, trg_pad.unsqueeze(0), expected_n=Nt)\n",
        "\n",
        "    Fs = tokens_to_featuremap(src_tok, hg_s, wg_s)\n",
        "    Ft = tokens_to_featuremap(trg_tok, hg_t, wg_t)\n",
        "    Ft_flat = Ft.view(-1, Ft.shape[-1])\n",
        "\n",
        "    preds, gts = [], []\n",
        "    for sp, gt in zip(src_kps, trg_kps):\n",
        "        if (sp[0] < 0) or (sp[1] < 0) or (gt[0] < 0) or (gt[1] < 0):\n",
        "            continue\n",
        "\n",
        "        x_src, y_src = float(sp[0].item()), float(sp[1].item())\n",
        "        x_gt,  y_gt  = float(gt[0].item()), float(gt[1].item())\n",
        "\n",
        "        if not (0.0 <= x_src < Ws and 0.0 <= y_src < Hs):\n",
        "            continue\n",
        "        if not (0.0 <= x_gt  < Wt and 0.0 <= y_gt  < Ht):\n",
        "            continue\n",
        "\n",
        "        jsrc = min(int(x_src) // PATCH, wg_s - 1)\n",
        "        isrc = min(int(y_src) // PATCH, hg_s - 1)\n",
        "        f_src = Fs[isrc, jsrc]\n",
        "\n",
        "        best = argmax_cosine(Ft_flat, f_src, chunk=sim_chunk)\n",
        "        it = best // wg_t\n",
        "        jt = best %  wg_t\n",
        "\n",
        "        x_pred = jt * PATCH + (PATCH / 2.0)\n",
        "        y_pred = it * PATCH + (PATCH / 2.0)\n",
        "\n",
        "        preds.append((x_pred, y_pred))\n",
        "        gts.append((x_gt, y_gt))\n",
        "\n",
        "    if len(preds) == 0:\n",
        "        return torch.zeros((0,2)), torch.zeros((0,2))\n",
        "    return torch.tensor(preds, dtype=torch.float32), torch.tensor(gts, dtype=torch.float32)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_pck_report(loader, name=\"EVAL\", max_pairs=None, sim_chunk=4096, print_per_category=True):\n",
        "    dinov3.eval()  # important: always eval during metric\n",
        "\n",
        "    thresholds = (0.05, 0.10, 0.20)\n",
        "\n",
        "    global_correct = {T: 0.0 for T in thresholds}\n",
        "    global_total_kp = 0.0\n",
        "    all_pck_img = {T: [] for T in thresholds}\n",
        "\n",
        "    cat_correct = {}\n",
        "    cat_total   = {}\n",
        "    cat_pck_img = {}\n",
        "\n",
        "    t0 = time.time()\n",
        "    pairs_seen = 0\n",
        "    pairs_used = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        if max_pairs is not None and pairs_seen >= int(max_pairs):\n",
        "            break\n",
        "        pairs_seen += 1\n",
        "\n",
        "        sample = {\n",
        "            \"src_img\": batch[\"src_img\"][0],\n",
        "            \"trg_img\": batch[\"trg_img\"][0],\n",
        "            \"src_kps\": batch[\"src_kps\"][0],\n",
        "            \"trg_kps\": batch[\"trg_kps\"][0],\n",
        "            \"category\": batch[\"category\"][0],\n",
        "            \"trg_bbox\": batch[\"trg_bbox\"][0],   # tensor [4]\n",
        "        }\n",
        "\n",
        "        pred, gt = match_one_pair(sample, sim_chunk=sim_chunk)\n",
        "        if pred.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        x0, y0, x1, y1 = sample[\"trg_bbox\"].detach().cpu().view(-1).tolist()\n",
        "        x0, y0, x1, y1 = float(x0), float(y0), float(x1), float(y1)\n",
        "        norm = max(x1 - x0, y1 - y0)\n",
        "        if norm <= 1e-6:\n",
        "            continue\n",
        "\n",
        "        dists = torch.linalg.norm(pred - gt, dim=1)\n",
        "        N = float(dists.numel())\n",
        "        if N <= 0:\n",
        "            continue\n",
        "\n",
        "        pairs_used += 1\n",
        "\n",
        "        global_total_kp += N\n",
        "        cat = sample[\"category\"]\n",
        "        cat_correct.setdefault(cat, {T: 0.0 for T in thresholds})\n",
        "        cat_total.setdefault(cat, 0.0)\n",
        "        cat_pck_img.setdefault(cat, {T: [] for T in thresholds})\n",
        "        cat_total[cat] += N\n",
        "\n",
        "        for T in thresholds:\n",
        "            thr = T * norm\n",
        "            correct = float((dists <= thr).float().sum().item())\n",
        "            pck_img = correct / N\n",
        "\n",
        "            global_correct[T] += correct\n",
        "            all_pck_img[T].append(pck_img)\n",
        "\n",
        "            cat_correct[cat][T] += correct\n",
        "            cat_pck_img[cat][T].append(pck_img)\n",
        "\n",
        "        if pairs_seen % 200 == 0:\n",
        "            print(f\"[{name}] seen={pairs_seen} used={pairs_used}\")\n",
        "\n",
        "    minutes = (time.time() - t0) / 60.0\n",
        "\n",
        "    mean_pck_img = {T: float(np.mean(all_pck_img[T])) if len(all_pck_img[T]) else 0.0 for T in thresholds}\n",
        "    global_pck_kp = {T: float(global_correct[T] / max(global_total_kp, 1.0)) for T in thresholds}\n",
        "\n",
        "    print(\"\\n\" + \"=\"*18 + f\" {name} REPORT \" + \"=\"*18)\n",
        "    print(f\"Pairs run: {pairs_used} (seen: {pairs_seen})\")\n",
        "    print(\"\\nGlobal PCK (per-image mean):\")\n",
        "    for T in thresholds:\n",
        "        print(f\"  PCK@{T:.2f}: {100.0*mean_pck_img[T]:.2f}%\")\n",
        "    print(\"\\nGlobal PCK (per-keypoint):\")\n",
        "    for T in thresholds:\n",
        "        print(f\"  PCK@{T:.2f}: {100.0*global_pck_kp[T]:.2f}%\")\n",
        "\n",
        "    per_cat_rows = []\n",
        "    if print_per_category and len(cat_total) > 0:\n",
        "        for cat in sorted(cat_total.keys()):\n",
        "            row = {\"Category\": cat}\n",
        "            for T in thresholds:\n",
        "                kp = float(cat_correct[cat][T] / max(cat_total[cat], 1.0))\n",
        "                im = float(np.mean(cat_pck_img[cat][T])) if len(cat_pck_img[cat][T]) else 0.0\n",
        "                row[f\"KP@{T:.2f}\"]  = 100.0 * kp\n",
        "                row[f\"IMG@{T:.2f}\"] = 100.0 * im\n",
        "            per_cat_rows.append(row)\n",
        "\n",
        "        df_cat = pd.DataFrame(per_cat_rows)\n",
        "        print(\"\\n\" + \"=\"*16 + \" PER-CATEGORY RESULTS \" + \"=\"*16)\n",
        "        cols = [\"Category\",\n",
        "                \"KP@0.05\",\"KP@0.10\",\"KP@0.20\",\n",
        "                \"IMG@0.05\",\"IMG@0.10\",\"IMG@0.20\"]\n",
        "        cols = [c for c in cols if c in df_cat.columns]\n",
        "        print(df_cat[cols].to_string(index=False))\n",
        "\n",
        "    print(f\"\\nMinutes: {minutes:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"pairs_seen\": pairs_seen,\n",
        "        \"pairs_run\": pairs_used,\n",
        "        \"minutes\": minutes,\n",
        "        \"global_img\": mean_pck_img,\n",
        "        \"global_kp\": global_pck_kp,\n",
        "        \"per_category\": per_cat_rows\n",
        "    }"
      ],
      "metadata": {
        "id": "5Va1TdMtcc_P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Training (steps-based) + AMP\n",
        "# ----------------------------\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "def train_steps(\n",
        "    loader,\n",
        "    n_last_blocks=1,\n",
        "    lr=1e-5,\n",
        "    weight_decay=0.05,\n",
        "    temp=0.1,\n",
        "    max_steps=2000,\n",
        "    log_every=200,\n",
        "    use_amp=True\n",
        "):\n",
        "    set_trainable_last_blocks(dinov3, n_last_blocks=n_last_blocks, train_final_norm=True)\n",
        "    dinov3.train()\n",
        "\n",
        "    params = [p for p in dinov3.parameters() if p.requires_grad]\n",
        "    n_trainable = sum(p.numel() for p in params)\n",
        "    print(f\"[train] n_last_blocks={n_last_blocks} | trainable params: {n_trainable:,}\")\n",
        "    assert n_trainable > 0, \"No trainable parameters!\"\n",
        "\n",
        "    opt = torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
        "    scaler = GradScaler(\"cuda\", enabled=(use_amp and device.type == \"cuda\"))\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_kps  = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    it = iter(loader)\n",
        "    for step in range(int(max_steps)):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "\n",
        "        src_img = batch[\"src_img\"][0].to(device)\n",
        "        trg_img = batch[\"trg_img\"][0].to(device)\n",
        "        src_kps = batch[\"src_kps\"][0].to(device)\n",
        "        trg_kps = batch[\"trg_kps\"][0].to(device)\n",
        "\n",
        "        src_x = normalize_img_chw_0_255(src_img)\n",
        "        trg_x = normalize_img_chw_0_255(trg_img)\n",
        "        src_pad, _, (Hs_pad, Ws_pad) = pad_to_patch_multiple(src_x, PATCH)\n",
        "        trg_pad, _, (Ht_pad, Wt_pad) = pad_to_patch_multiple(trg_x, PATCH)\n",
        "\n",
        "        src_flat, src_valid, hg_s, wg_s = kps_to_flat_indices(src_kps, Hs_pad, Ws_pad, PATCH)\n",
        "        trg_flat, trg_valid, hg_t, wg_t = kps_to_flat_indices(trg_kps, Ht_pad, Wt_pad, PATCH)\n",
        "        valid = src_valid & trg_valid\n",
        "\n",
        "        Ns = hg_s * wg_s\n",
        "        Nt = hg_t * wg_t\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(\"cuda\", enabled=scaler.is_enabled()):\n",
        "            src_tok = get_patch_tokens(dinov3, src_pad.unsqueeze(0), expected_n=Ns)\n",
        "            trg_tok = get_patch_tokens(dinov3, trg_pad.unsqueeze(0), expected_n=Nt)\n",
        "            loss, nvalid = kp_ce_loss(src_tok, trg_tok, src_flat, trg_flat, valid, temp=temp)\n",
        "\n",
        "        if nvalid == 0:\n",
        "            continue\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += float(loss.item()) * nvalid\n",
        "        running_kps  += nvalid\n",
        "\n",
        "        if (step + 1) % log_every == 0:\n",
        "            avg = running_loss / max(running_kps, 1)\n",
        "            dt = time.time() - t0\n",
        "            print(f\"[train] step {step+1}/{max_steps} | avg_loss {avg:.4f} | seen_kps {running_kps} | {dt:.1f}s\")\n",
        "\n",
        "    return running_loss / max(running_kps, 1)"
      ],
      "metadata": {
        "id": "_9Ak5KBnchBR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Sanity checks (optional but very useful)\n",
        "# ----------------------------\n",
        "def overfit_sanity(\n",
        "    n_last_blocks=2,\n",
        "    lr=5e-5,\n",
        "    weight_decay=0.05,   # NEW\n",
        "    temp=0.1,\n",
        "    steps=800,\n",
        "    eval_pairs=200\n",
        "):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SANITY CHECK: OVERFIT (quick)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    restore_pretrained()\n",
        "    set_trainable_last_blocks(dinov3, 0)\n",
        "    dinov3.eval()\n",
        "    base = evaluate_pck_report(val_loader, name=\"VAL (baseline, frozen)\", max_pairs=eval_pairs, print_per_category=False)\n",
        "\n",
        "    restore_pretrained()\n",
        "    avg_loss = train_steps(\n",
        "        train_loader,\n",
        "        n_last_blocks=n_last_blocks,\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,  # NEW\n",
        "        temp=temp,\n",
        "        max_steps=steps,\n",
        "        log_every=200\n",
        "    )\n",
        "\n",
        "    dinov3.eval()\n",
        "    fin = evaluate_pck_report(val_loader, name=\"VAL (after overfit)\", max_pairs=eval_pairs, print_per_category=False)\n",
        "\n",
        "    print(f\"\\n[overfit] avg_train_loss: {avg_loss:.4f}\")\n",
        "    print(f\"[overfit] baseline val KP@0.10: {100*base['global_kp'][0.10]:.2f}%  -> after: {100*fin['global_kp'][0.10]:.2f}%\")\n",
        "\n",
        "def lr_finder(\n",
        "    n_last_blocks=2,\n",
        "    lrs=(1e-6, 3e-6, 1e-5, 3e-5, 1e-4),\n",
        "    weight_decay=0.05,   # NEW\n",
        "    temp=0.1,\n",
        "    train_steps_each=300,\n",
        "    eval_pairs=300\n",
        "):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LR FINDER\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    rows = []\n",
        "    for lr in lrs:\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(f\"[lr_finder] lr={lr:g} | blocks={n_last_blocks}\")\n",
        "        print(\"-\"*60)\n",
        "\n",
        "        restore_pretrained()\n",
        "        avg_loss = train_steps(\n",
        "            train_loader,\n",
        "            n_last_blocks=n_last_blocks,\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay,  # NEW\n",
        "            temp=temp,\n",
        "            max_steps=train_steps_each,\n",
        "            log_every=200\n",
        "        )\n",
        "\n",
        "        dinov3.eval()\n",
        "        val_rep = evaluate_pck_report(val_loader, name=f\"VAL (lr={lr:g})\", max_pairs=eval_pairs, print_per_category=False)\n",
        "\n",
        "        rows.append({\n",
        "            \"lr\": lr,\n",
        "            \"n_last_blocks\": n_last_blocks,\n",
        "            \"temp\": temp,\n",
        "            \"weight_decay\": weight_decay,  # NEW (nice for logging)\n",
        "            \"train_steps\": train_steps_each,\n",
        "            \"avg_train_loss\": avg_loss,\n",
        "            \"val_kp_PCK@0.05\": 100*val_rep[\"global_kp\"][0.05],\n",
        "            \"val_kp_PCK@0.10\": 100*val_rep[\"global_kp\"][0.10],\n",
        "            \"val_kp_PCK@0.20\": 100*val_rep[\"global_kp\"][0.20],\n",
        "            \"val_img_PCK@0.05\": 100*val_rep[\"global_img\"][0.05],\n",
        "            \"val_img_PCK@0.10\": 100*val_rep[\"global_img\"][0.10],\n",
        "            \"val_img_PCK@0.20\": 100*val_rep[\"global_img\"][0.20],\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values(\"lr\").reset_index(drop=True)\n",
        "    print(\"\\n=== LR FINDER SUMMARY (choose on VAL, e.g. KP@0.10) ===\")\n",
        "    print(df.to_string(index=False))\n",
        "    return df"
      ],
      "metadata": {
        "id": "qHPqGdS8cj6c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Task2: sweep blocks, select best on VAL, test only best\n",
        "# ----------------------------\n",
        "def run_task2_sweep(\n",
        "    settings=(0,1,2,4),\n",
        "    lr=1e-5,\n",
        "    temp=0.1,\n",
        "    weight_decay=0.05,\n",
        "    train_steps_per_setting=2000,\n",
        "    val_pairs=1000,\n",
        "    test_pairs=1000,\n",
        "    compute_test_baseline=False   # <<< IMPORTANTE\n",
        "):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TASK2 SWEEP (select best on VAL; test only best)\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # ---------- BASELINE (VAL ONLY) ----------\n",
        "    restore_pretrained()\n",
        "    set_trainable_last_blocks(dinov3, 0)\n",
        "    dinov3.eval()\n",
        "\n",
        "    base_val = evaluate_pck_report(\n",
        "        val_loader,\n",
        "        name=\"VAL BASELINE (frozen)\",\n",
        "        max_pairs=val_pairs,\n",
        "        print_per_category=True\n",
        "    )\n",
        "\n",
        "    base_test = None\n",
        "    if compute_test_baseline:\n",
        "        base_test = evaluate_pck_report(\n",
        "            test_loader,\n",
        "            name=\"TEST BASELINE (frozen)\",\n",
        "            max_pairs=test_pairs,\n",
        "            print_per_category=False\n",
        "        )\n",
        "\n",
        "    # ---------- SWEEP ----------\n",
        "    rows = []\n",
        "    for n_last_blocks in settings:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"RUN setting: n_last_blocks={n_last_blocks}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        restore_pretrained()\n",
        "\n",
        "        avg_loss = None\n",
        "        if n_last_blocks > 0:\n",
        "            avg_loss = train_steps(\n",
        "                train_loader,\n",
        "                n_last_blocks=n_last_blocks,\n",
        "                lr=lr,\n",
        "                weight_decay=weight_decay,\n",
        "                temp=temp,\n",
        "                max_steps=train_steps_per_setting,\n",
        "                log_every=200\n",
        "            )\n",
        "\n",
        "        dinov3.eval()\n",
        "        val_rep = evaluate_pck_report(\n",
        "            val_loader,\n",
        "            name=f\"VAL FINETUNED (blocks={n_last_blocks})\",\n",
        "            max_pairs=val_pairs,\n",
        "            print_per_category=False\n",
        "        )\n",
        "\n",
        "        rows.append({\n",
        "            \"n_last_blocks\": n_last_blocks,\n",
        "            \"lr\": lr,\n",
        "            \"temp\": temp,\n",
        "            \"train_steps\": train_steps_per_setting if n_last_blocks > 0 else 0,\n",
        "            \"avg_train_loss\": avg_loss,\n",
        "            \"val_kp_PCK@0.10\": 100 * val_rep[\"global_kp\"][0.10],\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values(\"n_last_blocks\").reset_index(drop=True)\n",
        "    print(\"\\n=== SWEEP SUMMARY (VAL) ===\")\n",
        "    print(df.to_string(index=False))\n",
        "\n",
        "    # ---------- SELECT BEST ----------\n",
        "    best_idx = int(df[\"val_kp_PCK@0.10\"].values.argmax())\n",
        "    best = df.iloc[best_idx].to_dict()\n",
        "    best_blocks = int(best[\"n_last_blocks\"])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"BEST (by VAL KP@0.10): n_last_blocks={best_blocks}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ---------- FINAL TRAIN + TEST ----------\n",
        "    restore_pretrained()\n",
        "    if best_blocks > 0:\n",
        "        _ = train_steps(\n",
        "            train_loader,\n",
        "            n_last_blocks=best_blocks,\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay,\n",
        "            temp=temp,\n",
        "            max_steps=train_steps_per_setting,\n",
        "            log_every=200\n",
        "        )\n",
        "\n",
        "    dinov3.eval()\n",
        "    best_test = evaluate_pck_report(\n",
        "        test_loader,\n",
        "        name=f\"TEST FINETUNED (BEST blocks={best_blocks})\",\n",
        "        max_pairs=test_pairs,\n",
        "        print_per_category=True\n",
        "    )\n",
        "\n",
        "    return df, best, base_val, base_test, best_test"
      ],
      "metadata": {
        "id": "nop5hQr1cmvb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 0) (Opzionale) sanity checks come il collega\n",
        "# ----------------------------\n",
        "# overfit_sanity(n_last_blocks=2, lr=5e-5, weight_decay=0.05, steps=800, eval_pairs=200)\n",
        "\n",
        "# df_lr = lr_finder(\n",
        "    # n_last_blocks=2,\n",
        "    # lrs=(1e-6, 3e-6, 1e-5, 3e-5, 1e-4),\n",
        "    # weight_decay=0.05,\n",
        "    # train_steps_each=300,\n",
        "    # eval_pairs=300\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYK40I4YcqGw",
        "outputId": "42a2cac8-7ad9-4368-f28f-dc072f50ecea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SANITY CHECK: OVERFIT (quick)\n",
            "======================================================================\n",
            "[VAL (baseline, frozen)] seen=200 used=200\n",
            "\n",
            "================== VAL (baseline, frozen) REPORT ==================\n",
            "Pairs run: 200 (seen: 200)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 34.60%\n",
            "  PCK@0.10: 52.54%\n",
            "  PCK@0.20: 63.43%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 37.14%\n",
            "  PCK@0.10: 55.20%\n",
            "  PCK@0.20: 67.32%\n",
            "\n",
            "Minutes: 4.6610\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/800 | avg_loss 3.7358 | seen_kps 1422 | 676.0s\n",
            "[train] step 400/800 | avg_loss 3.3616 | seen_kps 2916 | 1037.6s\n",
            "[train] step 600/800 | avg_loss 3.1668 | seen_kps 4338 | 1362.1s\n",
            "[train] step 800/800 | avg_loss 3.0120 | seen_kps 5817 | 1629.1s\n",
            "[VAL (after overfit)] seen=200 used=200\n",
            "\n",
            "================== VAL (after overfit) REPORT ==================\n",
            "Pairs run: 200 (seen: 200)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 54.71%\n",
            "  PCK@0.10: 73.42%\n",
            "  PCK@0.20: 85.25%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 54.96%\n",
            "  PCK@0.10: 72.79%\n",
            "  PCK@0.20: 85.38%\n",
            "\n",
            "Minutes: 0.3625\n",
            "\n",
            "[overfit] avg_train_loss: 3.0120\n",
            "[overfit] baseline val KP@0.10: 55.20%  -> after: 72.79%\n",
            "\n",
            "======================================================================\n",
            "LR FINDER\n",
            "======================================================================\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=1e-06 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/300 | avg_loss 4.7101 | seen_kps 1466 | 230.9s\n",
            "[VAL (lr=1e-06)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=1e-06) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 30.67%\n",
            "  PCK@0.10: 48.02%\n",
            "  PCK@0.20: 61.44%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 32.92%\n",
            "  PCK@0.10: 50.78%\n",
            "  PCK@0.20: 65.48%\n",
            "\n",
            "Minutes: 2.2631\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=3e-06 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/300 | avg_loss 4.6709 | seen_kps 1422 | 202.3s\n",
            "[VAL (lr=3e-06)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=3e-06) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 33.00%\n",
            "  PCK@0.10: 49.96%\n",
            "  PCK@0.20: 64.22%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 34.94%\n",
            "  PCK@0.10: 52.48%\n",
            "  PCK@0.20: 68.12%\n",
            "\n",
            "Minutes: 0.5621\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=1e-05 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/300 | avg_loss 4.4549 | seen_kps 1411 | 166.9s\n",
            "[VAL (lr=1e-05)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=1e-05) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 38.28%\n",
            "  PCK@0.10: 57.90%\n",
            "  PCK@0.20: 72.11%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 39.86%\n",
            "  PCK@0.10: 59.47%\n",
            "  PCK@0.20: 75.10%\n",
            "\n",
            "Minutes: 0.5802\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=3e-05 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/300 | avg_loss 3.9145 | seen_kps 1440 | 171.1s\n",
            "[VAL (lr=3e-05)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=3e-05) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 45.74%\n",
            "  PCK@0.10: 64.56%\n",
            "  PCK@0.20: 77.56%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 46.64%\n",
            "  PCK@0.10: 65.06%\n",
            "  PCK@0.20: 79.45%\n",
            "\n",
            "Minutes: 0.5549\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=0.0001 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/300 | avg_loss 3.5012 | seen_kps 1344 | 167.6s\n",
            "[VAL (lr=0.0001)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=0.0001) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 49.14%\n",
            "  PCK@0.10: 68.72%\n",
            "  PCK@0.20: 82.06%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 50.16%\n",
            "  PCK@0.10: 68.94%\n",
            "  PCK@0.20: 83.33%\n",
            "\n",
            "Minutes: 0.5704\n",
            "\n",
            "=== LR FINDER SUMMARY (choose on VAL, e.g. KP@0.10) ===\n",
            "      lr  n_last_blocks  temp  weight_decay  train_steps  avg_train_loss  val_kp_PCK@0.05  val_kp_PCK@0.10  val_kp_PCK@0.20  val_img_PCK@0.05  val_img_PCK@0.10  val_img_PCK@0.20\n",
            "0.000001              2   0.1          0.05          300        4.673084        32.919255        50.776398        65.476190         30.670988         48.018966         61.442866\n",
            "0.000003              2   0.1          0.05          300        4.604844        34.937888        52.484472        68.115942         33.002980         49.960693         64.218034\n",
            "0.000010              2   0.1          0.05          300        4.213131        39.855072        59.472050        75.103520         38.275382         57.901489         72.114102\n",
            "0.000030              2   0.1          0.05          300        3.748452        46.635611        65.062112        79.451346         45.738670         64.555845         77.563706\n",
            "0.000100              2   0.1          0.05          300        3.310789        50.155280        68.944099        83.333333         49.142039         68.722866         82.055433\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 1) Sweep Task2 (coerente): selezione su VAL, test solo sul best\n",
        "# ----------------------------\n",
        "settings = (0, 1, 2, 4)\n",
        "VAL_PAIRS  = None   # set None for full\n",
        "TEST_PAIRS = None   # set None for full\n",
        "\n",
        "df_sweep, best_cfg, base_val, base_test, best_test = run_task2_sweep(\n",
        "    settings=(0,1,2,4),\n",
        "    lr=3e-5,\n",
        "    temp=0.1,\n",
        "    weight_decay=0.05,\n",
        "    train_steps_per_setting=2000,\n",
        "    val_pairs=None,\n",
        "    test_pairs=None,\n",
        "    compute_test_baseline=False\n",
        ")\n",
        "\n",
        "print(\"\\n=== DONE ===\")\n"
      ],
      "metadata": {
        "id": "0rB0jniZcruq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d72691-5145-4b30-9d91-8964db31b3c7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "TASK2 SWEEP (select best on VAL; test only best)\n",
            "================================================================================\n",
            "[VAL BASELINE (frozen)] seen=200 used=200\n",
            "[VAL BASELINE (frozen)] seen=400 used=400\n",
            "[VAL BASELINE (frozen)] seen=600 used=600\n",
            "[VAL BASELINE (frozen)] seen=800 used=800\n",
            "[VAL BASELINE (frozen)] seen=1000 used=1000\n",
            "\n",
            "================== VAL BASELINE (frozen) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 28.81%\n",
            "  PCK@0.10: 46.24%\n",
            "  PCK@0.20: 61.11%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 31.74%\n",
            "  PCK@0.10: 50.21%\n",
            "  PCK@0.20: 66.26%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "   Category   KP@0.05   KP@0.10   KP@0.20  IMG@0.05  IMG@0.10  IMG@0.20\n",
            "  aeroplane 39.436620 55.281690 68.485915 36.977169 53.396684 65.001936\n",
            "    bicycle 34.604106 51.319648 64.222874 35.101065 49.650837 62.893437\n",
            "       bird 41.275168 68.120805 78.859060 40.067875 68.800438 78.537358\n",
            "       boat 17.153285 24.817518 39.416058 14.290344 21.128968 33.134921\n",
            "     bottle 22.676580 41.635688 60.966543 21.303461 39.168320 57.379299\n",
            "        bus 28.295820 42.443730 53.376206 19.877840 30.819328 40.307345\n",
            "        car 33.333333 48.888889 55.555556 28.232653 41.948219 48.969008\n",
            "        cat 58.571429 77.551020 87.346939 55.597927 73.838515 86.467073\n",
            "      chair 21.613833 33.429395 47.838617 18.207245 29.239631 41.603943\n",
            "        cow 36.011905 55.357143 70.833333 35.644110 54.937992 70.021441\n",
            "        dog 35.655738 54.713115 69.057377 32.575589 51.776702 67.277945\n",
            "      horse 33.901919 56.289979 72.921109 34.004156 56.849908 71.957992\n",
            "  motorbike 19.607843 41.176471 57.843137 18.659420 41.913389 56.544168\n",
            "     person 41.014799 63.636364 80.549683 38.648824 60.055876 77.961572\n",
            "pottedplant 15.656566 29.040404 50.252525 14.618726 26.718683 47.575075\n",
            "      sheep 33.574007 53.429603 66.064982 28.535128 47.764099 59.861637\n",
            "      train 27.187865 46.441074 66.511085 26.356474 44.986746 64.395534\n",
            "  tvmonitor 25.685786 47.256858 71.820449 24.575116 46.812659 71.748162\n",
            "\n",
            "Minutes: 21.4759\n",
            "\n",
            "======================================================================\n",
            "RUN setting: n_last_blocks=0\n",
            "======================================================================\n",
            "[VAL FINETUNED (blocks=0)] seen=200 used=200\n",
            "[VAL FINETUNED (blocks=0)] seen=400 used=400\n",
            "[VAL FINETUNED (blocks=0)] seen=600 used=600\n",
            "[VAL FINETUNED (blocks=0)] seen=800 used=800\n",
            "[VAL FINETUNED (blocks=0)] seen=1000 used=1000\n",
            "\n",
            "================== VAL FINETUNED (blocks=0) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 28.81%\n",
            "  PCK@0.10: 46.24%\n",
            "  PCK@0.20: 61.11%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 31.74%\n",
            "  PCK@0.10: 50.21%\n",
            "  PCK@0.20: 66.26%\n",
            "\n",
            "Minutes: 2.1309\n",
            "\n",
            "======================================================================\n",
            "RUN setting: n_last_blocks=1\n",
            "======================================================================\n",
            "[train] n_last_blocks=1 | trainable params: 7,090,944\n",
            "[train] step 200/2000 | avg_loss 4.3753 | seen_kps 1374 | 426.2s\n",
            "[train] step 400/2000 | avg_loss 4.1083 | seen_kps 2784 | 785.4s\n",
            "[train] step 600/2000 | avg_loss 3.8950 | seen_kps 4183 | 1078.8s\n",
            "[train] step 800/2000 | avg_loss 3.7899 | seen_kps 5566 | 1337.6s\n",
            "[train] step 1000/2000 | avg_loss 3.7054 | seen_kps 6966 | 1565.7s\n",
            "[train] step 1200/2000 | avg_loss 3.6067 | seen_kps 8444 | 1773.9s\n",
            "[train] step 1400/2000 | avg_loss 3.5238 | seen_kps 9815 | 1968.4s\n",
            "[train] step 1600/2000 | avg_loss 3.4674 | seen_kps 11197 | 2164.0s\n",
            "[train] step 1800/2000 | avg_loss 3.4105 | seen_kps 12611 | 2349.8s\n",
            "[train] step 2000/2000 | avg_loss 3.3556 | seen_kps 14063 | 2536.4s\n",
            "[VAL FINETUNED (blocks=1)] seen=200 used=200\n",
            "[VAL FINETUNED (blocks=1)] seen=400 used=400\n",
            "[VAL FINETUNED (blocks=1)] seen=600 used=600\n",
            "[VAL FINETUNED (blocks=1)] seen=800 used=800\n",
            "[VAL FINETUNED (blocks=1)] seen=1000 used=1000\n",
            "\n",
            "================== VAL FINETUNED (blocks=1) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 41.85%\n",
            "  PCK@0.10: 61.08%\n",
            "  PCK@0.20: 75.27%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 43.64%\n",
            "  PCK@0.10: 63.19%\n",
            "  PCK@0.20: 78.49%\n",
            "\n",
            "Minutes: 2.0844\n",
            "\n",
            "======================================================================\n",
            "RUN setting: n_last_blocks=2\n",
            "======================================================================\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/2000 | avg_loss 3.8812 | seen_kps 1410 | 162.2s\n",
            "[train] step 400/2000 | avg_loss 3.5914 | seen_kps 2827 | 307.8s\n",
            "[train] step 600/2000 | avg_loss 3.4012 | seen_kps 4184 | 451.7s\n",
            "[train] step 800/2000 | avg_loss 3.2608 | seen_kps 5591 | 607.4s\n",
            "[train] step 1000/2000 | avg_loss 3.1381 | seen_kps 7064 | 763.4s\n",
            "[train] step 1200/2000 | avg_loss 3.0578 | seen_kps 8424 | 907.2s\n",
            "[train] step 1400/2000 | avg_loss 2.9848 | seen_kps 9800 | 1064.5s\n",
            "[train] step 1600/2000 | avg_loss 2.9196 | seen_kps 11230 | 1216.6s\n",
            "[train] step 1800/2000 | avg_loss 2.8569 | seen_kps 12741 | 1371.7s\n",
            "[train] step 2000/2000 | avg_loss 2.8071 | seen_kps 14082 | 1516.0s\n",
            "[VAL FINETUNED (blocks=2)] seen=200 used=200\n",
            "[VAL FINETUNED (blocks=2)] seen=400 used=400\n",
            "[VAL FINETUNED (blocks=2)] seen=600 used=600\n",
            "[VAL FINETUNED (blocks=2)] seen=800 used=800\n",
            "[VAL FINETUNED (blocks=2)] seen=1000 used=1000\n",
            "\n",
            "================== VAL FINETUNED (blocks=2) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 49.31%\n",
            "  PCK@0.10: 68.29%\n",
            "  PCK@0.20: 80.36%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 51.54%\n",
            "  PCK@0.10: 71.44%\n",
            "  PCK@0.20: 84.39%\n",
            "\n",
            "Minutes: 1.9932\n",
            "\n",
            "======================================================================\n",
            "RUN setting: n_last_blocks=4\n",
            "======================================================================\n",
            "[train] n_last_blocks=4 | trainable params: 28,359,168\n",
            "[train] step 200/2000 | avg_loss 3.7389 | seen_kps 1408 | 125.9s\n",
            "[train] step 400/2000 | avg_loss 3.3329 | seen_kps 2779 | 249.1s\n",
            "[train] step 600/2000 | avg_loss 3.1156 | seen_kps 4148 | 379.0s\n",
            "[train] step 800/2000 | avg_loss 2.9647 | seen_kps 5434 | 499.7s\n",
            "[train] step 1000/2000 | avg_loss 2.8339 | seen_kps 6793 | 630.1s\n",
            "[train] step 1200/2000 | avg_loss 2.7461 | seen_kps 8184 | 762.4s\n",
            "[train] step 1400/2000 | avg_loss 2.6745 | seen_kps 9575 | 884.8s\n",
            "[train] step 1600/2000 | avg_loss 2.6015 | seen_kps 10933 | 1016.9s\n",
            "[train] step 1800/2000 | avg_loss 2.5289 | seen_kps 12328 | 1134.4s\n",
            "[train] step 2000/2000 | avg_loss 2.4688 | seen_kps 13693 | 1256.2s\n",
            "[VAL FINETUNED (blocks=4)] seen=200 used=200\n",
            "[VAL FINETUNED (blocks=4)] seen=400 used=400\n",
            "[VAL FINETUNED (blocks=4)] seen=600 used=600\n",
            "[VAL FINETUNED (blocks=4)] seen=800 used=800\n",
            "[VAL FINETUNED (blocks=4)] seen=1000 used=1000\n",
            "\n",
            "================== VAL FINETUNED (blocks=4) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 54.14%\n",
            "  PCK@0.10: 71.75%\n",
            "  PCK@0.20: 83.36%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 55.78%\n",
            "  PCK@0.10: 74.25%\n",
            "  PCK@0.20: 86.64%\n",
            "\n",
            "Minutes: 2.0945\n",
            "\n",
            "=== SWEEP SUMMARY (VAL) ===\n",
            " n_last_blocks      lr  temp  train_steps  avg_train_loss  val_kp_PCK@0.10\n",
            "             0 0.00003   0.1            0             NaN        50.205550\n",
            "             1 0.00003   0.1         2000        3.355634        63.193731\n",
            "             2 0.00003   0.1         2000        2.807147        71.441418\n",
            "             4 0.00003   0.1         2000        2.468816        74.254882\n",
            "\n",
            "======================================================================\n",
            "BEST (by VAL KP@0.10): n_last_blocks=4\n",
            "======================================================================\n",
            "[train] n_last_blocks=4 | trainable params: 28,359,168\n",
            "[train] step 200/2000 | avg_loss 3.8041 | seen_kps 1330 | 107.2s\n",
            "[train] step 400/2000 | avg_loss 3.3969 | seen_kps 2696 | 207.7s\n",
            "[train] step 600/2000 | avg_loss 3.1526 | seen_kps 4054 | 312.4s\n",
            "[train] step 800/2000 | avg_loss 2.9810 | seen_kps 5445 | 417.5s\n",
            "[train] step 1000/2000 | avg_loss 2.8453 | seen_kps 6839 | 530.8s\n",
            "[train] step 1200/2000 | avg_loss 2.7632 | seen_kps 8192 | 628.8s\n",
            "[train] step 1400/2000 | avg_loss 2.6782 | seen_kps 9604 | 735.9s\n",
            "[train] step 1600/2000 | avg_loss 2.6009 | seen_kps 11048 | 843.2s\n",
            "[train] step 1800/2000 | avg_loss 2.5417 | seen_kps 12428 | 949.0s\n",
            "[train] step 2000/2000 | avg_loss 2.4825 | seen_kps 13845 | 1053.8s\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=200 used=200\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=400 used=400\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=600 used=600\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=800 used=800\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=1000 used=1000\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=1200 used=1200\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=1400 used=1400\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=1600 used=1600\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=1800 used=1800\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=2000 used=2000\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=2200 used=2200\n",
            "[TEST FINETUNED (BEST blocks=4)] seen=2400 used=2400\n",
            "\n",
            "================== TEST FINETUNED (BEST blocks=4) REPORT ==================\n",
            "Pairs run: 2438 (seen: 2438)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 53.20%\n",
            "  PCK@0.10: 72.07%\n",
            "  PCK@0.20: 83.90%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 56.91%\n",
            "  PCK@0.10: 75.79%\n",
            "  PCK@0.20: 87.09%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "   Category   KP@0.05   KP@0.10   KP@0.20  IMG@0.05  IMG@0.10  IMG@0.20\n",
            "  aeroplane 61.100569 72.960152 85.199241 62.370517 73.778238 84.851000\n",
            "    bicycle 45.419847 66.157761 78.371501 43.079927 62.690261 74.522543\n",
            "       bird 70.462633 89.916963 95.848161 70.362723 89.860449 95.489764\n",
            "       boat 31.680000 52.000000 67.680000 35.732842 57.345552 71.744604\n",
            "     bottle 49.122807 65.470494 76.874003 47.604224 64.770571 76.101076\n",
            "        bus 61.512415 78.781038 85.327314 56.441787 73.755774 80.414008\n",
            "        car 65.075034 75.989086 84.447476 58.378096 70.781902 79.661788\n",
            "        cat 79.458599 87.261146 93.152866 79.907060 87.475091 93.335005\n",
            "      chair 39.509537 50.681199 60.081744 36.823205 49.108031 58.574204\n",
            "        cow 64.279835 84.526749 95.967078 63.291506 84.624123 95.602381\n",
            "        dog 56.277533 75.881057 87.665198 53.167418 73.201599 86.529191\n",
            "      horse 55.417957 74.509804 89.576883 54.884210 72.858089 88.481271\n",
            "  motorbike 56.666667 76.666667 85.757576 53.441454 74.484990 84.260409\n",
            "     person 48.102815 69.522644 83.720930 44.185013 65.994139 81.494378\n",
            "pottedplant 41.721854 70.419426 89.183223 41.143515 68.962384 87.497182\n",
            "      sheep 49.566474 65.606936 85.693642 47.820241 60.573471 79.863240\n",
            "      train 66.629277 88.839035 97.195738 65.075301 88.224870 96.803053\n",
            "  tvmonitor 53.409091 83.877841 96.377841 50.607748 80.698537 95.055476\n",
            "\n",
            "Minutes: 43.9971\n",
            "\n",
            "=== DONE ===\n"
          ]
        }
      ]
    }
  ]
}