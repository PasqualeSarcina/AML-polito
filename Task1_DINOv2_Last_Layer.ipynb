{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y8AKrNt5lxaQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k.zip' estratto con successo nella directory 'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted'\n",
      "Contenuti della directory 'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted':\n",
      "['SPair-71k']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "zip_file_path = r'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k.zip' \n",
    "extract_dir = r'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted'\n",
    "\n",
    "# Crea la directory di estrazione se non esiste\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Estrai il file ZIP solo se esiste\n",
    "if os.path.exists(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"File '{zip_file_path}' estratto con successo nella directory '{extract_dir}'\")\n",
    "    print(f\"Contenuti della directory '{extract_dir}':\\n{os.listdir(extract_dir)}\")\n",
    "else:\n",
    "    print(f\"File zip '{zip_file_path}' non trovato. Assicurati che il dataset sia estratto in '{extract_dir}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "honcpimEq_B2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset caricati correttamente.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import json\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, image_keys):\n",
    "        self.image_keys = image_keys\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        for key in self.image_keys:\n",
    "            image[key] /= 255.0\n",
    "            image[key] = self.normalize(image[key])\n",
    "        return image\n",
    "\n",
    "\n",
    "def read_img(path):\n",
    "    img = np.array(Image.open(path).convert('RGB'))\n",
    "\n",
    "    return torch.tensor(img.transpose(2, 0, 1).astype(np.float32))\n",
    "\n",
    "\n",
    "class SPairDataset(Dataset):\n",
    "    def __init__(self, pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype):\n",
    "\n",
    "        self.datatype = datatype\n",
    "        self.pck_alpha = pck_alpha\n",
    "        self.ann_files = open(os.path.join(layout_path, dataset_size, datatype + '.txt'), \"r\").read().split('\\n')\n",
    "        self.ann_files = self.ann_files[:len(self.ann_files) - 1]\n",
    "        self.pair_ann_path = pair_ann_path\n",
    "        self.image_path = image_path\n",
    "        self.categories = list(map(lambda x: os.path.basename(x), glob.glob('%s/*' % image_path)))\n",
    "        self.categories.sort()\n",
    "        self.transform = Normalize(['src_img', 'trg_img'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        raw_line = self.ann_files[idx]\n",
    "        ann_filename = raw_line.replace(':', '_')\n",
    "        ann_file = ann_filename + '.json'\n",
    "        json_path = os.path.join(self.pair_ann_path, self.datatype, ann_file)\n",
    "\n",
    "        with open(json_path) as f:\n",
    "            annotation = json.load(f)\n",
    "\n",
    "        category = annotation['category']\n",
    "        src_img = read_img(os.path.join(self.image_path, category, annotation['src_imname']))\n",
    "        trg_img = read_img(os.path.join(self.image_path, category, annotation['trg_imname']))\n",
    "\n",
    "        trg_bbox = annotation['trg_bndbox']\n",
    "        pck_threshold = max(trg_bbox[2] - trg_bbox[0],  trg_bbox[3] - trg_bbox[1]) * self.pck_alpha\n",
    "\n",
    "        sample = {'pair_id': annotation['pair_id'],\n",
    "                  'filename': annotation['filename'],\n",
    "                  'src_imname': annotation['src_imname'],\n",
    "                  'trg_imname': annotation['trg_imname'],\n",
    "                  'src_imsize': src_img.size(),\n",
    "                  'trg_imsize': trg_img.size(),\n",
    "\n",
    "                  'src_bbox': annotation['src_bndbox'],\n",
    "                  'trg_bbox': annotation['trg_bndbox'],\n",
    "                  'category': annotation['category'],\n",
    "\n",
    "                  'src_pose': annotation['src_pose'],\n",
    "                  'trg_pose': annotation['trg_pose'],\n",
    "\n",
    "                  'src_img': src_img,\n",
    "                  'trg_img': trg_img,\n",
    "                  'src_kps': torch.tensor(annotation['src_kps']).float(),\n",
    "                  'trg_kps': torch.tensor(annotation['trg_kps']).float(),\n",
    "\n",
    "                  'mirror': annotation['mirror'],\n",
    "                  'vp_var': annotation['viewpoint_variation'],\n",
    "                  'sc_var': annotation['scale_variation'],\n",
    "                  'truncn': annotation['truncation'],\n",
    "                  'occlsn': annotation['occlusion'],\n",
    "\n",
    "                  'pck_threshold': pck_threshold}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base_dir = r\"C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted\\SPair-71k\\SPair-71k\"    \n",
    "    pair_ann_path = os.path.join(base_dir, 'PairAnnotation')\n",
    "    layout_path = os.path.join(base_dir, 'Layout')\n",
    "    image_path = os.path.join(base_dir, 'JPEGImages')\n",
    "    dataset_size = 'large'\n",
    "    pck_alpha = 0.05\n",
    "    \n",
    "    # Verifica che i percorsi esistano prima di creare il dataset\n",
    "    if os.path.exists(pair_ann_path) and os.path.exists(layout_path) and os.path.exists(image_path):\n",
    "        trn_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='trn')\n",
    "        val_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='val')\n",
    "        test_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='test')\n",
    "\n",
    "        trn_dataloader = DataLoader(trn_dataset, num_workers=0)\n",
    "        val_dataloader = DataLoader(val_dataset, num_workers=0)\n",
    "        test_dataloader = DataLoader(test_dataset, num_workers=0)\n",
    "        print(\"Dataset caricati correttamente.\")\n",
    "    else:\n",
    "        print(f\"Errore: Impossibile trovare i percorsi del dataset in '{base_dir}'.\\nVerifica l'estrazione e controlla se la struttura delle cartelle corrisponde.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Official DINOv2 Model from Torch Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nicol/.cache\\torch\\hub\\facebookresearch_dinov2_main\n",
      "C:\\Users\\nicol/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "C:\\Users\\nicol/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "C:\\Users\\nicol/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 12234/12234 [26:38<00:00,  7.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# PCK PER POINT - OFFICIAL DINOv2 VERSION (WITH PADDING FIX)\n",
    "import torch\n",
    "import math \n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. LOAD OFFICIAL MODEL (Replaces Hugging Face)\n",
    "print(\"Loading Official DINOv2 Model from Torch Hub...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')\n",
    "model.to(device)\n",
    "model.eval() \n",
    "\n",
    "print(f\"Model loaded on: {device}\")\n",
    "\n",
    "# Helper function for Padding\n",
    "def pad_to_multiple(x, k=14):\n",
    "    \"\"\"\n",
    "    Pads the image (bottom and right) so that H and W are multiples of k.\n",
    "    \"\"\"\n",
    "    h, w = x.shape[-2:]\n",
    "    new_h = math.ceil(h / k) * k #  return the ceiling value of a number\n",
    "    new_w = math.ceil(w / k) * k\n",
    "    \n",
    "    pad_bottom = new_h - h\n",
    "    pad_right = new_w - w\n",
    "    \n",
    "    if pad_bottom == 0 and pad_right == 0:\n",
    "        return x\n",
    "    return F.pad(x, (0, pad_right, 0, pad_bottom), value=0)\n",
    "\n",
    "# Initialize counters\n",
    "class_pck_data = {}\n",
    "class_pck_image = {}\n",
    "\n",
    "with torch.no_grad(): # Disable gradients\n",
    "    for i, data in enumerate(tqdm(test_dataloader, desc=\"Evaluation\")):\n",
    "        \n",
    "        category = data['category'][0]\n",
    "        if category not in class_pck_data:\n",
    "            class_pck_data[category] = {\n",
    "                'total_keypoints': 0,\n",
    "                'correct_kps_0_05': 0,\n",
    "                'correct_kps_0_1': 0,\n",
    "                'correct_kps_0_2': 0\n",
    "\n",
    "            }\n",
    "        if category not in class_pck_image:\n",
    "            class_pck_image[category] = {\n",
    "                'total_image': 0,\n",
    "                'image_value_sum_0_05': 0, # Accumulatore per le medie delle singole immagini\n",
    "                'image_value_sum_0_1': 0,\n",
    "                'image_value_sum_0_2': 0\n",
    "            }\n",
    "            # Counters specific for THIS image\n",
    "        img_tot_keypoints = 0\n",
    "        img_correct_keypoints_0_05 = 0\n",
    "        img_correct_keypoints_0_1 = 0\n",
    "        img_correct_keypoints_0_2 = 0\n",
    "\n",
    "        src_img = data['src_img'].to(device) # torch.Size([1, 3, 333, 500])\n",
    "       \n",
    "        trg_img = data['trg_img'].to(device)\n",
    "\n",
    "        # --- FIX: APPLY PADDING ---\n",
    "        # Ensure dimensions are multiples of 14 to avoid AssertionError\n",
    "        src_img_padded = pad_to_multiple(src_img, 14)\n",
    "        trg_img_padded = pad_to_multiple(trg_img, 14)\n",
    "\n",
    "        \n",
    "        # We pass the PADDED images\n",
    "        dict_src = model.forward_features(src_img_padded) # Python dictionary. \n",
    "        dict_trg = model.forward_features(trg_img_padded)\n",
    "        \n",
    "        feats_src = dict_src[\"x_norm_patchtokens\"] # [Batch_Size, Num_Patches, Dimension]\n",
    "        feats_trg = dict_trg[\"x_norm_patchtokens\"]\n",
    "        \n",
    "        # --- IMPORTANT: GRID CALCULATION ---\n",
    "        # We must use PADDED dimensions for the grid, otherwise indices will drift\n",
    "        _, _, H_padded, W_padded = src_img_padded.shape \n",
    "        \n",
    "        # We keep ORIGINAL dimensions for valid boundary checks\n",
    "        _, _, H_orig, W_orig = data['src_img'].shape\n",
    "\n",
    "        patch_size = 14\n",
    "        w_grid = W_padded // patch_size \n",
    "        h_grid = H_padded // patch_size\n",
    "\n",
    "        kps_list_src = data['src_kps'][0] \n",
    "        trg_kps_gt = data['trg_kps'][0] \n",
    "        \n",
    "        bbox_list = data['trg_bbox'] \n",
    "\n",
    "        # Estraiamo i 4 valori scalari per l'immagine corrente (indice batch 0)\n",
    "        x_min = bbox_list[0][0].item()\n",
    "        y_min = bbox_list[1][0].item()\n",
    "        x_max = bbox_list[2][0].item()\n",
    "        y_max = bbox_list[3][0].item()\n",
    "\n",
    "        w_bbox = x_max - x_min\n",
    "        h_bbox = y_max - y_min\n",
    "        # La dimensione di riferimento è il lato massimo della BBox\n",
    "        max_side = max(w_bbox, h_bbox)\n",
    "        \n",
    "        # Calcoliamo le 3 soglie in pixel\n",
    "        thr_05 = max_side * 0.05\n",
    "        thr_10 = max_side * 0.10\n",
    "        thr_20 = max_side * 0.20\n",
    "        # Get threshold value\n",
    "        #         \n",
    "        for n_keypoint, keypoint_src in enumerate(kps_list_src):\n",
    "\n",
    "            x_src_val = keypoint_src[0].item()\n",
    "            y_src_val = keypoint_src[1].item()\n",
    "\n",
    "            # NaN Check\n",
    "            if math.isnan(x_src_val) or math.isnan(y_src_val):\n",
    "                continue\n",
    "            \n",
    "            x_pixel_src = int(x_src_val)\n",
    "            y_pixel_src = int(y_src_val)\n",
    "\n",
    "            # Boundary Check on ORIGINAL image (ignore points in padded area if any)\n",
    "            if not (0 <= x_pixel_src < W_orig and 0 <= y_pixel_src < H_orig):\n",
    "                continue\n",
    "\n",
    "            # Grid Clamp\n",
    "            x_patch_src = min(x_pixel_src // patch_size, w_grid - 1)\n",
    "            y_patch_src = min(y_pixel_src // patch_size, h_grid - 1)\n",
    "\n",
    "            # 3. INDEX CALCULATION\n",
    "            patch_index_src = (y_patch_src * w_grid) + x_patch_src\n",
    "\n",
    "            # Extract Vector\n",
    "            source_vec = feats_src[0, patch_index_src, :]\n",
    "\n",
    "            # Cosine Similarity\n",
    "            similarity_map = torch.cosine_similarity(source_vec, feats_trg[0], dim=-1)\n",
    "\n",
    "            # Prediction\n",
    "            patch_idx_spatial = torch.argmax(similarity_map).item()\n",
    "\n",
    "            # Convert Index -> Grid -> Pixel\n",
    "            x_col_pred = patch_idx_spatial % w_grid\n",
    "            y_row_pred = patch_idx_spatial // w_grid\n",
    "\n",
    "            x_pred_pixel = x_col_pred * patch_size + (patch_size // 2)\n",
    "            y_pred_pixel = y_row_pred * patch_size + (patch_size // 2)\n",
    "\n",
    "            # Ground Truth Check\n",
    "            gt_x = trg_kps_gt[n_keypoint, 0].item()\n",
    "            gt_y = trg_kps_gt[n_keypoint, 1].item()\n",
    "\n",
    "            if math.isnan(gt_x) or math.isnan(gt_y):\n",
    "                continue\n",
    "            if not (0 <= gt_x < W_orig and 0 <= gt_y < H_orig):\n",
    "                continue\n",
    "\n",
    "            # Distance & Update\n",
    "            distance = math.sqrt((x_pred_pixel - gt_x)**2 + (y_pred_pixel - gt_y)**2)\n",
    "\n",
    "           \n",
    "            is_correct_05 = distance <= thr_05\n",
    "            is_correct_10 = distance <= thr_10\n",
    "            is_correct_20 = distance <= thr_20\n",
    "\n",
    "            # Update Category Data\n",
    "            class_pck_data[category]['total_keypoints'] += 1\n",
    "            if is_correct_05: class_pck_data[category]['correct_kps_0_05'] += 1\n",
    "            if is_correct_10: class_pck_data[category]['correct_kps_0_1'] += 1\n",
    "            if is_correct_20: class_pck_data[category]['correct_kps_0_2'] += 1\n",
    "\n",
    "            # Update Image Data\n",
    "            img_tot_keypoints += 1\n",
    "            if is_correct_05: img_correct_keypoints_0_05 += 1\n",
    "            if is_correct_10: img_correct_keypoints_0_1 += 1\n",
    "            if is_correct_20: img_correct_keypoints_0_2 += 1\n",
    "        \n",
    "        # AGGIORNAMENTO DATI CATEGORIA (PCK PER IMAGE)\n",
    "        # Se l'immagine aveva almeno un punto valido, calcoliamo la sua accuratezza\n",
    "        if img_tot_keypoints > 0:\n",
    "            image_accuracy_0_05 = img_correct_keypoints_0_05 / img_tot_keypoints\n",
    "            image_accuracy_0_1 = img_correct_keypoints_0_1 / img_tot_keypoints\n",
    "            image_accuracy_0_2 = img_correct_keypoints_0_2 / img_tot_keypoints\n",
    "\n",
    "            \n",
    "            class_pck_image[category]['total_image'] += 1\n",
    "            class_pck_image[category]['image_value_sum_0_05'] += image_accuracy_0_05\n",
    "            class_pck_image[category]['image_value_sum_0_1'] += image_accuracy_0_1\n",
    "            class_pck_image[category]['image_value_sum_0_2'] += image_accuracy_0_2\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PCK per Class ---\n",
      "Category: aeroplane\n",
      "  PCK@0.05: 37.37% (256.69845381656506/687)\n",
      "  PCK@0.1: 49.32% (338.8228772259731/687)\n",
      "  PCK@0.2: 62.51% (429.413891255803/687)\n",
      "--------------------\n",
      "Category: bicycle\n",
      "  PCK@0.05: 20.13% (126.84765512265517/630)\n",
      "  PCK@0.1: 31.50% (198.46590909090895/630)\n",
      "  PCK@0.2: 39.78% (250.62063492063461/630)\n",
      "--------------------\n",
      "Category: bird\n",
      "  PCK@0.05: 30.57% (214.6260572760573/702)\n",
      "  PCK@0.1: 45.11% (316.65251692751707/702)\n",
      "  PCK@0.2: 57.62% (404.49004329004305/702)\n",
      "--------------------\n",
      "Category: boat\n",
      "  PCK@0.05: 16.18% (105.18730158730165/650)\n",
      "  PCK@0.1: 26.84% (174.43888888888884/650)\n",
      "  PCK@0.2: 43.84% (284.94722222222214/650)\n",
      "--------------------\n",
      "Category: bottle\n",
      "  PCK@0.05: 7.96% (66.94325396825404/841)\n",
      "  PCK@0.1: 15.51% (130.40357142857152/841)\n",
      "  PCK@0.2: 29.87% (251.22896825396813/841)\n",
      "--------------------\n",
      "Category: bus\n",
      "  PCK@0.05: 24.98% (159.13415799886394/637)\n",
      "  PCK@0.1: 36.02% (229.4485494081082/637)\n",
      "  PCK@0.2: 46.52% (296.3500358301827/637)\n",
      "--------------------\n",
      "Category: car\n",
      "  PCK@0.05: 20.03% (111.18535631035637/555)\n",
      "  PCK@0.1: 31.13% (172.7879495504495/555)\n",
      "  PCK@0.2: 42.53% (236.0599608724609/555)\n",
      "--------------------\n",
      "Category: cat\n",
      "  PCK@0.05: 42.40% (253.98803696303648/599)\n",
      "  PCK@0.1: 51.39% (307.83190698190685/599)\n",
      "  PCK@0.2: 64.39% (385.68241480741506/599)\n",
      "--------------------\n",
      "Category: chair\n",
      "  PCK@0.05: 6.05% (37.559668109668095/621)\n",
      "  PCK@0.1: 11.96% (74.26619769119768/621)\n",
      "  PCK@0.2: 22.16% (137.64058441558456/621)\n",
      "--------------------\n",
      "Category: cow\n",
      "  PCK@0.05: 24.38% (155.29778007939777/637)\n",
      "  PCK@0.1: 38.49% (245.19216258887292/637)\n",
      "  PCK@0.2: 54.74% (348.6873078332056/637)\n",
      "--------------------\n",
      "Category: dog\n",
      "  PCK@0.05: 28.99% (173.93099123099134/600)\n",
      "  PCK@0.1: 44.08% (264.50982350982355/600)\n",
      "  PCK@0.2: 60.30% (361.804625929626/600)\n",
      "--------------------\n",
      "Category: horse\n",
      "  PCK@0.05: 8.14% (48.04459984459985/590)\n",
      "  PCK@0.1: 16.69% (98.46919746919752/590)\n",
      "  PCK@0.2: 28.60% (168.75636030636028/590)\n",
      "--------------------\n",
      "Category: motorbike\n",
      "  PCK@0.05: 24.94% (170.0698412698414/682)\n",
      "  PCK@0.1: 38.94% (265.5650793650794/682)\n",
      "  PCK@0.2: 52.99% (361.36666666666673/682)\n",
      "--------------------\n",
      "Category: person\n",
      "  PCK@0.05: 20.97% (135.46288988788993/646)\n",
      "  PCK@0.1: 35.04% (226.33523698523706/646)\n",
      "  PCK@0.2: 48.24% (311.6288433788433/646)\n",
      "--------------------\n",
      "Category: pottedplant\n",
      "  PCK@0.05: 5.52% (40.42380952380953/732)\n",
      "  PCK@0.1: 13.34% (97.65238095238102/732)\n",
      "  PCK@0.2: 28.16% (206.14761904761903/732)\n",
      "--------------------\n",
      "Category: sheep\n",
      "  PCK@0.05: 23.88% (156.3969314998729/655)\n",
      "  PCK@0.1: 40.22% (263.4445250011425/655)\n",
      "  PCK@0.2: 56.45% (369.77220965309226/655)\n",
      "--------------------\n",
      "Category: train\n",
      "  PCK@0.05: 25.08% (189.59338716838744/756)\n",
      "  PCK@0.1: 41.88% (316.62916389166435/756)\n",
      "  PCK@0.2: 61.17% (462.4400224775228/756)\n",
      "--------------------\n",
      "Category: tvmonitor\n",
      "  PCK@0.05: 7.00% (48.234386446886504/689)\n",
      "  PCK@0.1: 15.02% (103.46999389499399/689)\n",
      "  PCK@0.2: 27.60% (190.18057359307363/689)\n",
      "--------------------\n",
      "\n",
      "--- Overall Mean PCK ---\n",
      "Overall Mean PCK@0.05: 20.81%\n",
      "Overall Mean PCK@0.1: 32.36%\n",
      "Overall Mean PCK@0.2: 45.97%\n"
     ]
    }
   ],
   "source": [
    "# CALCOLO PCK PER IMAGE\n",
    "print(\"--- PCK per Class ---\")\n",
    "class_pck_0_05_list = []\n",
    "class_pck_0_1_list = []\n",
    "class_pck_0_2_list = []\n",
    "\n",
    "for category, data in class_pck_image.items():\n",
    "    total_image = data['total_image']\n",
    "    correct_image_0_05 = data['image_value_sum_0_05']\n",
    "    correct_image_0_1 = data['image_value_sum_0_1']\n",
    "    correct_image_0_2 = data['image_value_sum_0_2']\n",
    "\n",
    "    pck_0_05 = (correct_image_0_05 / total_image) * 100 if total_image > 0 else 0\n",
    "    pck_0_1 = (correct_image_0_1 / total_image) * 100 if total_image > 0 else 0\n",
    "    pck_0_2 = (correct_image_0_2 / total_image) * 100 if total_image > 0 else 0\n",
    "\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"  PCK@0.05: {pck_0_05:.2f}% ({correct_image_0_05}/{total_image})\")\n",
    "    print(f\"  PCK@0.1: {pck_0_1:.2f}% ({correct_image_0_1}/{total_image})\")\n",
    "    print(f\"  PCK@0.2: {pck_0_2:.2f}% ({correct_image_0_2}/{total_image})\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    if total_image> 0: # Only add to the list if there were keypoints for this class\n",
    "        class_pck_0_05_list.append(pck_0_05)\n",
    "        class_pck_0_1_list.append(pck_0_1)\n",
    "        class_pck_0_2_list.append(pck_0_2)\n",
    "\n",
    "# 4. Calculate and Display Overall Mean PCK\n",
    "print(\"\\n--- Overall Mean PCK ---\")\n",
    "overall_mean_pck_0_05 = sum(class_pck_0_05_list) / len(class_pck_0_05_list) if class_pck_0_05_list else 0\n",
    "overall_mean_pck_0_1 = sum(class_pck_0_1_list) / len(class_pck_0_1_list) if class_pck_0_1_list else 0\n",
    "overall_mean_pck_0_2 = sum(class_pck_0_2_list) / len(class_pck_0_2_list) if class_pck_0_2_list else 0\n",
    "\n",
    "print(f\"Overall Mean PCK@0.05: {overall_mean_pck_0_05:.2f}%\")\n",
    "print(f\"Overall Mean PCK@0.1: {overall_mean_pck_0_1:.2f}%\")\n",
    "print(f\"Overall Mean PCK@0.2: {overall_mean_pck_0_2:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S0-oTron10lL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PCK per Class ---\n",
      "Category: aeroplane\n",
      "  PCK@0.05: 41.03% (2141/5218)\n",
      "  PCK@0.1: 52.70% (2750/5218)\n",
      "  PCK@0.2: 65.06% (3395/5218)\n",
      "--------------------\n",
      "Category: bicycle\n",
      "  PCK@0.05: 24.74% (869/3513)\n",
      "  PCK@0.1: 38.14% (1340/3513)\n",
      "  PCK@0.2: 47.14% (1656/3513)\n",
      "--------------------\n",
      "Category: bird\n",
      "  PCK@0.05: 32.53% (1292/3972)\n",
      "  PCK@0.1: 47.96% (1905/3972)\n",
      "  PCK@0.2: 59.82% (2376/3972)\n",
      "--------------------\n",
      "Category: boat\n",
      "  PCK@0.05: 16.64% (502/3016)\n",
      "  PCK@0.1: 27.98% (844/3016)\n",
      "  PCK@0.2: 45.62% (1376/3016)\n",
      "--------------------\n",
      "Category: bottle\n",
      "  PCK@0.05: 8.89% (481/5409)\n",
      "  PCK@0.1: 16.60% (898/5409)\n",
      "  PCK@0.2: 31.93% (1727/5409)\n",
      "--------------------\n",
      "Category: bus\n",
      "  PCK@0.05: 31.64% (1322/4178)\n",
      "  PCK@0.1: 44.85% (1874/4178)\n",
      "  PCK@0.2: 55.84% (2333/4178)\n",
      "--------------------\n",
      "Category: car\n",
      "  PCK@0.05: 25.84% (866/3352)\n",
      "  PCK@0.1: 38.87% (1303/3352)\n",
      "  PCK@0.2: 49.67% (1665/3352)\n",
      "--------------------\n",
      "Category: cat\n",
      "  PCK@0.05: 44.33% (2602/5870)\n",
      "  PCK@0.1: 53.48% (3139/5870)\n",
      "  PCK@0.2: 66.39% (3897/5870)\n",
      "--------------------\n",
      "Category: chair\n",
      "  PCK@0.05: 7.28% (216/2968)\n",
      "  PCK@0.1: 13.85% (411/2968)\n",
      "  PCK@0.2: 24.56% (729/2968)\n",
      "--------------------\n",
      "Category: cow\n",
      "  PCK@0.05: 25.68% (1286/5007)\n",
      "  PCK@0.1: 40.08% (2007/5007)\n",
      "  PCK@0.2: 55.10% (2759/5007)\n",
      "--------------------\n",
      "Category: dog\n",
      "  PCK@0.05: 32.08% (1449/4517)\n",
      "  PCK@0.1: 47.97% (2167/4517)\n",
      "  PCK@0.2: 63.58% (2872/4517)\n",
      "--------------------\n",
      "Category: horse\n",
      "  PCK@0.05: 9.60% (390/4064)\n",
      "  PCK@0.1: 18.45% (750/4064)\n",
      "  PCK@0.2: 30.63% (1245/4064)\n",
      "--------------------\n",
      "Category: motorbike\n",
      "  PCK@0.05: 28.20% (877/3110)\n",
      "  PCK@0.1: 44.18% (1374/3110)\n",
      "  PCK@0.2: 59.07% (1837/3110)\n",
      "--------------------\n",
      "Category: person\n",
      "  PCK@0.05: 24.58% (998/4061)\n",
      "  PCK@0.1: 40.36% (1639/4061)\n",
      "  PCK@0.2: 54.54% (2215/4061)\n",
      "--------------------\n",
      "Category: pottedplant\n",
      "  PCK@0.05: 6.77% (227/3353)\n",
      "  PCK@0.1: 14.88% (499/3353)\n",
      "  PCK@0.2: 30.06% (1008/3353)\n",
      "--------------------\n",
      "Category: sheep\n",
      "  PCK@0.05: 25.39% (902/3553)\n",
      "  PCK@0.1: 42.02% (1493/3553)\n",
      "  PCK@0.2: 59.39% (2110/3553)\n",
      "--------------------\n",
      "Category: train\n",
      "  PCK@0.05: 27.06% (2283/8437)\n",
      "  PCK@0.1: 44.17% (3727/8437)\n",
      "  PCK@0.2: 63.27% (5338/8437)\n",
      "--------------------\n",
      "Category: tvmonitor\n",
      "  PCK@0.05: 7.81% (552/7066)\n",
      "  PCK@0.1: 16.87% (1192/7066)\n",
      "  PCK@0.2: 30.75% (2173/7066)\n",
      "--------------------\n",
      "\n",
      "--- Overall Mean PCK ---\n",
      "Overall Mean PCK@0.05: 23.34%\n",
      "Overall Mean PCK@0.1: 35.75%\n",
      "Overall Mean PCK@0.2: 49.58%\n"
     ]
    }
   ],
   "source": [
    "#PCK per point\n",
    "print(\"--- PCK per Class ---\")\n",
    "class_pck_0_05_list = []\n",
    "class_pck_0_1_list = []\n",
    "class_pck_0_2_list = []\n",
    "\n",
    "for category, data in class_pck_data.items():\n",
    "    total_kps = data['total_keypoints']\n",
    "    correct_kps_0_05 = data['correct_kps_0_05']\n",
    "    correct_kps_0_1 = data['correct_kps_0_1']\n",
    "    correct_kps_0_2 = data['correct_kps_0_2']\n",
    "\n",
    "    pck_0_05 = (correct_kps_0_05 / total_kps) * 100 if total_kps > 0 else 0\n",
    "    pck_0_1 = (correct_kps_0_1 / total_kps) * 100 if total_kps > 0 else 0\n",
    "    pck_0_2 = (correct_kps_0_2 / total_kps) * 100 if total_kps > 0 else 0\n",
    "\n",
    "    print(f\"Category: {category}\")\n",
    "    print(f\"  PCK@0.05: {pck_0_05:.2f}% ({correct_kps_0_05}/{total_kps})\")\n",
    "    print(f\"  PCK@0.1: {pck_0_1:.2f}% ({correct_kps_0_1}/{total_kps})\")\n",
    "    print(f\"  PCK@0.2: {pck_0_2:.2f}% ({correct_kps_0_2}/{total_kps})\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    if total_kps > 0: # Only add to the list if there were keypoints for this class\n",
    "        class_pck_0_05_list.append(pck_0_05)\n",
    "        class_pck_0_1_list.append(pck_0_1)\n",
    "        class_pck_0_2_list.append(pck_0_2)\n",
    "\n",
    "# 4. Calculate and Display Overall Mean PCK\n",
    "print(\"\\n--- Overall Mean PCK ---\")\n",
    "overall_mean_pck_0_05 = sum(class_pck_0_05_list) / len(class_pck_0_05_list) if class_pck_0_05_list else 0\n",
    "overall_mean_pck_0_1 = sum(class_pck_0_1_list) / len(class_pck_0_1_list) if class_pck_0_1_list else 0\n",
    "overall_mean_pck_0_2 = sum(class_pck_0_2_list) / len(class_pck_0_2_list) if class_pck_0_2_list else 0\n",
    "\n",
    "print(f\"Overall Mean PCK@0.05: {overall_mean_pck_0_05:.2f}%\")\n",
    "print(f\"Overall Mean PCK@0.1: {overall_mean_pck_0_1:.2f}%\")\n",
    "print(f\"Overall Mean PCK@0.2: {overall_mean_pck_0_2:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM94XQGmSqU+CbzhlwN85hS",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
