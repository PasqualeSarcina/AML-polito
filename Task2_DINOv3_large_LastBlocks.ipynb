{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-s1j0jeDJRT",
        "outputId": "701c6c6c-5955-4d08-a8a3-0eef7a0f6c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan  4 16:04:33 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
            "| N/A   35C    P0             62W /  400W |    1919MiB /  81920MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Task 2 — DINOv3 Light Fine-tuning (Last Blocks) — SPair-71k\n",
        "# - Supervision: keypoint -> target patch index (CrossEntropy over target patches)\n",
        "# - Eval: PCK@{0.05,0.10,0.20} with argmax cosine matching (Task1-style)\n",
        "# - Geometry: pad bottom/right to multiple of PATCH=16\n",
        "#\n",
        "# PROTOCOLLO (tuning SMALL → finale LARGE):\n",
        "# 0) Overfit sanity (SMALL): train per un numero fisso di step, eval su 200 VAL pairs (SMALL)\n",
        "# 1) LR finder (SMALL): prova alcuni LR, eval su 300 VAL pairs (SMALL)\n",
        "# 2) Sweep n_last_blocks (SMALL): prova {0,1,2,4}, seleziona il BEST su VAL (SMALL) usando KP@0.10\n",
        "#    - Nota: durante lo sweep NON si usa il TEST (per evitare leakage e risparmiare tempo)\n",
        "# 3) Run finale su LARGE (NO sweep):\n",
        "#    - calcola baseline FROZEN su VAL (LARGE) e TEST (LARGE)\n",
        "#    - riparte dai pesi pretrained e allena SOLO il BEST setting (n_last_blocks scelto su SMALL)\n",
        "#    - valuta BEST su VAL (LARGE) e TEST (LARGE)\n",
        "#    - stampa globale (KP + IMG) e per-categoria (KP + IMG) per baseline e best, su VAL e TEST\n",
        "#\n",
        "# CONFIG:\n",
        "# - DATASET_SIZE_TUNE=\"small\"\n",
        "# - DATASET_SIZE_FINAL=\"large\"\n",
        "# - sanity: eval_pairs=200 (VAL SMALL)\n",
        "# - lr_finder: eval_pairs=300 (VAL SMALL)\n",
        "# - sweep: val_pairs=None (FULL VAL SMALL)\n",
        "# - finale: max_pairs=None (FULL VAL/TEST LARGE)\n",
        "# ============================================================\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "from pathlib import Path\n",
        "import os, json, time, copy, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------\n",
        "# Paths\n",
        "# ----------------------------\n",
        "SPAIR_ROOT = Path(\"/content/drive/MyDrive/AMLDataset/SPair-71k\")\n",
        "PAIR_ANN_PATH = SPAIR_ROOT / \"PairAnnotation\"\n",
        "LAYOUT_PATH   = SPAIR_ROOT / \"Layout\"\n",
        "IMAGE_PATH    = SPAIR_ROOT / \"JPEGImages\"\n",
        "assert SPAIR_ROOT.exists(), f\"SPair-71k non trovato: {SPAIR_ROOT}\"\n",
        "assert PAIR_ANN_PATH.exists() and LAYOUT_PATH.exists() and IMAGE_PATH.exists(), \"Cartelle SPair mancanti\"\n",
        "\n",
        "# ----------------------------\n",
        "# Setup\n",
        "# ----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "PATCH = 16  # vitb16\n",
        "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MtSUZbYEu3L",
        "outputId": "e9a5119f-0ec6-4bd2-85af-d05e809120ed"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Utilities\n",
        "# ----------------------------\n",
        "def read_img(image_path: str) -> torch.Tensor:\n",
        "    \"\"\"CHW float in [0..255]\"\"\"\n",
        "    img = np.array(Image.open(image_path).convert(\"RGB\"))\n",
        "    return torch.from_numpy(img.transpose(2, 0, 1)).float()\n",
        "\n",
        "def normalize_img_chw_0_255(img_chw_0_255: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"CHW float [0..255] -> normalized float (ImageNet)\"\"\"\n",
        "    x = img_chw_0_255 / 255.0\n",
        "    mean = torch.tensor(IMAGENET_MEAN, device=x.device).view(3,1,1)\n",
        "    std  = torch.tensor(IMAGENET_STD,  device=x.device).view(3,1,1)\n",
        "    return (x - mean) / std\n",
        "\n",
        "def pad_to_patch_multiple(x_chw: torch.Tensor, patch=16):\n",
        "    \"\"\"Pad bottom/right with zeros so H,W multiples of patch.\"\"\"\n",
        "    C, H, W = x_chw.shape\n",
        "    H_pad = ((H + patch - 1) // patch) * patch\n",
        "    W_pad = ((W + patch - 1) // patch) * patch\n",
        "    pad_bottom = H_pad - H\n",
        "    pad_right  = W_pad - W\n",
        "    x_pad = F.pad(x_chw, (0, pad_right, 0, pad_bottom), value=0.0)\n",
        "    return x_pad, (H, W), (H_pad, W_pad)\n",
        "\n",
        "def ensure_kps_k2(kps: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Coerce keypoints to [K,2] (x,y). Accepts [K,2], [2,K], [K,3], [3,K].\n",
        "    Drops visibility if present.\n",
        "    \"\"\"\n",
        "    if kps.ndim != 2:\n",
        "        raise ValueError(f\"kps must be 2D, got {kps.shape}\")\n",
        "    if kps.shape[0] in (2,3) and kps.shape[1] not in (2,3):\n",
        "        kps = kps.t()\n",
        "    if kps.shape[1] == 3:\n",
        "        kps = kps[:, :2]\n",
        "    if kps.shape[1] != 2:\n",
        "        raise ValueError(f\"Cannot convert to [K,2], got {kps.shape}\")\n",
        "    return kps\n",
        "\n",
        "def kps_to_flat_indices(kps_k2: torch.Tensor, H_pad: int, W_pad: int, patch=16):\n",
        "    \"\"\"\n",
        "    kps_k2: [K,2] pixel coords.\n",
        "    Returns:\n",
        "      flat_idx [K] long\n",
        "      valid [K] bool (inside padded image and non-negative)\n",
        "      hg,wg\n",
        "    \"\"\"\n",
        "    x = kps_k2[:,0]\n",
        "    y = kps_k2[:,1]\n",
        "    valid = (x >= 0) & (y >= 0) & (x < W_pad) & (y < H_pad)\n",
        "\n",
        "    hg = H_pad // patch\n",
        "    wg = W_pad // patch\n",
        "\n",
        "    ix = torch.clamp((x // patch).long(), 0, wg - 1)\n",
        "    iy = torch.clamp((y // patch).long(), 0, hg - 1)\n",
        "    flat = iy * wg + ix\n",
        "    return flat, valid, hg, wg\n",
        "\n",
        "def find_layout_file(layout_root: Path, dataset_size: str, split: str):\n",
        "    \"\"\"\n",
        "    Robustly find Layout/<size>/<split>.txt, allowing small naming variants.\n",
        "    \"\"\"\n",
        "    folder = layout_root / dataset_size\n",
        "    candidates = [\n",
        "        folder / f\"{split}.txt\",\n",
        "        folder / f\"{split}n.txt\",   # e.g., trnn/valn\n",
        "        folder / f\"{split}_.txt\"\n",
        "    ]\n",
        "    for c in candidates:\n",
        "        if c.exists():\n",
        "            return c\n",
        "    for f in folder.glob(\"*.txt\"):\n",
        "        if f.stem.lower() == split.lower():\n",
        "            return f\n",
        "    raise FileNotFoundError(f\"Nessun layout file trovato per split='{split}' in {folder}.\")"
      ],
      "metadata": {
        "id": "XeptVLNcExxZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Dataset\n",
        "# ----------------------------\n",
        "class SPairDataset(Dataset):\n",
        "    def __init__(self, pair_ann_path, layout_path, image_path,\n",
        "                 dataset_size=\"large\", split=\"trn\", max_retries=3):\n",
        "        self.split = split\n",
        "        self.pair_ann_path = Path(pair_ann_path)\n",
        "        self.layout_path   = Path(layout_path)\n",
        "        self.image_path    = Path(image_path)\n",
        "        self.max_retries   = int(max_retries)\n",
        "\n",
        "        layout_file = find_layout_file(self.layout_path, dataset_size, split)\n",
        "        with open(layout_file, \"r\") as f:\n",
        "            self.ann_files = [x.strip() for x in f.read().splitlines() if len(x.strip()) > 0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        pair_id = self.ann_files[index]\n",
        "        ann_filepath = self.pair_ann_path / self.split / f\"{pair_id}.json\"\n",
        "\n",
        "        last_err = None\n",
        "        for t in range(self.max_retries):\n",
        "            try:\n",
        "                with open(ann_filepath, \"r\") as f:\n",
        "                    ann = json.load(f)\n",
        "                break\n",
        "            except OSError as e:\n",
        "                last_err = e\n",
        "                time.sleep(0.2 * (t + 1))\n",
        "        else:\n",
        "            raise last_err\n",
        "\n",
        "        category = ann[\"category\"]\n",
        "        src_img_path = self.image_path / category / ann[\"src_imname\"]\n",
        "        trg_img_path = self.image_path / category / ann[\"trg_imname\"]\n",
        "\n",
        "        src_img = read_img(str(src_img_path))  # CHW float [0..255]\n",
        "        trg_img = read_img(str(trg_img_path))\n",
        "\n",
        "        # keypoints -> torch float [K,2]\n",
        "        src_kps = ensure_kps_k2(torch.tensor(ann[\"src_kps\"], dtype=torch.float32))\n",
        "        trg_kps = ensure_kps_k2(torch.tensor(ann[\"trg_kps\"], dtype=torch.float32))\n",
        "\n",
        "        # bboxes -> torch float [4]\n",
        "        src_bbox = torch.tensor(ann[\"src_bndbox\"], dtype=torch.float32).view(-1)\n",
        "        trg_bbox = torch.tensor(ann[\"trg_bndbox\"], dtype=torch.float32).view(-1)\n",
        "        if src_bbox.numel() != 4 or trg_bbox.numel() != 4:\n",
        "            raise ValueError(f\"Bad bbox size for pair_id={pair_id}: \"\n",
        "                             f\"src_bbox={src_bbox.tolist()} trg_bbox={trg_bbox.tolist()}\")\n",
        "\n",
        "        return {\n",
        "            \"pair_id\": pair_id,\n",
        "            \"category\": category,\n",
        "            \"src_bbox\": src_bbox,\n",
        "            \"trg_bbox\": trg_bbox,\n",
        "            \"src_img\": src_img,\n",
        "            \"trg_img\": trg_img,\n",
        "            \"src_kps\": src_kps,\n",
        "            \"trg_kps\": trg_kps,\n",
        "        }"
      ],
      "metadata": {
        "id": "o0okcgh-E1Ab"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Choose dataset sizes\n",
        "# ----------------------------\n",
        "DATASET_SIZE_TUNE  = \"small\"\n",
        "DATASET_SIZE_FINAL = \"large\"\n",
        "print(\"DATASET_SIZE_TUNE :\", DATASET_SIZE_TUNE)\n",
        "print(\"DATASET_SIZE_FINAL:\", DATASET_SIZE_FINAL)\n",
        "\n",
        "def make_loaders(dataset_size: str):\n",
        "    train_dataset = SPairDataset(PAIR_ANN_PATH, LAYOUT_PATH, IMAGE_PATH, dataset_size=dataset_size, split=\"trn\")\n",
        "    val_dataset   = SPairDataset(PAIR_ANN_PATH, LAYOUT_PATH, IMAGE_PATH, dataset_size=dataset_size, split=\"val\")\n",
        "    test_dataset  = SPairDataset(PAIR_ANN_PATH, LAYOUT_PATH, IMAGE_PATH, dataset_size=dataset_size, split=\"test\")\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True,  num_workers=0, pin_memory=False)\n",
        "    val_loader   = DataLoader(val_dataset,   batch_size=1, shuffle=False, num_workers=0, pin_memory=False)\n",
        "    test_loader  = DataLoader(test_dataset,  batch_size=1, shuffle=False, num_workers=0, pin_memory=False)\n",
        "\n",
        "    print(f\"[{dataset_size}] Train pairs:\", len(train_dataset))\n",
        "    print(f\"[{dataset_size}] Val   pairs:\", len(val_dataset))\n",
        "    print(f\"[{dataset_size}] Test  pairs:\", len(test_dataset))\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "train_loader_s, val_loader_s, test_loader_s = make_loaders(DATASET_SIZE_TUNE)\n",
        "train_loader_l, val_loader_l, test_loader_l = make_loaders(DATASET_SIZE_FINAL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR-ehhx0E3wt",
        "outputId": "0503f5a6-208d-4531-f595-554998739b0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET_SIZE_TUNE : small\n",
            "DATASET_SIZE_FINAL: large\n",
            "[small] Train pairs: 10652\n",
            "[small] Val   pairs: 1070\n",
            "[small] Test  pairs: 2438\n",
            "[large] Train pairs: 53340\n",
            "[large] Val   pairs: 5384\n",
            "[large] Test  pairs: 12234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Load DINOv3\n",
        "# ----------------------------\n",
        "%cd /content\n",
        "!test -d dinov3 || git clone https://github.com/facebookresearch/dinov3.git\n",
        "%cd /content/dinov3\n",
        "!pip -q install einops timm opencv-python torchmetrics fvcore iopath\n",
        "\n",
        "DINOV3_DIR = \"/content/dinov3\"\n",
        "DINOV3_WEIGHTS = \"/content/drive/MyDrive/AMLDataset/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
        "assert os.path.exists(DINOV3_WEIGHTS), f\"Pesi DINOv3 non trovati: {DINOV3_WEIGHTS}\"\n",
        "\n",
        "dinov3 = torch.hub.load(\n",
        "    DINOV3_DIR,\n",
        "    \"dinov3_vitb16\",\n",
        "    source=\"local\",\n",
        "    weights=DINOV3_WEIGHTS,\n",
        ").to(device)\n",
        "\n",
        "assert hasattr(dinov3, \"blocks\"), \"Model has no attribute 'blocks'—cannot unfreeze last blocks.\"\n",
        "print(\"DINOv3 blocks:\", len(dinov3.blocks))\n",
        "\n",
        "# Save pretrained snapshot (fair compare)\n",
        "pretrained_state = copy.deepcopy(dinov3.state_dict())\n",
        "\n",
        "def restore_pretrained():\n",
        "    dinov3.load_state_dict(pretrained_state, strict=True)\n",
        "    dinov3.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfKfYS_lE8PM",
        "outputId": "9ccf51ec-f5b4-4842-9c44-4ac4857b6618"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'dinov3'...\n",
            "remote: Enumerating objects: 538, done.\u001b[K\n",
            "remote: Counting objects: 100% (362/362), done.\u001b[K\n",
            "remote: Compressing objects: 100% (263/263), done.\u001b[K\n",
            "remote: Total 538 (delta 199), reused 99 (delta 99), pack-reused 176 (from 1)\u001b[K\n",
            "Receiving objects: 100% (538/538), 9.88 MiB | 10.63 MiB/s, done.\n",
            "Resolving deltas: 100% (222/222), done.\n",
            "/content/dinov3\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading: \"file:///content/drive/MyDrive/AMLDataset/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\" to /root/.cache/torch/hub/checkpoints/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 327M/327M [00:08<00:00, 39.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DINOv3 blocks: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Trainability control\n",
        "# ----------------------------\n",
        "def set_trainable_last_blocks(model, n_last_blocks: int, train_final_norm=True):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad_(False)\n",
        "\n",
        "    if n_last_blocks > 0:\n",
        "        for b in model.blocks[-n_last_blocks:]:\n",
        "            for p in b.parameters():\n",
        "                p.requires_grad_(True)\n",
        "\n",
        "    if train_final_norm and hasattr(model, \"norm\"):\n",
        "        for p in model.norm.parameters():\n",
        "            p.requires_grad_(True)"
      ],
      "metadata": {
        "id": "titBKyMDE_N1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Patch tokens extraction (robust)\n",
        "# ----------------------------\n",
        "def get_patch_tokens(model, x_bchw: torch.Tensor, expected_n: int | None = None) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Returns patch tokens [B, N, C] (no CLS).\n",
        "    Nota: non verificato che le chiavi siano sempre le stesse tra versioni repo.\n",
        "    \"\"\"\n",
        "    def strip_cls_if_needed(t: torch.Tensor) -> torch.Tensor:\n",
        "        if t.ndim != 3:\n",
        "            return t\n",
        "        if expected_n is None:\n",
        "            return t[:, 1:, :] if t.shape[1] > 1 else t\n",
        "        if t.shape[1] == expected_n:\n",
        "            return t\n",
        "        if t.shape[1] == expected_n + 1:\n",
        "            return t[:, 1:, :]\n",
        "        return t\n",
        "\n",
        "    if hasattr(model, \"forward_features\"):\n",
        "        out = model.forward_features(x_bchw)\n",
        "        if isinstance(out, dict):\n",
        "            for key in [\"x_patchtokens\", \"patchtokens\", \"x_norm_patchtokens\", \"x_norm\", \"x\"]:\n",
        "                if key in out and isinstance(out[key], torch.Tensor):\n",
        "                    return strip_cls_if_needed(out[key])\n",
        "        elif torch.is_tensor(out):\n",
        "            return strip_cls_if_needed(out)\n",
        "\n",
        "    out = model(x_bchw)\n",
        "    if torch.is_tensor(out):\n",
        "        return strip_cls_if_needed(out)\n",
        "\n",
        "    raise RuntimeError(\"Could not extract patch tokens from DINOv3 output.\")"
      ],
      "metadata": {
        "id": "xqbqfh5hFC4N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Training loss (Keypoint CE)\n",
        "# ----------------------------\n",
        "def kp_ce_loss(src_tok_bnc, trg_tok_bnc, src_flat_idx, trg_flat_idx, valid_mask, temp=0.1):\n",
        "    src = F.normalize(src_tok_bnc[0], dim=-1)  # [Ns,C]\n",
        "    trg = F.normalize(trg_tok_bnc[0], dim=-1)  # [Nt,C]\n",
        "\n",
        "    if valid_mask.sum() == 0:\n",
        "        return src.new_tensor(0.0), 0\n",
        "\n",
        "    src_kp = src[src_flat_idx]              # [K,C]\n",
        "    logits = (src_kp @ trg.t()) / temp      # [K,Nt]\n",
        "\n",
        "    logits_v = logits[valid_mask]\n",
        "    gt_v     = trg_flat_idx[valid_mask]\n",
        "    loss = F.cross_entropy(logits_v, gt_v)\n",
        "    return loss, int(valid_mask.sum().item())"
      ],
      "metadata": {
        "id": "cUwFsKrfFF8V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Evaluation helpers\n",
        "# ----------------------------\n",
        "@torch.no_grad()\n",
        "def tokens_to_featuremap(tok_bnc, hg, wg):\n",
        "    t = tok_bnc[0]  # [N,C]\n",
        "    if t.shape[0] != hg * wg:\n",
        "        raise RuntimeError(f\"N={t.shape[0]} != hg*wg={hg*wg}\")\n",
        "    return F.normalize(t.view(hg, wg, -1), dim=-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def argmax_cosine(Ft_flat: torch.Tensor, f_src: torch.Tensor, chunk: int = 4096) -> int:\n",
        "    best_val = None\n",
        "    best_idx = 0\n",
        "    N = Ft_flat.shape[0]\n",
        "    for s in range(0, N, chunk):\n",
        "        part = Ft_flat[s:s+chunk]\n",
        "        sim = (part * f_src).sum(dim=-1)\n",
        "        v, i = sim.max(dim=0)\n",
        "        v = float(v.item())\n",
        "        i = int(i.item()) + s\n",
        "        if (best_val is None) or (v > best_val):\n",
        "            best_val, best_idx = v, i\n",
        "    return best_idx\n",
        "\n",
        "@torch.no_grad()\n",
        "def match_one_pair(sample, sim_chunk=4096):\n",
        "    dinov3.eval()\n",
        "\n",
        "    src_img = sample[\"src_img\"].to(device)\n",
        "    trg_img = sample[\"trg_img\"].to(device)\n",
        "    src_kps = sample[\"src_kps\"].to(device)\n",
        "    trg_kps = sample[\"trg_kps\"].to(device)\n",
        "\n",
        "    src_x = normalize_img_chw_0_255(src_img)\n",
        "    trg_x = normalize_img_chw_0_255(trg_img)\n",
        "\n",
        "    src_pad, (Hs, Ws), (Hs_pad, Ws_pad) = pad_to_patch_multiple(src_x, PATCH)\n",
        "    trg_pad, (Ht, Wt), (Ht_pad, Wt_pad) = pad_to_patch_multiple(trg_x, PATCH)\n",
        "\n",
        "    hg_s, wg_s = Hs_pad // PATCH, Ws_pad // PATCH\n",
        "    hg_t, wg_t = Ht_pad // PATCH, Wt_pad // PATCH\n",
        "\n",
        "    Ns = hg_s * wg_s\n",
        "    Nt = hg_t * wg_t\n",
        "\n",
        "    src_tok = get_patch_tokens(dinov3, src_pad.unsqueeze(0), expected_n=Ns)\n",
        "    trg_tok = get_patch_tokens(dinov3, trg_pad.unsqueeze(0), expected_n=Nt)\n",
        "\n",
        "    Fs = tokens_to_featuremap(src_tok, hg_s, wg_s)\n",
        "    Ft = tokens_to_featuremap(trg_tok, hg_t, wg_t)\n",
        "    Ft_flat = Ft.view(-1, Ft.shape[-1])\n",
        "\n",
        "    preds, gts = [], []\n",
        "    for sp, gt in zip(src_kps, trg_kps):\n",
        "        if (sp[0] < 0) or (sp[1] < 0) or (gt[0] < 0) or (gt[1] < 0):\n",
        "            continue\n",
        "\n",
        "        x_src, y_src = float(sp[0].item()), float(sp[1].item())\n",
        "        x_gt,  y_gt  = float(gt[0].item()), float(gt[1].item())\n",
        "\n",
        "        if not (0.0 <= x_src < Ws and 0.0 <= y_src < Hs):\n",
        "            continue\n",
        "        if not (0.0 <= x_gt  < Wt and 0.0 <= y_gt  < Ht):\n",
        "            continue\n",
        "\n",
        "        jsrc = min(int(x_src) // PATCH, wg_s - 1)\n",
        "        isrc = min(int(y_src) // PATCH, hg_s - 1)\n",
        "        f_src = Fs[isrc, jsrc]\n",
        "\n",
        "        best = argmax_cosine(Ft_flat, f_src, chunk=sim_chunk)\n",
        "        it = best // wg_t\n",
        "        jt = best %  wg_t\n",
        "\n",
        "        x_pred = jt * PATCH + (PATCH / 2.0)\n",
        "        y_pred = it * PATCH + (PATCH / 2.0)\n",
        "\n",
        "        preds.append((x_pred, y_pred))\n",
        "        gts.append((x_gt, y_gt))\n",
        "\n",
        "    if len(preds) == 0:\n",
        "        return torch.zeros((0,2)), torch.zeros((0,2))\n",
        "    return torch.tensor(preds, dtype=torch.float32), torch.tensor(gts, dtype=torch.float32)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_pck_report(loader, name=\"EVAL\", max_pairs=None, sim_chunk=4096, print_per_category=True):\n",
        "    dinov3.eval()\n",
        "    thresholds = (0.05, 0.10, 0.20)\n",
        "\n",
        "    global_correct = {T: 0.0 for T in thresholds}\n",
        "    global_total_kp = 0.0\n",
        "    all_pck_img = {T: [] for T in thresholds}\n",
        "\n",
        "    cat_correct = {}\n",
        "    cat_total   = {}\n",
        "    cat_pck_img = {}\n",
        "\n",
        "    t0 = time.time()\n",
        "    pairs_seen = 0\n",
        "    pairs_used = 0\n",
        "\n",
        "    for batch in loader:\n",
        "        if max_pairs is not None and pairs_seen >= int(max_pairs):\n",
        "            break\n",
        "        pairs_seen += 1\n",
        "\n",
        "        sample = {\n",
        "            \"src_img\": batch[\"src_img\"][0],\n",
        "            \"trg_img\": batch[\"trg_img\"][0],\n",
        "            \"src_kps\": batch[\"src_kps\"][0],\n",
        "            \"trg_kps\": batch[\"trg_kps\"][0],\n",
        "            \"category\": batch[\"category\"][0],\n",
        "            \"trg_bbox\": batch[\"trg_bbox\"][0],\n",
        "        }\n",
        "\n",
        "        pred, gt = match_one_pair(sample, sim_chunk=sim_chunk)\n",
        "        if pred.shape[0] == 0:\n",
        "            continue\n",
        "\n",
        "        x0, y0, x1, y1 = sample[\"trg_bbox\"].detach().cpu().view(-1).tolist()\n",
        "        norm = max(float(x1 - x0), float(y1 - y0))\n",
        "        if norm <= 1e-6:\n",
        "            continue\n",
        "\n",
        "        dists = torch.linalg.norm(pred - gt, dim=1)\n",
        "        N = float(dists.numel())\n",
        "        if N <= 0:\n",
        "            continue\n",
        "\n",
        "        pairs_used += 1\n",
        "\n",
        "        global_total_kp += N\n",
        "        cat = sample[\"category\"]\n",
        "        cat_correct.setdefault(cat, {T: 0.0 for T in thresholds})\n",
        "        cat_total.setdefault(cat, 0.0)\n",
        "        cat_pck_img.setdefault(cat, {T: [] for T in thresholds})\n",
        "        cat_total[cat] += N\n",
        "\n",
        "        for T in thresholds:\n",
        "            thr = T * norm\n",
        "            correct = float((dists <= thr).float().sum().item())\n",
        "            pck_img = correct / N\n",
        "\n",
        "            global_correct[T] += correct\n",
        "            all_pck_img[T].append(pck_img)\n",
        "\n",
        "            cat_correct[cat][T] += correct\n",
        "            cat_pck_img[cat][T].append(pck_img)\n",
        "\n",
        "        if pairs_seen % 200 == 0:\n",
        "            print(f\"[{name}] seen={pairs_seen} used={pairs_used}\")\n",
        "\n",
        "    minutes = (time.time() - t0) / 60.0\n",
        "\n",
        "    mean_pck_img = {T: float(np.mean(all_pck_img[T])) if len(all_pck_img[T]) else 0.0 for T in thresholds}\n",
        "    global_pck_kp = {T: float(global_correct[T] / max(global_total_kp, 1.0)) for T in thresholds}\n",
        "\n",
        "    print(\"\\n\" + \"=\"*18 + f\" {name} REPORT \" + \"=\"*18)\n",
        "    print(f\"Pairs run: {pairs_used} (seen: {pairs_seen})\")\n",
        "    print(\"\\nGlobal PCK (per-image mean):\")\n",
        "    for T in thresholds:\n",
        "        print(f\"  PCK@{T:.2f}: {100.0*mean_pck_img[T]:.2f}%\")\n",
        "    print(\"\\nGlobal PCK (per-keypoint):\")\n",
        "    for T in thresholds:\n",
        "        print(f\"  PCK@{T:.2f}: {100.0*global_pck_kp[T]:.2f}%\")\n",
        "\n",
        "    per_cat_rows = []\n",
        "    if print_per_category and len(cat_total) > 0:\n",
        "        for cat in sorted(cat_total.keys()):\n",
        "            row = {\"Category\": cat}\n",
        "            for T in thresholds:\n",
        "                kp = float(cat_correct[cat][T] / max(cat_total[cat], 1.0))\n",
        "                im = float(np.mean(cat_pck_img[cat][T])) if len(cat_pck_img[cat][T]) else 0.0\n",
        "                row[f\"KP@{T:.2f}\"]  = 100.0 * kp\n",
        "                row[f\"IMG@{T:.2f}\"] = 100.0 * im\n",
        "            per_cat_rows.append(row)\n",
        "\n",
        "        df_cat = pd.DataFrame(per_cat_rows)\n",
        "        print(\"\\n\" + \"=\"*16 + \" PER-CATEGORY RESULTS \" + \"=\"*16)\n",
        "        cols = [\"Category\",\"KP@0.05\",\"KP@0.10\",\"KP@0.20\",\"IMG@0.05\",\"IMG@0.10\",\"IMG@0.20\"]\n",
        "        print(df_cat[cols].to_string(index=False))\n",
        "\n",
        "    print(f\"\\nMinutes: {minutes:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"pairs_seen\": pairs_seen,\n",
        "        \"pairs_run\": pairs_used,\n",
        "        \"minutes\": minutes,\n",
        "        \"global_img\": mean_pck_img,\n",
        "        \"global_kp\": global_pck_kp,\n",
        "        \"per_category\": per_cat_rows\n",
        "    }"
      ],
      "metadata": {
        "id": "2n2NNMLuFJif"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Training (steps-based) + AMP\n",
        "# ----------------------------\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "def train_steps(\n",
        "    loader,\n",
        "    n_last_blocks=1,\n",
        "    lr=1e-5,\n",
        "    weight_decay=0.05,\n",
        "    temp=0.1,\n",
        "    max_steps=2000,\n",
        "    log_every=200,\n",
        "    use_amp=True\n",
        "):\n",
        "    set_trainable_last_blocks(dinov3, n_last_blocks=n_last_blocks, train_final_norm=True)\n",
        "    dinov3.train()\n",
        "\n",
        "    params = [p for p in dinov3.parameters() if p.requires_grad]\n",
        "    n_trainable = sum(p.numel() for p in params)\n",
        "    print(f\"[train] n_last_blocks={n_last_blocks} | trainable params: {n_trainable:,}\")\n",
        "    assert n_trainable > 0, \"No trainable parameters!\"\n",
        "\n",
        "    opt = torch.optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
        "    scaler = GradScaler(\"cuda\", enabled=(use_amp and device.type == \"cuda\"))\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_kps  = 0\n",
        "    t0 = time.time()\n",
        "\n",
        "    it = iter(loader)\n",
        "    for step in range(int(max_steps)):\n",
        "        try:\n",
        "            batch = next(it)\n",
        "        except StopIteration:\n",
        "            it = iter(loader)\n",
        "            batch = next(it)\n",
        "\n",
        "        src_img = batch[\"src_img\"][0].to(device)\n",
        "        trg_img = batch[\"trg_img\"][0].to(device)\n",
        "        src_kps = batch[\"src_kps\"][0].to(device)\n",
        "        trg_kps = batch[\"trg_kps\"][0].to(device)\n",
        "\n",
        "        src_x = normalize_img_chw_0_255(src_img)\n",
        "        trg_x = normalize_img_chw_0_255(trg_img)\n",
        "        src_pad, _, (Hs_pad, Ws_pad) = pad_to_patch_multiple(src_x, PATCH)\n",
        "        trg_pad, _, (Ht_pad, Wt_pad) = pad_to_patch_multiple(trg_x, PATCH)\n",
        "\n",
        "        src_flat, src_valid, hg_s, wg_s = kps_to_flat_indices(src_kps, Hs_pad, Ws_pad, PATCH)\n",
        "        trg_flat, trg_valid, hg_t, wg_t = kps_to_flat_indices(trg_kps, Ht_pad, Wt_pad, PATCH)\n",
        "        valid = src_valid & trg_valid\n",
        "\n",
        "        Ns = hg_s * wg_s\n",
        "        Nt = hg_t * wg_t\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast(\"cuda\", enabled=scaler.is_enabled()):\n",
        "            src_tok = get_patch_tokens(dinov3, src_pad.unsqueeze(0), expected_n=Ns)\n",
        "            trg_tok = get_patch_tokens(dinov3, trg_pad.unsqueeze(0), expected_n=Nt)\n",
        "            loss, nvalid = kp_ce_loss(src_tok, trg_tok, src_flat, trg_flat, valid, temp=temp)\n",
        "\n",
        "        if nvalid == 0:\n",
        "            continue\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += float(loss.item()) * nvalid\n",
        "        running_kps  += nvalid\n",
        "\n",
        "        if (step + 1) % log_every == 0:\n",
        "            avg = running_loss / max(running_kps, 1)\n",
        "            dt = time.time() - t0\n",
        "            print(f\"[train] step {step+1}/{max_steps} | avg_loss {avg:.4f} | seen_kps {running_kps} | {dt:.1f}s\")\n",
        "\n",
        "    return running_loss / max(running_kps, 1)"
      ],
      "metadata": {
        "id": "Twq9R8DFFN0s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Sanity: overfit quick\n",
        "# ----------------------------\n",
        "def overfit_sanity(\n",
        "    train_loader, val_loader,\n",
        "    n_last_blocks=2,\n",
        "    lr=5e-5,\n",
        "    weight_decay=0.05,\n",
        "    temp=0.1,\n",
        "    steps=800,\n",
        "    eval_pairs=200\n",
        "):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SANITY CHECK: OVERFIT\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Baseline frozen\n",
        "    restore_pretrained()\n",
        "    set_trainable_last_blocks(dinov3, 0)\n",
        "    dinov3.eval()\n",
        "    base = evaluate_pck_report(val_loader, name=\"VAL (baseline, frozen)\", max_pairs=eval_pairs, print_per_category=False)\n",
        "\n",
        "    # Train\n",
        "    restore_pretrained()\n",
        "    avg_loss = train_steps(\n",
        "        train_loader,\n",
        "        n_last_blocks=n_last_blocks,\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,\n",
        "        temp=temp,\n",
        "        max_steps=steps,\n",
        "        log_every=200\n",
        "    )\n",
        "\n",
        "    # Evaluate after training\n",
        "    dinov3.eval()\n",
        "    fin = evaluate_pck_report(val_loader, name=\"VAL (after overfit)\", max_pairs=eval_pairs, print_per_category=False)\n",
        "\n",
        "    print(f\"\\n[overfit] avg_train_loss: {avg_loss:.4f}\")\n",
        "    print(f\"[overfit] baseline VAL KP@0.10: {100*base['global_kp'][0.10]:.2f}% -> after: {100*fin['global_kp'][0.10]:.2f}%\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# LR finder quick\n",
        "# ----------------------------\n",
        "def lr_finder(\n",
        "    train_loader, val_loader,\n",
        "    n_last_blocks=2,\n",
        "    lrs=(1e-6, 3e-6, 1e-5, 3e-5, 1e-4),\n",
        "    weight_decay=0.05,\n",
        "    temp=0.1,\n",
        "    train_steps_each=200,\n",
        "    eval_pairs=300\n",
        "):\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LR FINDER\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    rows = []\n",
        "    for lr in lrs:\n",
        "        print(\"\\n\" + \"-\"*60)\n",
        "        print(f\"[lr_finder] lr={lr:g} | blocks={n_last_blocks}\")\n",
        "        print(\"-\"*60)\n",
        "\n",
        "        restore_pretrained()\n",
        "        avg_loss = train_steps(\n",
        "            train_loader,\n",
        "            n_last_blocks=n_last_blocks,\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay,\n",
        "            temp=temp,\n",
        "            max_steps=train_steps_each,\n",
        "            log_every=200\n",
        "        )\n",
        "\n",
        "        dinov3.eval()\n",
        "        val_rep = evaluate_pck_report(val_loader, name=f\"VAL (lr={lr:g})\", max_pairs=eval_pairs, print_per_category=False)\n",
        "\n",
        "        rows.append({\n",
        "            \"lr\": lr,\n",
        "            \"n_last_blocks\": n_last_blocks,\n",
        "            \"avg_train_loss\": float(avg_loss),\n",
        "            \"val_kp_PCK@0.05\": 100*val_rep[\"global_kp\"][0.05],\n",
        "            \"val_kp_PCK@0.10\": 100*val_rep[\"global_kp\"][0.10],\n",
        "            \"val_kp_PCK@0.20\": 100*val_rep[\"global_kp\"][0.20],\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values(\"lr\").reset_index(drop=True)\n",
        "    print(\"\\n=== LR FINDER SUMMARY ===\")\n",
        "    print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\" if x < 1 else f\"{x:.2f}\"))\n",
        "    return df\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Sweep on SMALL (VAL selection only) — NO TEST HERE\n",
        "# ----------------------------\n",
        "def sweep_blocks_on_val(\n",
        "    train_loader, val_loader,\n",
        "    settings=(0,1,2,4),\n",
        "    lr=3e-5,\n",
        "    temp=0.1,\n",
        "    weight_decay=0.05,\n",
        "    train_steps_per_setting=2000,\n",
        "    val_pairs=None,\n",
        "    select_on=\"KP@0.10\"  # either \"KP@0.10\" or \"IMG@0.10\"\n",
        "):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"SWEEP (VAL ONLY) — selecting best on VAL\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Baseline frozen on VAL\n",
        "    restore_pretrained()\n",
        "    set_trainable_last_blocks(dinov3, 0)\n",
        "    dinov3.eval()\n",
        "    base_val = evaluate_pck_report(val_loader, name=\"VAL BASELINE (frozen)\", max_pairs=val_pairs, print_per_category=False)\n",
        "\n",
        "    rows = []\n",
        "    for n_last_blocks in settings:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"RUN setting: n_last_blocks={n_last_blocks}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        restore_pretrained()\n",
        "        avg_loss = None\n",
        "\n",
        "        if n_last_blocks > 0:\n",
        "            avg_loss = train_steps(\n",
        "                train_loader,\n",
        "                n_last_blocks=n_last_blocks,\n",
        "                lr=lr,\n",
        "                weight_decay=weight_decay,\n",
        "                temp=temp,\n",
        "                max_steps=train_steps_per_setting,\n",
        "                log_every=200\n",
        "            )\n",
        "\n",
        "        dinov3.eval()\n",
        "        val_rep = evaluate_pck_report(\n",
        "            val_loader,\n",
        "            name=f\"VAL FINETUNED (blocks={n_last_blocks})\",\n",
        "            max_pairs=val_pairs,\n",
        "            print_per_category=False\n",
        "        )\n",
        "\n",
        "        rows.append({\n",
        "            \"n_last_blocks\": n_last_blocks,\n",
        "            \"lr\": lr,\n",
        "            \"temp\": temp,\n",
        "            \"train_steps\": int(train_steps_per_setting) if n_last_blocks > 0 else 0,\n",
        "            \"avg_train_loss\": float(avg_loss) if avg_loss is not None else None,\n",
        "            \"val_kp_PCK@0.05\": 100 * val_rep[\"global_kp\"][0.05],\n",
        "            \"val_kp_PCK@0.10\": 100 * val_rep[\"global_kp\"][0.10],\n",
        "            \"val_kp_PCK@0.20\": 100 * val_rep[\"global_kp\"][0.20],\n",
        "            \"val_img_PCK@0.10\": 100 * val_rep[\"global_img\"][0.10],\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values(\"n_last_blocks\").reset_index(drop=True)\n",
        "    print(\"\\n=== SWEEP SUMMARY (VAL) ===\")\n",
        "    print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\" if abs(x) < 1 else f\"{x:.2f}\"))\n",
        "\n",
        "    # Select best\n",
        "    if select_on == \"IMG@0.10\":\n",
        "        metric_col = \"val_img_PCK@0.10\"\n",
        "    else:\n",
        "        metric_col = \"val_kp_PCK@0.10\"\n",
        "\n",
        "    best_idx = int(df[metric_col].astype(float).idxmax())\n",
        "    best_blocks = int(df.loc[best_idx, \"n_last_blocks\"])\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"BEST on VAL by {select_on}: n_last_blocks={best_blocks}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return df, best_blocks, base_val"
      ],
      "metadata": {
        "id": "-gpmwX52FQew"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_large_run_no_sweep(\n",
        "    train_loader_l, val_loader_l, test_loader_l,\n",
        "    best_blocks: int,\n",
        "    lr: float,\n",
        "    temp=0.1,\n",
        "    weight_decay=0.05,\n",
        "    train_steps_best=2000,\n",
        "):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FINAL LARGE RUN (NO SWEEP)\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Using best_blocks={best_blocks} | lr={lr:g} | temp={temp} | wd={weight_decay} | steps={train_steps_best}\")\n",
        "\n",
        "    # ---- BASELINE (FROZEN) ----\n",
        "    restore_pretrained()\n",
        "    set_trainable_last_blocks(dinov3, 0)\n",
        "    dinov3.eval()\n",
        "\n",
        "    base_val_l = evaluate_pck_report(val_loader_l,  name=\"VAL LARGE BASELINE (frozen)\",  max_pairs=None, print_per_category=True)\n",
        "    base_test_l = evaluate_pck_report(test_loader_l, name=\"TEST LARGE BASELINE (frozen)\", max_pairs=None, print_per_category=True)\n",
        "\n",
        "    # ---- TRAIN BEST ON TRAIN LARGE ----\n",
        "    restore_pretrained()\n",
        "    if best_blocks > 0:\n",
        "        _ = train_steps(\n",
        "            train_loader_l,\n",
        "            n_last_blocks=best_blocks,\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay,\n",
        "            temp=temp,\n",
        "            max_steps=train_steps_best,\n",
        "            log_every=200\n",
        "        )\n",
        "\n",
        "    # ---- EVAL BEST ----\n",
        "    dinov3.eval()\n",
        "    best_val_l = evaluate_pck_report(val_loader_l,  name=f\"VAL LARGE BEST (blocks={best_blocks})\",  max_pairs=None, print_per_category=True)\n",
        "    best_test_l = evaluate_pck_report(test_loader_l, name=f\"TEST LARGE BEST (blocks={best_blocks})\", max_pairs=None, print_per_category=True)\n",
        "\n",
        "    return base_val_l, best_val_l, base_test_l, best_test_l"
      ],
      "metadata": {
        "id": "mOpLBxc22VN0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Final summary table (KP only) + deltas\n",
        "# ----------------------------\n",
        "def make_final_kp_table(base_val, best_val, base_test, best_test, best_blocks):\n",
        "    def row(split, model_name, rep):\n",
        "        return {\n",
        "            \"Split\": split,\n",
        "            \"Model\": model_name,\n",
        "            \"KP@0.05\": 100 * rep[\"global_kp\"][0.05],\n",
        "            \"KP@0.10\": 100 * rep[\"global_kp\"][0.10],\n",
        "            \"KP@0.20\": 100 * rep[\"global_kp\"][0.20],\n",
        "        }\n",
        "\n",
        "    rows = []\n",
        "    rows.append(row(\"VAL\", \"Frozen\", base_val))\n",
        "    rows.append(row(\"VAL\", f\"Best (blocks={best_blocks})\", best_val))\n",
        "    rows.append({\n",
        "        \"Split\": \"VAL\",\n",
        "        \"Model\": \"Δ Best - Frozen\",\n",
        "        \"KP@0.05\": 100*best_val[\"global_kp\"][0.05] - 100*base_val[\"global_kp\"][0.05],\n",
        "        \"KP@0.10\": 100*best_val[\"global_kp\"][0.10] - 100*base_val[\"global_kp\"][0.10],\n",
        "        \"KP@0.20\": 100*best_val[\"global_kp\"][0.20] - 100*base_val[\"global_kp\"][0.20],\n",
        "    })\n",
        "\n",
        "    if base_test is not None:\n",
        "        rows.append(row(\"TEST\", \"Frozen\", base_test))\n",
        "        rows.append(row(\"TEST\", f\"Best (blocks={best_blocks})\", best_test))\n",
        "        rows.append({\n",
        "            \"Split\": \"TEST\",\n",
        "            \"Model\": \"Δ Best - Frozen\",\n",
        "            \"KP@0.05\": 100*best_test[\"global_kp\"][0.05] - 100*base_test[\"global_kp\"][0.05],\n",
        "            \"KP@0.10\": 100*best_test[\"global_kp\"][0.10] - 100*base_test[\"global_kp\"][0.10],\n",
        "            \"KP@0.20\": 100*best_test[\"global_kp\"][0.20] - 100*base_test[\"global_kp\"][0.20],\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def make_final_img_table(base_val, best_val, base_test, best_test, best_blocks):\n",
        "    def row(split, model_name, rep):\n",
        "        return {\n",
        "            \"Split\": split,\n",
        "            \"Model\": model_name,\n",
        "            \"IMG@0.05\": 100 * rep[\"global_img\"][0.05],\n",
        "            \"IMG@0.10\": 100 * rep[\"global_img\"][0.10],\n",
        "            \"IMG@0.20\": 100 * rep[\"global_img\"][0.20],\n",
        "        }\n",
        "\n",
        "    rows = []\n",
        "    rows.append(row(\"VAL\", \"Frozen\", base_val))\n",
        "    rows.append(row(\"VAL\", f\"Best (blocks={best_blocks})\", best_val))\n",
        "    rows.append({\n",
        "        \"Split\": \"VAL\",\n",
        "        \"Model\": \"Δ Best - Frozen\",\n",
        "        \"IMG@0.05\": 100*best_val[\"global_img\"][0.05] - 100*base_val[\"global_img\"][0.05],\n",
        "        \"IMG@0.10\": 100*best_val[\"global_img\"][0.10] - 100*base_val[\"global_img\"][0.10],\n",
        "        \"IMG@0.20\": 100*best_val[\"global_img\"][0.20] - 100*base_val[\"global_img\"][0.20],\n",
        "    })\n",
        "\n",
        "    if base_test is not None:\n",
        "        rows.append(row(\"TEST\", \"Frozen\", base_test))\n",
        "        rows.append(row(\"TEST\", f\"Best (blocks={best_blocks})\", best_test))\n",
        "        rows.append({\n",
        "            \"Split\": \"TEST\",\n",
        "            \"Model\": \"Δ Best - Frozen\",\n",
        "            \"IMG@0.05\": 100*best_test[\"global_img\"][0.05] - 100*base_test[\"global_img\"][0.05],\n",
        "            \"IMG@0.10\": 100*best_test[\"global_img\"][0.10] - 100*base_test[\"global_img\"][0.10],\n",
        "            \"IMG@0.20\": 100*best_test[\"global_img\"][0.20] - 100*base_test[\"global_img\"][0.20],\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n"
      ],
      "metadata": {
        "id": "w4AxEB3OFWF3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# RUN SECTION (FULL: val_pairs=None, test_pairs=None)\n",
        "# ============================================================"
      ],
      "metadata": {
        "id": "JOKg-xK0FYRL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0) Overfit sanity on SMALL ---\n",
        "overfit_sanity(\n",
        "    train_loader_s, val_loader_s,\n",
        "    n_last_blocks=2,\n",
        "    lr=5e-5,\n",
        "    weight_decay=0.05,\n",
        "    temp=0.1,\n",
        "    steps=800,\n",
        "    eval_pairs=200\n",
        ")\n",
        "\n",
        "# --- 1) LR finder on SMALL ---\n",
        "df_lr = lr_finder(\n",
        "    train_loader_s, val_loader_s,\n",
        "    n_last_blocks=2,\n",
        "    lrs=(1e-6, 3e-6, 1e-5, 3e-5, 1e-4),\n",
        "    weight_decay=0.05,\n",
        "    temp=0.1,\n",
        "    train_steps_each=200,\n",
        "    eval_pairs=300\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XF7TpwjHLVL",
        "outputId": "2fb11eef-8050-4fe8-fd79-e18f194a3221"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SANITY CHECK: OVERFIT\n",
            "======================================================================\n",
            "[VAL (baseline, frozen)] seen=200 used=200\n",
            "\n",
            "================== VAL (baseline, frozen) REPORT ==================\n",
            "Pairs run: 200 (seen: 200)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 34.60%\n",
            "  PCK@0.10: 52.54%\n",
            "  PCK@0.20: 63.43%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 37.14%\n",
            "  PCK@0.10: 55.20%\n",
            "  PCK@0.20: 67.32%\n",
            "\n",
            "Minutes: 0.1622\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/800 | avg_loss 3.7585 | seen_kps 1428 | 172.6s\n",
            "[train] step 400/800 | avg_loss 3.3729 | seen_kps 2868 | 348.5s\n",
            "[train] step 600/800 | avg_loss 3.1745 | seen_kps 4391 | 521.3s\n",
            "[train] step 800/800 | avg_loss 3.0239 | seen_kps 5859 | 695.0s\n",
            "[VAL (after overfit)] seen=200 used=200\n",
            "\n",
            "================== VAL (after overfit) REPORT ==================\n",
            "Pairs run: 200 (seen: 200)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 54.29%\n",
            "  PCK@0.10: 73.54%\n",
            "  PCK@0.20: 84.75%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 55.04%\n",
            "  PCK@0.10: 73.49%\n",
            "  PCK@0.20: 85.54%\n",
            "\n",
            "Minutes: 0.1528\n",
            "\n",
            "[overfit] avg_train_loss: 3.0239\n",
            "[overfit] baseline VAL KP@0.10: 55.20% -> after: 73.49%\n",
            "\n",
            "======================================================================\n",
            "LR FINDER\n",
            "======================================================================\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=1e-06 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/200 | avg_loss 4.7527 | seen_kps 1402 | 162.7s\n",
            "[VAL (lr=1e-06)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=1e-06) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 30.35%\n",
            "  PCK@0.10: 47.39%\n",
            "  PCK@0.20: 60.54%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 32.76%\n",
            "  PCK@0.10: 50.36%\n",
            "  PCK@0.20: 64.86%\n",
            "\n",
            "Minutes: 0.2304\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=3e-06 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/200 | avg_loss 4.6250 | seen_kps 1388 | 155.3s\n",
            "[VAL (lr=3e-06)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=3e-06) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 31.77%\n",
            "  PCK@0.10: 48.80%\n",
            "  PCK@0.20: 62.74%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 33.85%\n",
            "  PCK@0.10: 51.50%\n",
            "  PCK@0.20: 66.77%\n",
            "\n",
            "Minutes: 0.2334\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=1e-05 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/200 | avg_loss 4.2919 | seen_kps 1452 | 155.7s\n",
            "[VAL (lr=1e-05)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=1e-05) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 35.86%\n",
            "  PCK@0.10: 54.61%\n",
            "  PCK@0.20: 69.02%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 38.15%\n",
            "  PCK@0.10: 57.04%\n",
            "  PCK@0.20: 72.46%\n",
            "\n",
            "Minutes: 0.2368\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=3e-05 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/200 | avg_loss 3.9634 | seen_kps 1447 | 148.8s\n",
            "[VAL (lr=3e-05)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=3e-05) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 43.58%\n",
            "  PCK@0.10: 63.48%\n",
            "  PCK@0.20: 76.67%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 44.57%\n",
            "  PCK@0.10: 63.66%\n",
            "  PCK@0.20: 78.36%\n",
            "\n",
            "Minutes: 0.2342\n",
            "\n",
            "------------------------------------------------------------\n",
            "[lr_finder] lr=0.0001 | blocks=2\n",
            "------------------------------------------------------------\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/200 | avg_loss 3.3588 | seen_kps 1458 | 153.3s\n",
            "[VAL (lr=0.0001)] seen=200 used=200\n",
            "\n",
            "================== VAL (lr=0.0001) REPORT ==================\n",
            "Pairs run: 300 (seen: 300)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 47.62%\n",
            "  PCK@0.10: 67.70%\n",
            "  PCK@0.20: 79.71%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 49.17%\n",
            "  PCK@0.10: 69.00%\n",
            "  PCK@0.20: 81.94%\n",
            "\n",
            "Minutes: 0.2331\n",
            "\n",
            "=== LR FINDER SUMMARY ===\n",
            "    lr  n_last_blocks  avg_train_loss  val_kp_PCK@0.05  val_kp_PCK@0.10  val_kp_PCK@0.20\n",
            "0.0000              2            4.75            32.76            50.36            64.86\n",
            "0.0000              2            4.63            33.85            51.50            66.77\n",
            "0.0000              2            4.29            38.15            57.04            72.46\n",
            "0.0000              2            3.96            44.57            63.66            78.36\n",
            "0.0001              2            3.36            49.17            69.00            81.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick LR_FINAL manually based on df_lr\n",
        "LR_FINAL = 3e-5\n",
        "\n",
        "# --- 2) Sweep blocks on SMALL (VAL only) ---\n",
        "df_sweep_s, best_blocks_s, base_val_s = sweep_blocks_on_val(\n",
        "    train_loader_s, val_loader_s,\n",
        "    settings=(0,1,2,4),\n",
        "    lr=LR_FINAL,\n",
        "    temp=0.1,\n",
        "    weight_decay=0.05,\n",
        "    train_steps_per_setting=2000,\n",
        "    val_pairs=None,         # full VAL small\n",
        "    select_on=\"KP@0.10\"\n",
        ")\n",
        "\n",
        "print(\"\\n[TUNING DONE] best_blocks_s =\", best_blocks_s, \"| LR_FINAL =\", LR_FINAL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSL2JAAeHQNW",
        "outputId": "8b71e57a-b9c5-49f8-fcf2-c881164728b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SWEEP (VAL ONLY) — selecting best on VAL\n",
            "================================================================================\n",
            "[VAL BASELINE (frozen)] seen=200 used=200\n",
            "[VAL BASELINE (frozen)] seen=400 used=400\n",
            "[VAL BASELINE (frozen)] seen=600 used=600\n",
            "[VAL BASELINE (frozen)] seen=800 used=800\n",
            "[VAL BASELINE (frozen)] seen=1000 used=1000\n",
            "\n",
            "================== VAL BASELINE (frozen) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 28.82%\n",
            "  PCK@0.10: 46.25%\n",
            "  PCK@0.20: 61.13%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 31.76%\n",
            "  PCK@0.10: 50.23%\n",
            "  PCK@0.20: 66.28%\n",
            "\n",
            "Minutes: 20.8490\n",
            "\n",
            "======================================================================\n",
            "RUN setting: n_last_blocks=0\n",
            "======================================================================\n",
            "[VAL FINETUNED (blocks=0)] seen=200 used=200\n",
            "[VAL FINETUNED (blocks=0)] seen=400 used=400\n",
            "[VAL FINETUNED (blocks=0)] seen=600 used=600\n",
            "[VAL FINETUNED (blocks=0)] seen=800 used=800\n",
            "[VAL FINETUNED (blocks=0)] seen=1000 used=1000\n",
            "\n",
            "================== VAL FINETUNED (blocks=0) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 28.82%\n",
            "  PCK@0.10: 46.25%\n",
            "  PCK@0.20: 61.13%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 31.76%\n",
            "  PCK@0.10: 50.23%\n",
            "  PCK@0.20: 66.28%\n",
            "\n",
            "Minutes: 0.8384\n",
            "\n",
            "======================================================================\n",
            "RUN setting: n_last_blocks=1\n",
            "======================================================================\n",
            "[train] n_last_blocks=1 | trainable params: 7,090,944\n",
            "[train] step 200/2000 | avg_loss 4.3754 | seen_kps 1374 | 654.3s\n",
            "[train] step 400/2000 | avg_loss 4.1083 | seen_kps 2784 | 1015.2s\n",
            "[train] step 600/2000 | avg_loss 3.8951 | seen_kps 4183 | 1309.7s\n",
            "[train] step 800/2000 | avg_loss 3.7899 | seen_kps 5566 | 1571.6s\n",
            "[train] step 1000/2000 | avg_loss 3.7054 | seen_kps 6966 | 1799.4s\n",
            "[train] step 1200/2000 | avg_loss 3.6067 | seen_kps 8444 | 2009.0s\n",
            "[train] step 1400/2000 | avg_loss 3.5238 | seen_kps 9815 | 2208.4s\n",
            "[train] step 1600/2000 | avg_loss 3.4674 | seen_kps 11197 | 2402.5s\n",
            "[train] step 1800/2000 | avg_loss 3.4104 | seen_kps 12611 | 2586.3s\n",
            "[train] step 2000/2000 | avg_loss 3.3556 | seen_kps 14063 | 2772.2s\n",
            "[VAL FINETUNED (blocks=1)] seen=200 used=200\n",
            "[VAL FINETUNED (blocks=1)] seen=400 used=400\n",
            "[VAL FINETUNED (blocks=1)] seen=600 used=600\n",
            "[VAL FINETUNED (blocks=1)] seen=800 used=800\n",
            "[VAL FINETUNED (blocks=1)] seen=1000 used=1000\n",
            "\n",
            "================== VAL FINETUNED (blocks=1) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 41.84%\n",
            "  PCK@0.10: 61.05%\n",
            "  PCK@0.20: 75.25%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 43.63%\n",
            "  PCK@0.10: 63.17%\n",
            "  PCK@0.20: 78.48%\n",
            "\n",
            "Minutes: 0.8388\n",
            "\n",
            "======================================================================\n",
            "RUN setting: n_last_blocks=2\n",
            "======================================================================\n",
            "[train] n_last_blocks=2 | trainable params: 14,180,352\n",
            "[train] step 200/2000 | avg_loss 3.8812 | seen_kps 1410 | 160.0s\n",
            "[train] step 400/2000 | avg_loss 3.5915 | seen_kps 2827 | 309.7s\n",
            "[train] step 600/2000 | avg_loss 3.4012 | seen_kps 4184 | 455.7s\n",
            "[train] step 800/2000 | avg_loss 3.2608 | seen_kps 5591 | 610.3s\n",
            "[train] step 1000/2000 | avg_loss 3.1381 | seen_kps 7064 | 766.9s\n",
            "[train] step 1200/2000 | avg_loss 3.0578 | seen_kps 8424 | 907.7s\n",
            "[train] step 1400/2000 | avg_loss 2.9848 | seen_kps 9800 | 1063.6s\n",
            "[train] step 1600/2000 | avg_loss 2.9195 | seen_kps 11230 | 1213.9s\n",
            "[train] step 1800/2000 | avg_loss 2.8569 | seen_kps 12741 | 1370.5s\n",
            "[train] step 2000/2000 | avg_loss 2.8071 | seen_kps 14082 | 1515.3s\n",
            "[VAL FINETUNED (blocks=2)] seen=200 used=200\n",
            "[VAL FINETUNED (blocks=2)] seen=400 used=400\n",
            "[VAL FINETUNED (blocks=2)] seen=600 used=600\n",
            "[VAL FINETUNED (blocks=2)] seen=800 used=800\n",
            "[VAL FINETUNED (blocks=2)] seen=1000 used=1000\n",
            "\n",
            "================== VAL FINETUNED (blocks=2) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 49.31%\n",
            "  PCK@0.10: 68.29%\n",
            "  PCK@0.20: 80.36%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 51.54%\n",
            "  PCK@0.10: 71.44%\n",
            "  PCK@0.20: 84.39%\n",
            "\n",
            "Minutes: 0.8434\n",
            "\n",
            "======================================================================\n",
            "RUN setting: n_last_blocks=4\n",
            "======================================================================\n",
            "[train] n_last_blocks=4 | trainable params: 28,359,168\n",
            "[train] step 200/2000 | avg_loss 3.7388 | seen_kps 1408 | 121.5s\n",
            "[train] step 400/2000 | avg_loss 3.3328 | seen_kps 2779 | 241.4s\n",
            "[train] step 600/2000 | avg_loss 3.1156 | seen_kps 4148 | 367.8s\n",
            "[train] step 800/2000 | avg_loss 2.9646 | seen_kps 5434 | 487.9s\n",
            "[train] step 1000/2000 | avg_loss 2.8339 | seen_kps 6793 | 614.5s\n",
            "[train] step 1200/2000 | avg_loss 2.7460 | seen_kps 8184 | 742.5s\n",
            "[train] step 1400/2000 | avg_loss 2.6745 | seen_kps 9575 | 862.9s\n",
            "[train] step 1600/2000 | avg_loss 2.6015 | seen_kps 10933 | 990.9s\n",
            "[train] step 1800/2000 | avg_loss 2.5288 | seen_kps 12328 | 1113.2s\n",
            "[train] step 2000/2000 | avg_loss 2.4688 | seen_kps 13693 | 1237.6s\n",
            "[VAL FINETUNED (blocks=4)] seen=200 used=200\n",
            "[VAL FINETUNED (blocks=4)] seen=400 used=400\n",
            "[VAL FINETUNED (blocks=4)] seen=600 used=600\n",
            "[VAL FINETUNED (blocks=4)] seen=800 used=800\n",
            "[VAL FINETUNED (blocks=4)] seen=1000 used=1000\n",
            "\n",
            "================== VAL FINETUNED (blocks=4) REPORT ==================\n",
            "Pairs run: 1070 (seen: 1070)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 54.10%\n",
            "  PCK@0.10: 71.73%\n",
            "  PCK@0.20: 83.33%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 55.76%\n",
            "  PCK@0.10: 74.25%\n",
            "  PCK@0.20: 86.63%\n",
            "\n",
            "Minutes: 0.8591\n",
            "\n",
            "=== SWEEP SUMMARY (VAL) ===\n",
            " n_last_blocks     lr   temp  train_steps  avg_train_loss  val_kp_PCK@0.05  val_kp_PCK@0.10  val_kp_PCK@0.20  val_img_PCK@0.10\n",
            "             0 0.0000 0.1000            0             NaN            31.76            50.23            66.28             46.25\n",
            "             1 0.0000 0.1000         2000            3.36            43.63            63.17            78.48             61.05\n",
            "             2 0.0000 0.1000         2000            2.81            51.54            71.44            84.39             68.29\n",
            "             4 0.0000 0.1000         2000            2.47            55.76            74.25            86.63             71.73\n",
            "\n",
            "======================================================================\n",
            "BEST on VAL by KP@0.10: n_last_blocks=4\n",
            "======================================================================\n",
            "\n",
            "[TUNING DONE] best_blocks_s = 4 | LR_FINAL = 3e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3) FINAL on LARGE (baseline + best only, no sweep) ---\n",
        "base_val_l, best_val_l, base_test_l, best_test_l = final_large_run_no_sweep(\n",
        "    train_loader_l, val_loader_l, test_loader_l,\n",
        "    best_blocks=int(best_blocks_s),\n",
        "    lr=float(LR_FINAL),\n",
        "    temp=0.1,\n",
        "    weight_decay=0.05,\n",
        "    train_steps_best=2000\n",
        ")\n",
        "\n",
        "print(\"\\n=== FINAL KP SUMMARY (VAL + TEST) ===\")\n",
        "df_final_kp = make_final_kp_table(base_val_l, best_val_l, base_test_l, best_test_l, int(best_blocks_s))\n",
        "print(df_final_kp.to_string(index=False, float_format=lambda x: f\"{x:.2f}\"))\n",
        "\n",
        "print(\"\\n=== FINAL IMG SUMMARY (VAL + TEST) ===\")\n",
        "df_final_img = make_final_img_table(base_val_l, best_val_l, base_test_l, best_test_l, int(best_blocks_s))\n",
        "print(df_final_img.to_string(index=False, float_format=lambda x: f\"{x:.2f}\"))\n",
        "\n",
        "print(\"\\n=== DONE ===\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWARF_dU2gt0",
        "outputId": "431a0efa-d12f-4767-a8b5-e054b1a2ba2e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL LARGE RUN (NO SWEEP)\n",
            "================================================================================\n",
            "Using best_blocks=4 | lr=3e-05 | temp=0.1 | wd=0.05 | steps=2000\n",
            "[VAL LARGE BASELINE (frozen)] seen=200 used=200\n",
            "[VAL LARGE BASELINE (frozen)] seen=400 used=400\n",
            "[VAL LARGE BASELINE (frozen)] seen=600 used=600\n",
            "[VAL LARGE BASELINE (frozen)] seen=800 used=800\n",
            "[VAL LARGE BASELINE (frozen)] seen=1000 used=1000\n",
            "[VAL LARGE BASELINE (frozen)] seen=1200 used=1200\n",
            "[VAL LARGE BASELINE (frozen)] seen=1400 used=1400\n",
            "[VAL LARGE BASELINE (frozen)] seen=1600 used=1600\n",
            "[VAL LARGE BASELINE (frozen)] seen=1800 used=1800\n",
            "[VAL LARGE BASELINE (frozen)] seen=2000 used=2000\n",
            "[VAL LARGE BASELINE (frozen)] seen=2200 used=2200\n",
            "[VAL LARGE BASELINE (frozen)] seen=2400 used=2400\n",
            "[VAL LARGE BASELINE (frozen)] seen=2600 used=2600\n",
            "[VAL LARGE BASELINE (frozen)] seen=2800 used=2800\n",
            "[VAL LARGE BASELINE (frozen)] seen=3000 used=3000\n",
            "[VAL LARGE BASELINE (frozen)] seen=3200 used=3200\n",
            "[VAL LARGE BASELINE (frozen)] seen=3400 used=3400\n",
            "[VAL LARGE BASELINE (frozen)] seen=3600 used=3600\n",
            "[VAL LARGE BASELINE (frozen)] seen=3800 used=3800\n",
            "[VAL LARGE BASELINE (frozen)] seen=4000 used=4000\n",
            "[VAL LARGE BASELINE (frozen)] seen=4200 used=4200\n",
            "[VAL LARGE BASELINE (frozen)] seen=4400 used=4400\n",
            "[VAL LARGE BASELINE (frozen)] seen=4600 used=4600\n",
            "[VAL LARGE BASELINE (frozen)] seen=4800 used=4800\n",
            "[VAL LARGE BASELINE (frozen)] seen=5000 used=5000\n",
            "[VAL LARGE BASELINE (frozen)] seen=5200 used=5200\n",
            "\n",
            "================== VAL LARGE BASELINE (frozen) REPORT ==================\n",
            "Pairs run: 5384 (seen: 5384)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 29.45%\n",
            "  PCK@0.10: 45.93%\n",
            "  PCK@0.20: 60.93%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 32.58%\n",
            "  PCK@0.10: 50.61%\n",
            "  PCK@0.20: 66.52%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "   Category   KP@0.05   KP@0.10   KP@0.20  IMG@0.05  IMG@0.10  IMG@0.20\n",
            "  aeroplane 38.987252 53.222380 67.776204 35.931334 50.354468 65.167830\n",
            "    bicycle 34.720571 49.286564 62.128419 33.748488 46.841760 59.104626\n",
            "       bird 44.296578 67.427123 81.622307 43.465511 67.462466 81.464766\n",
            "       boat 18.450704 30.563380 44.436620 14.332492 23.524913 34.569011\n",
            "     bottle 25.768406 46.211580 63.330951 24.315635 43.050993 59.458662\n",
            "        bus 28.669154 42.412935 52.425373 21.064639 31.842107 40.264978\n",
            "        car 34.375000 51.432292 63.085938 27.893874 41.700444 54.105640\n",
            "        cat 60.950413 75.371901 85.082645 57.385260 71.056359 82.083852\n",
            "      chair 25.439560 37.637363 50.054945 21.594564 31.965111 43.445614\n",
            "        cow 36.614646 53.661465 68.667467 35.283090 51.380970 66.082090\n",
            "        dog 37.411208 54.340963 68.626677 34.996621 51.599522 65.819005\n",
            "      horse 35.441426 56.706282 73.599321 37.298791 57.806873 74.336856\n",
            "  motorbike 19.921875 40.234375 57.812500 17.642224 38.267807 54.631019\n",
            "     person 40.252393 60.791993 76.066144 36.751437 56.628582 72.207666\n",
            "pottedplant 13.014981 27.715356 49.110487 12.250209 26.018901 46.879699\n",
            "      sheep 33.093525 55.107914 69.640288 29.773834 49.069170 63.162481\n",
            "      train 30.378251 50.330969 70.212766 29.013174 48.366065 67.804138\n",
            "  tvmonitor 24.108053 47.273191 69.597350 23.188842 46.414123 68.690907\n",
            "\n",
            "Minutes: 64.7863\n",
            "[TEST LARGE BASELINE (frozen)] seen=200 used=200\n",
            "[TEST LARGE BASELINE (frozen)] seen=400 used=400\n",
            "[TEST LARGE BASELINE (frozen)] seen=600 used=600\n",
            "[TEST LARGE BASELINE (frozen)] seen=800 used=800\n",
            "[TEST LARGE BASELINE (frozen)] seen=1000 used=1000\n",
            "[TEST LARGE BASELINE (frozen)] seen=1200 used=1200\n",
            "[TEST LARGE BASELINE (frozen)] seen=1400 used=1400\n",
            "[TEST LARGE BASELINE (frozen)] seen=1600 used=1600\n",
            "[TEST LARGE BASELINE (frozen)] seen=1800 used=1800\n",
            "[TEST LARGE BASELINE (frozen)] seen=2000 used=2000\n",
            "[TEST LARGE BASELINE (frozen)] seen=2200 used=2200\n",
            "[TEST LARGE BASELINE (frozen)] seen=2400 used=2400\n",
            "[TEST LARGE BASELINE (frozen)] seen=2600 used=2600\n",
            "[TEST LARGE BASELINE (frozen)] seen=2800 used=2800\n",
            "[TEST LARGE BASELINE (frozen)] seen=3000 used=3000\n",
            "[TEST LARGE BASELINE (frozen)] seen=3200 used=3200\n",
            "[TEST LARGE BASELINE (frozen)] seen=3400 used=3400\n",
            "[TEST LARGE BASELINE (frozen)] seen=3600 used=3600\n",
            "[TEST LARGE BASELINE (frozen)] seen=3800 used=3800\n",
            "[TEST LARGE BASELINE (frozen)] seen=4000 used=4000\n",
            "[TEST LARGE BASELINE (frozen)] seen=4200 used=4200\n",
            "[TEST LARGE BASELINE (frozen)] seen=4400 used=4400\n",
            "[TEST LARGE BASELINE (frozen)] seen=4600 used=4600\n",
            "[TEST LARGE BASELINE (frozen)] seen=4800 used=4800\n",
            "[TEST LARGE BASELINE (frozen)] seen=5000 used=5000\n",
            "[TEST LARGE BASELINE (frozen)] seen=5200 used=5200\n",
            "[TEST LARGE BASELINE (frozen)] seen=5400 used=5400\n",
            "[TEST LARGE BASELINE (frozen)] seen=5600 used=5600\n",
            "[TEST LARGE BASELINE (frozen)] seen=5800 used=5800\n",
            "[TEST LARGE BASELINE (frozen)] seen=6000 used=6000\n",
            "[TEST LARGE BASELINE (frozen)] seen=6200 used=6200\n",
            "[TEST LARGE BASELINE (frozen)] seen=6400 used=6400\n",
            "[TEST LARGE BASELINE (frozen)] seen=6600 used=6600\n",
            "[TEST LARGE BASELINE (frozen)] seen=6800 used=6800\n",
            "[TEST LARGE BASELINE (frozen)] seen=7000 used=7000\n",
            "[TEST LARGE BASELINE (frozen)] seen=7200 used=7200\n",
            "[TEST LARGE BASELINE (frozen)] seen=7400 used=7400\n",
            "[TEST LARGE BASELINE (frozen)] seen=7600 used=7600\n",
            "[TEST LARGE BASELINE (frozen)] seen=7800 used=7800\n",
            "[TEST LARGE BASELINE (frozen)] seen=8000 used=8000\n",
            "[TEST LARGE BASELINE (frozen)] seen=8200 used=8200\n",
            "[TEST LARGE BASELINE (frozen)] seen=8400 used=8400\n",
            "[TEST LARGE BASELINE (frozen)] seen=8600 used=8600\n",
            "[TEST LARGE BASELINE (frozen)] seen=8800 used=8800\n",
            "[TEST LARGE BASELINE (frozen)] seen=9000 used=9000\n",
            "[TEST LARGE BASELINE (frozen)] seen=9200 used=9200\n",
            "[TEST LARGE BASELINE (frozen)] seen=9400 used=9400\n",
            "[TEST LARGE BASELINE (frozen)] seen=9600 used=9600\n",
            "[TEST LARGE BASELINE (frozen)] seen=9800 used=9800\n",
            "[TEST LARGE BASELINE (frozen)] seen=10000 used=10000\n",
            "[TEST LARGE BASELINE (frozen)] seen=10200 used=10200\n",
            "[TEST LARGE BASELINE (frozen)] seen=10400 used=10400\n",
            "[TEST LARGE BASELINE (frozen)] seen=10600 used=10600\n",
            "[TEST LARGE BASELINE (frozen)] seen=10800 used=10800\n",
            "[TEST LARGE BASELINE (frozen)] seen=11000 used=11000\n",
            "[TEST LARGE BASELINE (frozen)] seen=11200 used=11200\n",
            "[TEST LARGE BASELINE (frozen)] seen=11400 used=11400\n",
            "[TEST LARGE BASELINE (frozen)] seen=11600 used=11600\n",
            "[TEST LARGE BASELINE (frozen)] seen=11800 used=11800\n",
            "[TEST LARGE BASELINE (frozen)] seen=12000 used=12000\n",
            "[TEST LARGE BASELINE (frozen)] seen=12200 used=12200\n",
            "\n",
            "================== TEST LARGE BASELINE (frozen) REPORT ==================\n",
            "Pairs run: 12234 (seen: 12234)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 29.25%\n",
            "  PCK@0.10: 46.32%\n",
            "  PCK@0.20: 61.95%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 33.21%\n",
            "  PCK@0.10: 51.44%\n",
            "  PCK@0.20: 67.23%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "   Category   KP@0.05   KP@0.10   KP@0.20  IMG@0.05  IMG@0.10  IMG@0.20\n",
            "  aeroplane 38.276990 52.635405 65.685205 36.308213 50.646338 63.598760\n",
            "    bicycle 28.479048 47.128815 63.321262 26.452720 43.541331 59.136586\n",
            "       bird 49.471021 73.321067 85.418583 49.046254 72.190641 84.405977\n",
            "       boat 13.880685 27.790904 42.350856 12.284799 24.721374 37.147040\n",
            "     bottle 28.682653 45.982560 61.616319 27.293286 44.684045 60.659734\n",
            "        bus 32.961143 47.833854 58.642251 25.054970 36.483201 45.696482\n",
            "        car 30.790646 46.854120 59.270601 22.421880 34.936265 47.440605\n",
            "        cat 56.469829 69.909648 81.235883 56.412119 69.965699 81.394338\n",
            "      chair 21.412924 35.158817 49.370208 19.085068 32.756272 46.301996\n",
            "        cow 44.494214 64.688317 79.600597 40.831656 61.147945 76.907922\n",
            "        dog 34.818825 53.248646 69.471054 32.609065 51.305760 68.237421\n",
            "      horse 31.420068 50.467687 69.005102 29.910223 48.615283 66.972994\n",
            "  motorbike 25.896531 46.178718 65.255732 24.515726 44.159601 63.326211\n",
            "     person 34.706704 55.726257 71.205773 32.452560 51.770126 67.496360\n",
            "pottedplant 18.201949 36.558902 58.480957 16.141356 33.686149 55.380253\n",
            "      sheep 27.736842 46.500000 66.473684 25.379748 41.881658 60.790449\n",
            "      train 36.085450 55.831409 72.528868 33.116827 52.469861 70.053622\n",
            "  tvmonitor 25.782739 48.665941 68.744895 23.184478 43.315942 61.922926\n",
            "\n",
            "Minutes: 184.2207\n",
            "[train] n_last_blocks=4 | trainable params: 28,359,168\n",
            "[train] step 200/2000 | avg_loss 3.7100 | seen_kps 1475 | 161.3s\n",
            "[train] step 400/2000 | avg_loss 3.3254 | seen_kps 2792 | 318.3s\n",
            "[train] step 600/2000 | avg_loss 3.0511 | seen_kps 4264 | 482.8s\n",
            "[train] step 800/2000 | avg_loss 2.9088 | seen_kps 5683 | 642.2s\n",
            "[train] step 1000/2000 | avg_loss 2.8043 | seen_kps 7049 | 808.3s\n",
            "[train] step 1200/2000 | avg_loss 2.7028 | seen_kps 8470 | 973.1s\n",
            "[train] step 1400/2000 | avg_loss 2.6294 | seen_kps 9942 | 1137.1s\n",
            "[train] step 1600/2000 | avg_loss 2.5523 | seen_kps 11404 | 1298.4s\n",
            "[train] step 1800/2000 | avg_loss 2.4846 | seen_kps 12828 | 1459.3s\n",
            "[train] step 2000/2000 | avg_loss 2.4319 | seen_kps 14177 | 1620.7s\n",
            "[VAL LARGE BEST (blocks=4)] seen=200 used=200\n",
            "[VAL LARGE BEST (blocks=4)] seen=400 used=400\n",
            "[VAL LARGE BEST (blocks=4)] seen=600 used=600\n",
            "[VAL LARGE BEST (blocks=4)] seen=800 used=800\n",
            "[VAL LARGE BEST (blocks=4)] seen=1000 used=1000\n",
            "[VAL LARGE BEST (blocks=4)] seen=1200 used=1200\n",
            "[VAL LARGE BEST (blocks=4)] seen=1400 used=1400\n",
            "[VAL LARGE BEST (blocks=4)] seen=1600 used=1600\n",
            "[VAL LARGE BEST (blocks=4)] seen=1800 used=1800\n",
            "[VAL LARGE BEST (blocks=4)] seen=2000 used=2000\n",
            "[VAL LARGE BEST (blocks=4)] seen=2200 used=2200\n",
            "[VAL LARGE BEST (blocks=4)] seen=2400 used=2400\n",
            "[VAL LARGE BEST (blocks=4)] seen=2600 used=2600\n",
            "[VAL LARGE BEST (blocks=4)] seen=2800 used=2800\n",
            "[VAL LARGE BEST (blocks=4)] seen=3000 used=3000\n",
            "[VAL LARGE BEST (blocks=4)] seen=3200 used=3200\n",
            "[VAL LARGE BEST (blocks=4)] seen=3400 used=3400\n",
            "[VAL LARGE BEST (blocks=4)] seen=3600 used=3600\n",
            "[VAL LARGE BEST (blocks=4)] seen=3800 used=3800\n",
            "[VAL LARGE BEST (blocks=4)] seen=4000 used=4000\n",
            "[VAL LARGE BEST (blocks=4)] seen=4200 used=4200\n",
            "[VAL LARGE BEST (blocks=4)] seen=4400 used=4400\n",
            "[VAL LARGE BEST (blocks=4)] seen=4600 used=4600\n",
            "[VAL LARGE BEST (blocks=4)] seen=4800 used=4800\n",
            "[VAL LARGE BEST (blocks=4)] seen=5000 used=5000\n",
            "[VAL LARGE BEST (blocks=4)] seen=5200 used=5200\n",
            "\n",
            "================== VAL LARGE BEST (blocks=4) REPORT ==================\n",
            "Pairs run: 5384 (seen: 5384)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 52.49%\n",
            "  PCK@0.10: 69.56%\n",
            "  PCK@0.20: 80.70%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 55.11%\n",
            "  PCK@0.10: 73.17%\n",
            "  PCK@0.20: 84.66%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "   Category   KP@0.05   KP@0.10   KP@0.20  IMG@0.05  IMG@0.10  IMG@0.20\n",
            "  aeroplane 61.154391 72.910765 82.967422 61.029716 73.261893 82.850489\n",
            "    bicycle 54.458977 71.284185 82.520809 53.192457 70.605175 80.858024\n",
            "       bird 65.019011 85.678074 94.486692 65.837219 86.222904 95.188373\n",
            "       boat 42.816901 56.338028 71.619718 42.848733 55.280012 69.003338\n",
            "     bottle 55.289492 76.340243 85.775554 53.749788 73.882523 83.530791\n",
            "        bus 57.027363 72.388060 79.104478 53.590426 67.286241 73.845830\n",
            "        car 64.062500 76.627604 82.486979 59.366737 71.525890 79.335264\n",
            "        cat 80.702479 88.429752 93.636364 77.787250 84.991220 91.872522\n",
            "      chair 39.230769 47.637363 54.890110 34.907443 43.477586 50.227261\n",
            "        cow 61.524610 76.470588 87.875150 60.483196 75.720516 85.978230\n",
            "        dog 58.721389 76.282557 84.530387 55.325763 73.053414 81.087041\n",
            "      horse 55.772496 73.981324 90.577250 58.098077 75.572692 90.725482\n",
            "  motorbike 46.679688 64.160156 76.269531 43.845371 62.616213 74.159330\n",
            "     person 55.570061 74.020888 84.073107 52.422022 71.917551 82.647810\n",
            "pottedplant 28.745318 47.471910 67.462547 28.296992 47.325710 67.409252\n",
            "      sheep 51.294964 70.647482 82.661871 47.695248 65.843242 75.714557\n",
            "      train 59.172577 81.276596 93.238771 58.728149 80.534269 92.346386\n",
            "  tvmonitor 46.483180 78.414883 96.712538 45.499442 77.506368 96.469645\n",
            "\n",
            "Minutes: 4.1416\n",
            "[TEST LARGE BEST (blocks=4)] seen=200 used=200\n",
            "[TEST LARGE BEST (blocks=4)] seen=400 used=400\n",
            "[TEST LARGE BEST (blocks=4)] seen=600 used=600\n",
            "[TEST LARGE BEST (blocks=4)] seen=800 used=800\n",
            "[TEST LARGE BEST (blocks=4)] seen=1000 used=1000\n",
            "[TEST LARGE BEST (blocks=4)] seen=1200 used=1200\n",
            "[TEST LARGE BEST (blocks=4)] seen=1400 used=1400\n",
            "[TEST LARGE BEST (blocks=4)] seen=1600 used=1600\n",
            "[TEST LARGE BEST (blocks=4)] seen=1800 used=1800\n",
            "[TEST LARGE BEST (blocks=4)] seen=2000 used=2000\n",
            "[TEST LARGE BEST (blocks=4)] seen=2200 used=2200\n",
            "[TEST LARGE BEST (blocks=4)] seen=2400 used=2400\n",
            "[TEST LARGE BEST (blocks=4)] seen=2600 used=2600\n",
            "[TEST LARGE BEST (blocks=4)] seen=2800 used=2800\n",
            "[TEST LARGE BEST (blocks=4)] seen=3000 used=3000\n",
            "[TEST LARGE BEST (blocks=4)] seen=3200 used=3200\n",
            "[TEST LARGE BEST (blocks=4)] seen=3400 used=3400\n",
            "[TEST LARGE BEST (blocks=4)] seen=3600 used=3600\n",
            "[TEST LARGE BEST (blocks=4)] seen=3800 used=3800\n",
            "[TEST LARGE BEST (blocks=4)] seen=4000 used=4000\n",
            "[TEST LARGE BEST (blocks=4)] seen=4200 used=4200\n",
            "[TEST LARGE BEST (blocks=4)] seen=4400 used=4400\n",
            "[TEST LARGE BEST (blocks=4)] seen=4600 used=4600\n",
            "[TEST LARGE BEST (blocks=4)] seen=4800 used=4800\n",
            "[TEST LARGE BEST (blocks=4)] seen=5000 used=5000\n",
            "[TEST LARGE BEST (blocks=4)] seen=5200 used=5200\n",
            "[TEST LARGE BEST (blocks=4)] seen=5400 used=5400\n",
            "[TEST LARGE BEST (blocks=4)] seen=5600 used=5600\n",
            "[TEST LARGE BEST (blocks=4)] seen=5800 used=5800\n",
            "[TEST LARGE BEST (blocks=4)] seen=6000 used=6000\n",
            "[TEST LARGE BEST (blocks=4)] seen=6200 used=6200\n",
            "[TEST LARGE BEST (blocks=4)] seen=6400 used=6400\n",
            "[TEST LARGE BEST (blocks=4)] seen=6600 used=6600\n",
            "[TEST LARGE BEST (blocks=4)] seen=6800 used=6800\n",
            "[TEST LARGE BEST (blocks=4)] seen=7000 used=7000\n",
            "[TEST LARGE BEST (blocks=4)] seen=7200 used=7200\n",
            "[TEST LARGE BEST (blocks=4)] seen=7400 used=7400\n",
            "[TEST LARGE BEST (blocks=4)] seen=7600 used=7600\n",
            "[TEST LARGE BEST (blocks=4)] seen=7800 used=7800\n",
            "[TEST LARGE BEST (blocks=4)] seen=8000 used=8000\n",
            "[TEST LARGE BEST (blocks=4)] seen=8200 used=8200\n",
            "[TEST LARGE BEST (blocks=4)] seen=8400 used=8400\n",
            "[TEST LARGE BEST (blocks=4)] seen=8600 used=8600\n",
            "[TEST LARGE BEST (blocks=4)] seen=8800 used=8800\n",
            "[TEST LARGE BEST (blocks=4)] seen=9000 used=9000\n",
            "[TEST LARGE BEST (blocks=4)] seen=9200 used=9200\n",
            "[TEST LARGE BEST (blocks=4)] seen=9400 used=9400\n",
            "[TEST LARGE BEST (blocks=4)] seen=9600 used=9600\n",
            "[TEST LARGE BEST (blocks=4)] seen=9800 used=9800\n",
            "[TEST LARGE BEST (blocks=4)] seen=10000 used=10000\n",
            "[TEST LARGE BEST (blocks=4)] seen=10200 used=10200\n",
            "[TEST LARGE BEST (blocks=4)] seen=10400 used=10400\n",
            "[TEST LARGE BEST (blocks=4)] seen=10600 used=10600\n",
            "[TEST LARGE BEST (blocks=4)] seen=10800 used=10800\n",
            "[TEST LARGE BEST (blocks=4)] seen=11000 used=11000\n",
            "[TEST LARGE BEST (blocks=4)] seen=11200 used=11200\n",
            "[TEST LARGE BEST (blocks=4)] seen=11400 used=11400\n",
            "[TEST LARGE BEST (blocks=4)] seen=11600 used=11600\n",
            "[TEST LARGE BEST (blocks=4)] seen=11800 used=11800\n",
            "[TEST LARGE BEST (blocks=4)] seen=12000 used=12000\n",
            "[TEST LARGE BEST (blocks=4)] seen=12200 used=12200\n",
            "\n",
            "================== TEST LARGE BEST (blocks=4) REPORT ==================\n",
            "Pairs run: 12234 (seen: 12234)\n",
            "\n",
            "Global PCK (per-image mean):\n",
            "  PCK@0.05: 52.99%\n",
            "  PCK@0.10: 70.69%\n",
            "  PCK@0.20: 82.48%\n",
            "\n",
            "Global PCK (per-keypoint):\n",
            "  PCK@0.05: 56.30%\n",
            "  PCK@0.10: 74.29%\n",
            "  PCK@0.20: 85.55%\n",
            "\n",
            "================ PER-CATEGORY RESULTS ================\n",
            "   Category   KP@0.05   KP@0.10   KP@0.20  IMG@0.05  IMG@0.10  IMG@0.20\n",
            "  aeroplane 60.468920 72.773537 83.296983 61.300038 73.763532 83.392205\n",
            "    bicycle 44.697362 62.312468 74.288670 43.281324 59.735853 70.704385\n",
            "       bird 68.629255 87.718491 95.124195 68.194931 87.011868 94.891167\n",
            "       boat 34.672180 53.957472 69.964560 37.216004 55.943958 71.232137\n",
            "     bottle 50.264715 65.119900 76.518219 49.365809 64.454069 76.333470\n",
            "        bus 66.480572 80.460027 85.663243 62.299113 75.775111 80.893435\n",
            "        car 58.379733 70.350780 79.120267 52.035230 63.185734 73.182348\n",
            "        cat 78.234914 85.350113 92.562117 78.476018 85.649149 92.893347\n",
            "      chair 39.485214 50.054765 58.844469 37.352344 47.835716 56.507266\n",
            "        cow 67.077268 84.229190 94.699515 65.093773 83.450092 94.205358\n",
            "        dog 58.413161 75.801749 87.338609 55.361495 73.792764 86.085801\n",
            "      horse 53.635204 71.875000 87.436224 52.436740 69.676363 86.154657\n",
            "  motorbike 55.379189 73.456790 84.656085 53.852541 73.588670 84.172998\n",
            "     person 48.230912 69.878957 81.936685 45.490976 67.362646 80.484145\n",
            "pottedplant 39.459699 67.294066 86.315323 37.961597 64.626653 85.026655\n",
            "      sheep 46.921053 66.473684 83.368421 45.381054 61.302370 77.336155\n",
            "      train 66.304850 86.685912 94.976905 65.128804 85.903245 94.340828\n",
            "  tvmonitor 50.843997 82.099102 96.011435 49.803674 80.416111 95.210782\n",
            "\n",
            "Minutes: 9.3279\n",
            "\n",
            "=== FINAL KP SUMMARY (VAL + TEST) ===\n",
            "Split           Model  KP@0.05  KP@0.10  KP@0.20\n",
            "  VAL          Frozen    32.58    50.61    66.52\n",
            "  VAL Best (blocks=4)    55.11    73.17    84.66\n",
            "  VAL Δ Best - Frozen    22.53    22.55    18.14\n",
            " TEST          Frozen    33.21    51.44    67.23\n",
            " TEST Best (blocks=4)    56.30    74.29    85.55\n",
            " TEST Δ Best - Frozen    23.09    22.86    18.32\n",
            "\n",
            "=== FINAL IMG SUMMARY (VAL + TEST) ===\n",
            "Split           Model  IMG@0.05  IMG@0.10  IMG@0.20\n",
            "  VAL          Frozen     29.45     45.93     60.93\n",
            "  VAL Best (blocks=4)     52.49     69.56     80.70\n",
            "  VAL Δ Best - Frozen     23.04     23.63     19.78\n",
            " TEST          Frozen     29.25     46.32     61.95\n",
            " TEST Best (blocks=4)     52.99     70.69     82.48\n",
            " TEST Δ Best - Frozen     23.75     24.37     20.52\n",
            "\n",
            "=== DONE ===\n"
          ]
        }
      ]
    }
  ]
}