{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y8AKrNt5lxaQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k.zip' estratto con successo nella directory 'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted'\n",
      "Contenuti della directory 'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted':\n",
      "['SPair-71k']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "zip_file_path = r'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k.zip' \n",
    "extract_dir = r'C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted'\n",
    "\n",
    "# Crea la directory di estrazione se non esiste\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Estrai il file ZIP solo se esiste\n",
    "if os.path.exists(zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    print(f\"File '{zip_file_path}' estratto con successo nella directory '{extract_dir}'\")\n",
    "    print(f\"Contenuti della directory '{extract_dir}':\\n{os.listdir(extract_dir)}\")\n",
    "else:\n",
    "    print(f\"File zip '{zip_file_path}' non trovato. Assicurati che il dataset sia estratto in '{extract_dir}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "honcpimEq_B2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset caricati correttamente.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import json\n",
    "\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, image_keys):\n",
    "        self.image_keys = image_keys\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        for key in self.image_keys:\n",
    "            image[key] /= 255.0\n",
    "            image[key] = self.normalize(image[key])\n",
    "        return image\n",
    "\n",
    "\n",
    "def read_img(path):\n",
    "    img = np.array(Image.open(path).convert('RGB'))\n",
    "\n",
    "    return torch.tensor(img.transpose(2, 0, 1).astype(np.float32))\n",
    "\n",
    "\n",
    "class SPairDataset(Dataset):\n",
    "    def __init__(self, pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype):\n",
    "\n",
    "        self.datatype = datatype\n",
    "        self.pck_alpha = pck_alpha\n",
    "        self.ann_files = open(os.path.join(layout_path, dataset_size, datatype + '.txt'), \"r\").read().split('\\n')\n",
    "        self.ann_files = self.ann_files[:len(self.ann_files) - 1]\n",
    "        self.pair_ann_path = pair_ann_path\n",
    "        self.image_path = image_path\n",
    "        self.categories = list(map(lambda x: os.path.basename(x), glob.glob('%s/*' % image_path)))\n",
    "        self.categories.sort()\n",
    "        self.transform = Normalize(['src_img', 'trg_img'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ann_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        raw_line = self.ann_files[idx]\n",
    "        ann_filename = raw_line.replace(':', '_')\n",
    "        ann_file = ann_filename + '.json'\n",
    "        json_path = os.path.join(self.pair_ann_path, self.datatype, ann_file)\n",
    "\n",
    "        with open(json_path) as f:\n",
    "            annotation = json.load(f)\n",
    "\n",
    "        category = annotation['category']\n",
    "        src_img = read_img(os.path.join(self.image_path, category, annotation['src_imname']))\n",
    "        trg_img = read_img(os.path.join(self.image_path, category, annotation['trg_imname']))\n",
    "\n",
    "        trg_bbox = annotation['trg_bndbox']\n",
    "        pck_threshold = max(trg_bbox[2] - trg_bbox[0],  trg_bbox[3] - trg_bbox[1]) * self.pck_alpha\n",
    "\n",
    "        sample = {'pair_id': annotation['pair_id'],\n",
    "                  'filename': annotation['filename'],\n",
    "                  'src_imname': annotation['src_imname'],\n",
    "                  'trg_imname': annotation['trg_imname'],\n",
    "                  'src_imsize': src_img.size(),\n",
    "                  'trg_imsize': trg_img.size(),\n",
    "\n",
    "                  'src_bbox': annotation['src_bndbox'],\n",
    "                  'trg_bbox': annotation['trg_bndbox'],\n",
    "                  'category': annotation['category'],\n",
    "\n",
    "                  'src_pose': annotation['src_pose'],\n",
    "                  'trg_pose': annotation['trg_pose'],\n",
    "\n",
    "                  'src_img': src_img,\n",
    "                  'trg_img': trg_img,\n",
    "                  'src_kps': torch.tensor(annotation['src_kps']).float(),\n",
    "                  'trg_kps': torch.tensor(annotation['trg_kps']).float(),\n",
    "\n",
    "                  'mirror': annotation['mirror'],\n",
    "                  'vp_var': annotation['viewpoint_variation'],\n",
    "                  'sc_var': annotation['scale_variation'],\n",
    "                  'truncn': annotation['truncation'],\n",
    "                  'occlsn': annotation['occlusion'],\n",
    "\n",
    "                  'pck_threshold': pck_threshold}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base_dir = r\"C:\\Users\\nicol\\Documents\\PoliTo\\AdvancedML\\project\\SPair-71k_extracted\\SPair-71k\\SPair-71k\"    \n",
    "    pair_ann_path = os.path.join(base_dir, 'PairAnnotation')\n",
    "    layout_path = os.path.join(base_dir, 'Layout')\n",
    "    image_path = os.path.join(base_dir, 'JPEGImages')\n",
    "    dataset_size = 'large'\n",
    "    pck_alpha = 0.1\n",
    "    \n",
    "    # Verifica che i percorsi esistano prima di creare il dataset\n",
    "    if os.path.exists(pair_ann_path) and os.path.exists(layout_path) and os.path.exists(image_path):\n",
    "        trn_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='trn')\n",
    "        val_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='val')\n",
    "        test_dataset = SPairDataset(pair_ann_path, layout_path, image_path, dataset_size, pck_alpha, datatype='test')\n",
    "\n",
    "        trn_dataloader = DataLoader(trn_dataset, num_workers=0)\n",
    "        val_dataloader = DataLoader(val_dataset, num_workers=0)\n",
    "        test_dataloader = DataLoader(test_dataset, num_workers=0)\n",
    "        print(\"Dataset caricati correttamente.\")\n",
    "    else:\n",
    "        print(f\"Errore: Impossibile trovare i percorsi del dataset in '{base_dir}'.\\nVerifica l'estrazione e controlla se la struttura delle cartelle corrisponde.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DINOv2 Model on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nicol/.cache\\torch\\hub\\facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PCA-only loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:   0%|          | 14/12234 [00:00<09:12, 22.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Saved PCA Analysis to: final_analysis_results\\PCA_ANALYSIS_aeroplane.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning:  44%|████▍     | 5422/12234 [00:49<01:02, 108.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Saved PCA Analysis to: final_analysis_results\\PCA_ANALYSIS_chair.png\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math \n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1. SETUP\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Loading DINOv2 Model on {device}...\")\n",
    "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14')\n",
    "model.to(device)\n",
    "model.eval() \n",
    "\n",
    "output_dir = \"final_analysis_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "done_classes = {'aeroplane': False, 'chair': False}\n",
    "\n",
    "# 2. FUNCTIONS\n",
    "def pad_to_multiple(x, k=14):\n",
    "    h, w = x.shape[-2:]\n",
    "    new_h = math.ceil(h / k) * k\n",
    "    new_w = math.ceil(w / k) * k\n",
    "    return F.pad(x, (0, new_w - w, 0, new_h - h), value=0)\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    img = img_tensor.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
    "    return np.clip((img * std) + mean, 0, 1)\n",
    "\n",
    "def compute_joint_pca(feat1, feat2, h1, w1, h2, w2):\n",
    "    f1 = feat1[0].cpu().detach().numpy()\n",
    "    f2 = feat2[0].cpu().detach().numpy()\n",
    "    \n",
    "    # Fit PCA on combined features so colors mean the same thing\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(np.concatenate((f1, f2), axis=0))\n",
    "    \n",
    "    p1 = pca.transform(f1)\n",
    "    p2 = pca.transform(f2)\n",
    "    \n",
    "    p_all = np.concatenate((p1, p2), axis=0)\n",
    "    p_min, p_max = p_all.min(0), p_all.max(0)\n",
    "    \n",
    "    # Normalize and reshape\n",
    "    img1 = ((p1 - p_min) / (p_max - p_min)).reshape(h1, w1, 3)\n",
    "    img2 = ((p2 - p_min) / (p_max - p_min)).reshape(h2, w2, 3)\n",
    "    return img1, img2\n",
    "\n",
    "# 3. MAIN LOOP\n",
    "print(\"Starting PCA-only loop...\")\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(test_dataloader, desc=\"Scanning\")):\n",
    "        category = data['category'][0]\n",
    "        if category not in done_classes or done_classes[category]: continue\n",
    "\n",
    "        # A. PREPARE\n",
    "        src_img, trg_img = data['src_img'].to(device), data['trg_img'].to(device)\n",
    "        \n",
    "        src_pad, trg_pad = pad_to_multiple(src_img, 14), pad_to_multiple(trg_img, 14)\n",
    "        h_g_s, w_g_s = src_pad.shape[-2] // 14, src_pad.shape[-1] // 14\n",
    "        h_g_t, w_g_t = trg_pad.shape[-2] // 14, trg_pad.shape[-1] // 14\n",
    "\n",
    "        # n=3 fetches the last 4 blocks: [Layer 10, Layer 11, Layer 12]\n",
    "        out_s = model.get_intermediate_layers(src_pad, n=3, reshape=False, return_class_token=False)\n",
    "        out_t = model.get_intermediate_layers(trg_pad, n=3, reshape=False, return_class_token=False)\n",
    "        \n",
    "        f_s_9, f_t_9 = F.normalize(out_s[0], p=2, dim=-1), F.normalize(out_t[0], p=2, dim=-1)\n",
    "        f_s_11, f_t_11 = F.normalize(out_s[2], p=2, dim=-1), F.normalize(out_t[2], p=2, dim=-1)\n",
    "\n",
    "        # C. VISUALIZATION\n",
    "        pca_s_9, pca_t_9 = compute_joint_pca(f_s_9, f_t_9, h_g_s, w_g_s, h_g_t, w_g_t)\n",
    "        _, pca_t_11 = compute_joint_pca(f_s_11, f_t_11, h_g_s, w_g_s, h_g_t, w_g_t)\n",
    "        \n",
    "        fig, ax = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        plt.subplots_adjust(hspace=0.2, wspace=0.1)\n",
    "        img_s, img_t = denormalize(src_img), denormalize(trg_img)\n",
    "\n",
    "        # Plotting\n",
    "        # Row 1: Original Images\n",
    "        ax[0, 0].imshow(img_s)\n",
    "        ax[0, 0].set_title(f\"SOURCE ({category})\\nOriginal Image\", fontsize=14)\n",
    "        \n",
    "        ax[0, 1].imshow(img_t)\n",
    "        ax[0, 1].set_title(\"TARGET\\nOriginal Image\", fontsize=14)\n",
    "        \n",
    "        ax[0, 2].axis('off') # Empty slot\n",
    "\n",
    "        # Row 2: PCA Visualization (Using bicubic for paper-like look)\n",
    "        ax[1, 0].imshow(pca_s_9, interpolation='bicubic')\n",
    "        ax[1, 0].set_title(\"Source PCA (Layer 10)\\nGeometric Features\", fontsize=14)\n",
    "        \n",
    "        ax[1, 1].imshow(pca_t_9, interpolation='bicubic')\n",
    "        ax[1, 1].set_title(\"Target PCA (Layer 10)\\nShould Match Source Colors\", fontsize=14)\n",
    "        \n",
    "        ax[1, 2].imshow(pca_t_11, interpolation='bicubic')\n",
    "        ax[1, 2].set_title(\"Target PCA (Last Layer)\\nSemantic Collapse\", fontsize=14)\n",
    "        \n",
    "        for a in ax.flatten(): a.axis('off')\n",
    "        \n",
    "        save_path = os.path.join(output_dir, f\"PCA_ANALYSIS_{category}.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"--> Saved PCA Analysis to: {save_path}\")\n",
    "        \n",
    "        done_classes[category] = True\n",
    "        if done_classes['aeroplane'] and done_classes['chair']: break\n",
    "\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM94XQGmSqU+CbzhlwN85hS",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
