{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DINOv3 — Task1 PCA + Qualitative\n",
        "# - JOINT PCA: fit su [source_patches ; target_patches]\n",
        "# - Visualizza PCA per Layer 10 e Last layer (Source + Target)\n",
        "# - Qualitative last layer: SOURCE(kps blu) | TARGET(pred rosso) | TARGET(GT verde)\n",
        "# - Dataset SPair-71k:\n",
        "#     PairAnnotation/test/nomefile:categoria.json\n",
        "#     JPEGImages/<cat>/<filename>.jpg\n",
        "# ============================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os, json, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip -q install scikit-learn\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1fK5IZ0Euby",
        "outputId": "936ef1c6-82c3-4b4d-88bb-bd8882cc4257"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# PATHS\n",
        "# -----------------------------\n",
        "SPAIR_ROOT = Path(\"/content/drive/MyDrive/AMLDataset/SPair-71k\")\n",
        "DINOv3_WEIGHTS = Path(\"/content/drive/MyDrive/AMLDataset/dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\")\n",
        "\n",
        "assert SPAIR_ROOT.exists(), f\"SPair-71k non trovato: {SPAIR_ROOT}\"\n",
        "assert DINOv3_WEIGHTS.exists(), f\"Pesi DINOv3 non trovati: {DINOv3_WEIGHTS}\"\n",
        "\n",
        "PAIR_ANN_ROOT = SPAIR_ROOT / \"PairAnnotation\" / \"test\"\n",
        "IMG_ROOT      = SPAIR_ROOT / \"JPEGImages\"\n",
        "assert PAIR_ANN_ROOT.exists(), f\"Manca: {PAIR_ANN_ROOT}\"\n",
        "assert IMG_ROOT.exists(), f\"Manca: {IMG_ROOT}\"\n",
        "\n",
        "# -----------------------------\n",
        "# OUTPUT\n",
        "# -----------------------------\n",
        "OUT_ROOT = Path(\"/content/drive/MyDrive/AML_Project_Results/DINOv3_Task1\")\n",
        "PCA_DIR  = OUT_ROOT / \"final_analysis_results_dinov3_jointPCA\"\n",
        "QUAL_DIR = OUT_ROOT / \"qualitative_results_last_layer_dinov3\"\n",
        "PCA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "QUAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Saving PCA  to:\", PCA_DIR)\n",
        "print(\"Saving QUAL to:\", QUAL_DIR)\n",
        "\n",
        "# -----------------------------\n",
        "# SETTINGS\n",
        "# -----------------------------\n",
        "CATEGORIES = [\"aeroplane\", \"chair\"]\n",
        "PAIRS_PER_CATEGORY = 1          # quante figure per categoria (per PCA e QUAL)\n",
        "MAX_SCAN_PER_CAT   = 200        # non serve molto qui (prendiamo le prime N)\n",
        "LAYER_INTER        = 10         # layer intermedio\n",
        "PATCH              = 16         # vitb16\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lApLLfP4E7pG",
        "outputId": "192010dd-cf2e-483f-8420-8c96789c4df5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving PCA  to: /content/drive/MyDrive/AML_Project_Results/DINOv3_Task1/final_analysis_results_dinov3_jointPCA\n",
            "Saving QUAL to: /content/drive/MyDrive/AML_Project_Results/DINOv3_Task1/qualitative_results_last_layer_dinov3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Load DINOv3\n",
        "# ============================================================\n",
        "%cd /content\n",
        "!test -d dinov3 || git clone https://github.com/facebookresearch/dinov3.git\n",
        "%cd /content/dinov3\n",
        "!pip -q install einops timm opencv-python torchmetrics fvcore iopath\n",
        "\n",
        "DINOV3_DIR = \"/content/dinov3\"\n",
        "\n",
        "dinov3 = torch.hub.load(\n",
        "    DINOV3_DIR,\n",
        "    \"dinov3_vitb16\",\n",
        "    source=\"local\",\n",
        "    weights=str(DINOv3_WEIGHTS),\n",
        ").eval().to(device)\n",
        "\n",
        "for p in dinov3.parameters():\n",
        "    p.requires_grad_(False)\n",
        "\n",
        "assert hasattr(dinov3, \"blocks\"), \"Il modello non ha .blocks: API diversa dal previsto\"\n",
        "N_BLOCKS = len(dinov3.blocks)\n",
        "print(\"DINOv3 blocks:\", N_BLOCKS)\n",
        "\n",
        "if not (0 <= LAYER_INTER < N_BLOCKS):\n",
        "    raise ValueError(f\"LAYER_INTER={LAYER_INTER} fuori range [0,{N_BLOCKS-1}]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjqOo3y5E_DM",
        "outputId": "c19aa581-40db-4ee3-e0ad-077b204fe50f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/dinov3\n",
            "DINOv3 blocks: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Utils: IO + padding + preprocess\n",
        "# ============================================================\n",
        "def load_rgb(path: Path):\n",
        "    return np.array(Image.open(path).convert(\"RGB\"))\n",
        "\n",
        "def to_chw_float_0_255(img_np: np.ndarray):\n",
        "    return torch.from_numpy(img_np).permute(2,0,1).float()  # CHW [0..255]\n",
        "\n",
        "def pad_to_multiple(img_chw: torch.Tensor, k: int):\n",
        "    C, H, W = img_chw.shape\n",
        "    Hpad = int(math.ceil(H / k) * k)\n",
        "    Wpad = int(math.ceil(W / k) * k)\n",
        "    out = torch.zeros((C, Hpad, Wpad), dtype=img_chw.dtype)\n",
        "    out[:, :H, :W] = img_chw\n",
        "    return out, (H, W), (Hpad, Wpad)\n",
        "\n",
        "def grid_hw(Hpad: int, Wpad: int, patch: int):\n",
        "    return Hpad // patch, Wpad // patch\n",
        "\n",
        "mean = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
        "std  = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def preprocess_for_model(img_chw_0_255: torch.Tensor) -> torch.Tensor:\n",
        "    x = (img_chw_0_255 / 255.0).unsqueeze(0).to(device)\n",
        "    return (x - mean) / std"
      ],
      "metadata": {
        "id": "MfUrEJxWFDjD"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Dataset specifics\n",
        "# ============================================================\n",
        "def list_pair_jsons_for_category(cat: str):\n",
        "    # PairAnnotation/test/nomefile:categoria.json\n",
        "    return sorted(PAIR_ANN_ROOT.glob(f\"*:{cat.lower()}.json\"))\n",
        "\n",
        "def extract_pair_fields(ann: dict):\n",
        "    # campi standard SPair\n",
        "    src_name = ann.get(\"src_imname\")\n",
        "    trg_name = ann.get(\"trg_imname\")\n",
        "    if src_name is None or trg_name is None:\n",
        "        raise KeyError(\"Nel json mancano src_imname/trg_imname\")\n",
        "    src_kps  = ann.get(\"src_kps\")\n",
        "    trg_kps  = ann.get(\"trg_kps\")\n",
        "    trg_bbox = ann.get(\"trg_bbox\")  # a volte None, non serve qui\n",
        "    pair_id  = ann.get(\"pair_id\") or ann.get(\"id\")\n",
        "    return src_name, trg_name, src_kps, trg_kps, trg_bbox, pair_id\n",
        "\n",
        "def load_pair_images(cat: str, src_name: str, trg_name: str):\n",
        "    src_path = IMG_ROOT / cat / src_name\n",
        "    trg_path = IMG_ROOT / cat / trg_name\n",
        "    if not src_path.exists():\n",
        "        raise FileNotFoundError(f\"Source image not found: {src_path}\")\n",
        "    if not trg_path.exists():\n",
        "        raise FileNotFoundError(f\"Target image not found: {trg_path}\")\n",
        "    return load_rgb(src_path), load_rgb(trg_path)"
      ],
      "metadata": {
        "id": "Hl-cmzGVFGdP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Feature extraction: patch tokens -> grid\n",
        "# ============================================================\n",
        "def safe_tokens(out):\n",
        "    if isinstance(out, (tuple, list)):\n",
        "        out = out[0]\n",
        "    if (not torch.is_tensor(out)) or out.ndim != 3:\n",
        "        raise RuntimeError(f\"Unexpected tokens output: {type(out)} shape={getattr(out,'shape',None)}\")\n",
        "    return out\n",
        "\n",
        "def tokens_to_patchgrid(tokens_bnc: torch.Tensor, hg: int, wg: int) -> torch.Tensor:\n",
        "    tok = tokens_bnc.squeeze(0)  # (N,C)\n",
        "    Npatch = hg * wg\n",
        "    if tok.shape[0] < Npatch:\n",
        "        raise RuntimeError(f\"Ntok={tok.shape[0]} < Npatch={Npatch}\")\n",
        "    patch_tok = tok[-Npatch:]  # drop CLS/register robustly\n",
        "    Fmap = patch_tok.view(hg, wg, -1)\n",
        "    return F.normalize(Fmap, dim=-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def feat_last(img_pad_chw: torch.Tensor, hg: int, wg: int) -> torch.Tensor:\n",
        "    out = dinov3.forward_features(preprocess_for_model(img_pad_chw))\n",
        "    patch = out[\"x_norm_patchtokens\"].squeeze(0)  # (Npatch, C)\n",
        "    if patch.shape[0] != hg*wg:\n",
        "        raise RuntimeError(f\"Last patch tokens {patch.shape[0]} != hg*wg {hg*wg}\")\n",
        "    return F.normalize(patch.view(hg, wg, -1), dim=-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def feat_inter(img_pad_chw: torch.Tensor, layer_id: int, hg: int, wg: int) -> torch.Tensor:\n",
        "    captured = {}\n",
        "    def hook_fn(m, inp, out):\n",
        "        captured[\"t\"] = safe_tokens(out).detach()\n",
        "\n",
        "    h = dinov3.blocks[layer_id].register_forward_hook(hook_fn)\n",
        "    _ = dinov3.forward_features(preprocess_for_model(img_pad_chw))\n",
        "    h.remove()\n",
        "\n",
        "    if \"t\" not in captured:\n",
        "        raise RuntimeError(\"Hook non ha catturato token (layer_id errato o API diversa)\")\n",
        "    return tokens_to_patchgrid(captured[\"t\"], hg, wg)"
      ],
      "metadata": {
        "id": "dUAxUYfFFKu8"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# JOINT PCA\n",
        "# ============================================================\n",
        "def joint_pca_rgb(Fs_hwC: torch.Tensor, Ft_hwC: torch.Tensor, n_components=3):\n",
        "    hg, wg, C = Fs_hwC.shape\n",
        "    assert Ft_hwC.shape[:2] == (hg, wg) and Ft_hwC.shape[2] == C, \"source/target grid mismatch\"\n",
        "\n",
        "    Xs = Fs_hwC.reshape(-1, C).detach().cpu().numpy()\n",
        "    Xt = Ft_hwC.reshape(-1, C).detach().cpu().numpy()\n",
        "    X  = np.concatenate([Xs, Xt], axis=0)\n",
        "\n",
        "    pca = PCA(n_components=n_components)\n",
        "    _ = pca.fit_transform(X)\n",
        "\n",
        "    Ys = pca.transform(Xs).reshape(hg, wg, n_components)\n",
        "    Yt = pca.transform(Xt).reshape(hg, wg, n_components)\n",
        "\n",
        "    Y_all = np.concatenate([Ys.reshape(-1,n_components), Yt.reshape(-1,n_components)], axis=0)\n",
        "    mn = Y_all.min(axis=0, keepdims=True)\n",
        "    mx = Y_all.max(axis=0, keepdims=True)\n",
        "\n",
        "    rgb_s = (Ys - mn) / (mx - mn + 1e-8)\n",
        "    rgb_t = (Yt - mn) / (mx - mn + 1e-8)\n",
        "    return rgb_s, rgb_t"
      ],
      "metadata": {
        "id": "9Ih2VDjwFOb5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# PCA Figure\n",
        "# ============================================================\n",
        "def save_pca_pair_figure_full(cat: str, pair_stem: str,\n",
        "                              src_img: np.ndarray, trg_img: np.ndarray,\n",
        "                              rgb_s_inter, rgb_t_inter,\n",
        "                              rgb_s_last,  rgb_t_last):\n",
        "    fig = plt.figure(figsize=(16, 9))\n",
        "\n",
        "    ax1 = plt.subplot(2,4,1); ax1.imshow(src_img); ax1.set_title(f\"SOURCE ({cat})\"); ax1.axis(\"off\")\n",
        "    ax2 = plt.subplot(2,4,2); ax2.imshow(trg_img); ax2.set_title(\"TARGET\"); ax2.axis(\"off\")\n",
        "\n",
        "    ax3 = plt.subplot(2,4,5); ax3.imshow(rgb_s_inter); ax3.set_title(f\"JOINT PCA L{LAYER_INTER} (S)\"); ax3.axis(\"off\")\n",
        "    ax4 = plt.subplot(2,4,6); ax4.imshow(rgb_t_inter); ax4.set_title(f\"JOINT PCA L{LAYER_INTER} (T)\"); ax4.axis(\"off\")\n",
        "\n",
        "    ax5 = plt.subplot(2,4,7); ax5.imshow(rgb_s_last); ax5.set_title(\"JOINT PCA Last (S)\"); ax5.axis(\"off\")\n",
        "    ax6 = plt.subplot(2,4,8); ax6.imshow(rgb_t_last); ax6.set_title(\"JOINT PCA Last (T)\"); ax6.axis(\"off\")\n",
        "\n",
        "    fig.suptitle(f\"DINOv3 — JOINT PCA — {cat} — {pair_stem}\", y=0.98)\n",
        "    out = PCA_DIR / f\"PCA_JOINT_FULL_{cat}_ID{pair_stem}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out, dpi=200)\n",
        "    plt.close(fig)\n"
      ],
      "metadata": {
        "id": "4lZbqA3TJR1Y"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Qualitative last-layer matching (Task1-style)\n",
        "# ============================================================\n",
        "def patch_center(ix, iy, patch=16):\n",
        "    return (ix*patch + patch/2.0, iy*patch + patch/2.0)\n",
        "\n",
        "@torch.no_grad()\n",
        "def match_keypoints_lastlayer(src_img_chw, trg_img_chw, src_kps):\n",
        "    # pad + grid\n",
        "    src_pad, (Hs,Ws), (Hsp,Wsp) = pad_to_multiple(src_img_chw, PATCH)\n",
        "    trg_pad, (Ht,Wt), (Htp,Wtp) = pad_to_multiple(trg_img_chw, PATCH)\n",
        "    hg_s, wg_s = grid_hw(Hsp, Wsp, PATCH)\n",
        "    hg_t, wg_t = grid_hw(Htp, Wtp, PATCH)\n",
        "\n",
        "    Fs = feat_last(src_pad, hg_s, wg_s).reshape(hg_s*wg_s, -1)  # (Ps,C)\n",
        "    Ft = feat_last(trg_pad, hg_t, wg_t).reshape(hg_t*wg_t, -1)  # (Pt,C)\n",
        "\n",
        "    pred_xy = []\n",
        "    for kp in src_kps:\n",
        "        if kp is None:\n",
        "            pred_xy.append((np.nan, np.nan))\n",
        "            continue\n",
        "        # kp = [x,y] oppure [x,y,vis]\n",
        "        if len(kp) >= 3 and kp[2] == 0:\n",
        "            pred_xy.append((np.nan, np.nan))\n",
        "            continue\n",
        "\n",
        "        x,y = kp[0], kp[1]\n",
        "        ix = int(np.clip(x//PATCH, 0, wg_s-1))\n",
        "        iy = int(np.clip(y//PATCH, 0, hg_s-1))\n",
        "        src_patch_id = iy*wg_s + ix\n",
        "\n",
        "        sims = Ft @ Fs[src_patch_id]  # (Pt,) cosine sim (features normalized)\n",
        "        j = int(torch.argmax(sims).item())\n",
        "        jy = j // wg_t\n",
        "        jx = j %  wg_t\n",
        "\n",
        "        px,py = patch_center(jx, jy, PATCH)\n",
        "        px = float(np.clip(px, 0, Wt-1))\n",
        "        py = float(np.clip(py, 0, Ht-1))\n",
        "        pred_xy.append((px,py))\n",
        "\n",
        "    return pred_xy\n",
        "\n",
        "def save_qual_figure(cat, pair_stem, src_np, trg_np, src_kps, trg_kps, pred_xy):\n",
        "    fig = plt.figure(figsize=(16,5))\n",
        "\n",
        "    # SOURCE (blue)\n",
        "    ax1 = plt.subplot(1,3,1)\n",
        "    ax1.imshow(src_np); ax1.set_title(f\"SOURCE ({cat})\"); ax1.axis(\"off\")\n",
        "    for kp in src_kps:\n",
        "        if kp is None:\n",
        "            continue\n",
        "        if len(kp) >= 3 and kp[2] == 0:\n",
        "            continue\n",
        "        ax1.scatter(kp[0], kp[1], s=120, c=\"blue\")\n",
        "\n",
        "    # PRED (red X) on TARGET\n",
        "    ax2 = plt.subplot(1,3,2)\n",
        "    ax2.imshow(trg_np); ax2.set_title(\"PREDICTION (Last Layer)\"); ax2.axis(\"off\")\n",
        "    for p in pred_xy:\n",
        "        if np.isnan(p[0]) or np.isnan(p[1]):\n",
        "            continue\n",
        "        ax2.scatter(p[0], p[1], s=120, c=\"red\", marker=\"x\")\n",
        "\n",
        "    # GT (green) on TARGET\n",
        "    ax3 = plt.subplot(1,3,3)\n",
        "    ax3.imshow(trg_np); ax3.set_title(\"GROUND TRUTH\"); ax3.axis(\"off\")\n",
        "    for kp in trg_kps:\n",
        "        if kp is None:\n",
        "            continue\n",
        "        if len(kp) >= 3 and kp[2] == 0:\n",
        "            continue\n",
        "        ax3.scatter(kp[0], kp[1], s=120, c=\"lime\")\n",
        "\n",
        "    out = QUAL_DIR / f\"Qual_{cat}_ID{pair_stem}.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out, dpi=200)\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "Kv6et_mbFRwM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Main: per categoria prendi le prime N coppie e salva PCA + QUAL\n",
        "# ============================================================\n",
        "@torch.no_grad()\n",
        "def process_category(cat: str):\n",
        "    jsons = list_pair_jsons_for_category(cat)\n",
        "    if len(jsons) == 0:\n",
        "        print(f\"[WARN] Nessun json per {cat}\")\n",
        "        return\n",
        "\n",
        "    picked = jsons[:min(MAX_SCAN_PER_CAT, len(jsons))][:PAIRS_PER_CATEGORY]\n",
        "    print(f\"{cat}: selected {len(picked)} pair(s)\")\n",
        "\n",
        "    for jp in picked:\n",
        "        with open(jp, \"r\") as f:\n",
        "            ann = json.load(f)\n",
        "\n",
        "        src_name, trg_name, src_kps, trg_kps, _, _ = extract_pair_fields(ann)\n",
        "        if src_kps is None or trg_kps is None:\n",
        "            raise KeyError(\"Nel json mancano src_kps / trg_kps\")\n",
        "\n",
        "        pair_stem = jp.stem  # utile per confronto v2/v3\n",
        "\n",
        "        # load images\n",
        "        src_np, trg_np = load_pair_images(cat, src_name, trg_name)\n",
        "        src_chw = to_chw_float_0_255(src_np)\n",
        "        trg_chw = to_chw_float_0_255(trg_np)\n",
        "\n",
        "        # -------- PCA --------\n",
        "        src_pad, _, (Hsp, Wsp) = pad_to_multiple(src_chw, PATCH)\n",
        "        trg_pad, _, (Htp, Wtp) = pad_to_multiple(trg_chw, PATCH)\n",
        "        hg_s, wg_s = grid_hw(Hsp, Wsp, PATCH)\n",
        "        hg_t, wg_t = grid_hw(Htp, Wtp, PATCH)\n",
        "\n",
        "        hg = min(hg_s, hg_t)\n",
        "        wg = min(wg_s, wg_t)\n",
        "\n",
        "        Fs_inter_full = feat_inter(src_pad, LAYER_INTER, hg_s, wg_s)\n",
        "        Ft_inter_full = feat_inter(trg_pad, LAYER_INTER, hg_t, wg_t)\n",
        "        Fs_inter = Fs_inter_full[:hg, :wg, :]\n",
        "        Ft_inter = Ft_inter_full[:hg, :wg, :]\n",
        "        rgb_s_inter, rgb_t_inter = joint_pca_rgb(Fs_inter, Ft_inter)\n",
        "\n",
        "        Fs_last_full = feat_last(src_pad, hg_s, wg_s)\n",
        "        Ft_last_full = feat_last(trg_pad, hg_t, wg_t)\n",
        "        Fs_last = Fs_last_full[:hg, :wg, :]\n",
        "        Ft_last = Ft_last_full[:hg, :wg, :]\n",
        "        rgb_s_last, rgb_t_last = joint_pca_rgb(Fs_last, Ft_last)\n",
        "\n",
        "        save_pca_pair_figure_full(\n",
        "            cat, pair_stem,\n",
        "            src_np, trg_np,\n",
        "            rgb_s_inter, rgb_t_inter,\n",
        "            rgb_s_last,  rgb_t_last\n",
        "        )\n",
        "\n",
        "        # -------- QUAL (Last layer) --------\n",
        "        pred_xy = match_keypoints_lastlayer(src_chw, trg_chw, src_kps)\n",
        "        save_qual_figure(cat, pair_stem, src_np, trg_np, src_kps, trg_kps, pred_xy)\n",
        "\n",
        "        print(\"  saved PCA :\", f\"PCA_JOINT_FULL_{cat}_ID{pair_stem}.png\")\n",
        "        print(\"  saved QUAL:\", f\"Qual_{cat}_ID{pair_stem}.png\")\n",
        "\n",
        "for cat in CATEGORIES:\n",
        "    process_category(cat)\n",
        "\n",
        "print(\"DONE.\")\n",
        "print(\"PCA_DIR :\", PCA_DIR)\n",
        "print(\"QUAL_DIR:\", QUAL_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU3BfJaLFXrk",
        "outputId": "fca7314a-890d-416d-c381-21f0ad6fcec0"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aeroplane: selected 1 pair(s)\n",
            "  saved PCA : PCA_JOINT_FULL_aeroplane_ID000001-2008_002719-2008_004100:aeroplane.png\n",
            "  saved QUAL: Qual_aeroplane_ID000001-2008_002719-2008_004100:aeroplane.png\n",
            "chair: selected 1 pair(s)\n",
            "  saved PCA : PCA_JOINT_FULL_chair_ID005637-2008_000089-2008_001467:chair.png\n",
            "  saved QUAL: Qual_chair_ID005637-2008_000089-2008_001467:chair.png\n",
            "DONE.\n",
            "PCA_DIR : /content/drive/MyDrive/AML_Project_Results/DINOv3_Task1/final_analysis_results_dinov3_jointPCA\n",
            "QUAL_DIR: /content/drive/MyDrive/AML_Project_Results/DINOv3_Task1/qualitative_results_last_layer_dinov3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmYITII_G16u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}